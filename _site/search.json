[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R_locker",
    "section": "",
    "text": "통계학과를 다니면서 배운 내용을 정리한 곳입니다!\n여기는 R을 사용한 자료만 모여 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 1\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\n회귀분석\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 13, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "통계학과 3학년의 학습내용을 담은 블로그입니다."
  },
  {
    "objectID": "posts/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 조윤호\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 조윤호\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "title: “회귀”\nauthor: “YunHo”\ndate: “2022-11-01”\ncategories: [news, code, analysis]\nimage: “image.jpg”\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-10-02-시계열자료분석-학습1.html",
    "href": "posts/2022-10-02-시계열자료분석-학습1.html",
    "title": "Yun98",
    "section": "",
    "text": "불규칙, 추세성분, 주기성분의 이해 - toc:true - branch: master - badges: true - comments: true - author: 조윤호\n\n\nlibrary('data.table')\nlibrary('tidyverse')\nlibrary('gridExtra') # grid.arrange 사용해주는(그림 한 화면에 그려주는, 사실 jupyter에서는 별로 쓸모 없음) \nlibrary('lmtest') # dwtest\n\n\n\n\nset.seed(1245)\nn = 100\n\n\nset.seed(1245)\nz <- 5000 + 20*rnorm(n)\nz %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n- 같은 방법\n\nset.seed(1245)\nrnorm(n, 5000, 20) %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n\nplot(rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n20곱하면 표준편차가 +- 20정도 증가\n\n\nplot(20*rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n5000더하면 평균도 5000증가\n\n\nplot(5000 + 20*rnorm(n), type = 'l')\nabline(h = 5000, lty = 2)\n\n\n\n\nts : TimeSeries로 바꿔주는 함수(시계열)\n\nz.ts <- ts(z,\n           start = c(1980,1), # 1980년 1월부터 시작\n           frequency = 12) # 12면 월별로, 4면 분기별로, 365면 일별로\nz.ts\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19805008.3834970.8834970.8824979.6874989.3384986.3285006.5185018.4514998.9835005.9444988.9784985.049\n    19815017.0354999.1034970.2894994.1244962.2044986.3115013.9224970.4944988.5714978.3634974.5295009.565\n    19824976.2174996.0124966.7555029.4895018.5755011.3985013.2095023.4214997.9015012.8204982.2455003.137\n    19835002.3525027.8035009.0284978.8744992.8705006.6864995.8024985.5614984.2865000.3535002.7724989.359\n    19845030.0114985.2724999.7675020.0354974.9765043.3494966.2285003.0274976.1265030.5124983.9015016.143\n    19854966.1775044.2414999.5144995.4454992.8184985.3865009.7784980.8184979.3394983.1665010.1625000.873\n    19864979.7124973.1134994.0885004.4155024.6815001.0015019.1754964.4174994.1124971.1705021.8705015.610\n    19874996.4874984.2194967.2795008.6345032.1914992.3095005.2094999.6485025.7374996.7664985.4084994.681\n    19885013.3425027.1085012.3205010.116                                                                \n\n\n\n\n\nz.ts %>% cycle # 주기알려줌\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1980 1 2 3 4 5 6 7 8 9101112\n    1981 1 2 3 4 5 6 7 8 9101112\n    1982 1 2 3 4 5 6 7 8 9101112\n    1983 1 2 3 4 5 6 7 8 9101112\n    1984 1 2 3 4 5 6 7 8 9101112\n    1985 1 2 3 4 5 6 7 8 9101112\n    1986 1 2 3 4 5 6 7 8 9101112\n    1987 1 2 3 4 5 6 7 8 9101112\n    1988 1 2 3 4                \n\n\n\n\n\nz.ts %>% time\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19801980.0001980.0831980.1671980.2501980.3331980.4171980.5001980.5831980.6671980.7501980.8331980.917\n    19811981.0001981.0831981.1671981.2501981.3331981.4171981.5001981.5831981.6671981.7501981.8331981.917\n    19821982.0001982.0831982.1671982.2501982.3331982.4171982.5001982.5831982.6671982.7501982.8331982.917\n    19831983.0001983.0831983.1671983.2501983.3331983.4171983.5001983.5831983.6671983.7501983.8331983.917\n    19841984.0001984.0831984.1671984.2501984.3331984.4171984.5001984.5831984.6671984.7501984.8331984.917\n    19851985.0001985.0831985.1671985.2501985.3331985.4171985.5001985.5831985.6671985.7501985.8331985.917\n    19861986.0001986.0831986.1671986.2501986.3331986.4171986.5001986.5831986.6671986.7501986.8331986.917\n    19871987.0001987.0831987.1671987.2501987.3331987.4171987.5001987.5831987.6671987.7501987.8331987.917\n    19881988.0001988.0831988.1671988.250                                                                \n\n\n\n\n\nz.ts %>% frequency\n\n12\n\n\n\nz.ts %>% start\n\n\n19801\n\n\n\nz.ts %>% end\n\n\n19884\n\n\n\nz.ts %>% tsp # 시작, 끝, 주기 알려줌\n\n\n19801988.2512\n\n\n\nts장점 : 기본적으로 linetype = l로 해줌, 부가 옵션들이 더 나옴\n\n\nts.plot(z.ts, xlab = \"date\", ylab = \"zt\",\n       main =\"irregular elements\")\nabline(h = 5000)\n\n\n\n\n- 예제)\n\na_ <- \"1980/1/1\"\na_ %>% class\nas.Date(a_) %>% class\n\n'character'\n\n\n'Date'\n\n\n\n보이기에 비슷해 보이는데 명확하게 분류되는게 작동면에서 유리\n\n\ntmp.data <- data.table(Time = seq.Date(as.Date(\"1980/1/1\"),\n                                       by = \"month\",\n                                       length.out = 100),\n                       z = z)\ntmp.data %>% head\n\n\n\nA data.table: 6 × 2\n\n    Timez\n    <date><dbl>\n\n\n    1980-01-015008.383\n    1980-02-014970.883\n    1980-03-014970.882\n    1980-04-014979.687\n    1980-05-014989.338\n    1980-06-014986.328\n\n\n\n\n\nggplot(tmp.data, aes(Time, z)) +\ngeom_line(col = 'steelblue') +\ngeom_hline(yintercept = 5000, col = 'grey80', lty = 2) + # 선 긋기\nggtitle(\"irregular elements\") +\nscale_x_date(date_breaks = \"year\", date_labels = \"%Y\") + # 연 단위로 보이게 만들기\ntheme_bw() +\ntheme(text = element_text(size = 16), # 글씨 크기 조절 옵션\n      axis.title = element_blank()) # x, y label 제거\n\n\n\n\n\n\n\n\n하는 방법 : 일단 추세를 하나 그리고 노이즈를 더해준다.\n\n\nset.seed(1234)\nn = 100\nt <- 1:n\nx <- 0.5*t # 추세\nz <- 0.5*t + rnorm(n) # 추세 + 오차\n\n\nplot(x, type = 'l')\n\n\n\n\n- 기본 추세 + 노이즈\n\nplot(z, type = 'l')\n\n\n\n\n- 노이즈 추가, 연도, 주기, 변경\n\nz.ts <- ts(z, start = c(1980, 1), frequency = 12)\nx.ts <- ts(x, start = c(1980, 1), frequency = 12)\n\n- 추세선 + (추세 + 노이즈)선\n\nts.plot(z.ts, x.ts)\n\n\n\n\n- 추세선, 추세 + 오차선 색 다르게해서 그리기\n\nts.plot(z.ts, x.ts,\n        col = c('blue', 'red'),\n        lty = 1:2,\n        xlab = \"date\",\n        ylab = \"zt\",\n        main = \"trend component\")\n\nlegend(\"topleft\", # 범례 추가\n       legend = c(\"series\", \"trend\"),\n       lty = 1:2,\n       col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nn = 120 # 계절성분 120개\nt <- 1:n\na <- rnorm(n,0,1) # 오차\n\n\nplot(a, type = 'l')\n\n\n\n\n\n앞에 0.8곱해주면 분산을 줄여줌(오차를 줄이니까) 10더한 것은 평균 10증가 -> 불규칙성분만들기\n\n\nplot(10 + 0.8*a, type = 'l')\n\n\n\n\n- 주기가 있는 사인함수\n\nplot(sin((2*pi*t)/12),type = 'l')\n\n\n\n\n- z는 위의 sin함수에 노이즈가 더해진 형태\n\nz <- 10 + 3*sin((2*pi*t)/12) + 0.8*a\n\n\nsin함수에 오차가 섞여서 계절성을 띄는 성분이 됨.\n\n\nz.ts <- ts(z,\n           start = c(1985, 1),\n           frequency = 12)\nplot(z.ts,\n     xlab = \"date\",\n     ylab = \"zt\",\n     main = \"seasonal component\")\n\n\n\n\n\n\n\n\n\n\nx <- seq(0, 48, 0.01)\ns <- 12\npar(mfrow = c(4, 1))\n\n\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\nplot(x, cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\nsin, cos 두 함수 더한 함수 아래는 각각 weight를 다르게 해 반영한 함수\n\n\nplot(x, sin(2*pi*x/s) + cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\nabline(v = seq(1.5, 48, by = s), lty = 2)\n\nplot(x, 1.5*sin(2*pi*x/s) + 0.7*cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\nabline(v = seq(1.5, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(4, 1))\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\n주기는 6그대로인데 weight를 다르게하면 또 다른 다양한 형태가 나온다.\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\nplot(x, 2*sin(2*pi*x/12) + 0.8*sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\n\n\n\n\n\n\n\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 3\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n여러개 섞으면서 그리기 마지막 거는 추세까지 섞임\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny <- sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c : frequncy=, 12\")\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny2 <- x*0.5 + sin(2*pi*x/12) + sin(2*pi*x/6) +sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y2, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c frequency=12\")\nabline(a = 0, b = 0.5, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\nn <- 100\nt <- 1:n\na1 <- -0.8 # 진폭\na2 <- 1.4 # 진폭\nphi1 <- pi/3\nphi2 <- 3*pi/4\nfirst <- a1*sin(pi*t/6 + phi1) # 첫 번째 주기성분(주기 6)\nsecond <- a2*sin(pi*t/3 + phi2) # 두 번째 주기성분(주기 3)\n\n\ndt <- data.table(t = t,\n                 first = first, # 첫 번째 주기 성분\n                 second = second,# 두 번째 주기 성분\n                 z = first + second)# 그 두 개 더한 성분\n\np1 <- ggplot(dt, aes(t, first)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np2 <- ggplot(dt, aes(t, second)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np3 <- ggplot(dt, aes(t, z)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\n\np1\np2\np3\n\n\n\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, p3, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- scan(\"depart.txt\")\n\ndep <- ts(z, frequency = 12, start = c(1984, 1)) # TimeSeries로 바꿔도되고 안해도 되는데 여기서는 함\nplot(dep)\n\n\n\n\n\n매출액이 증가하는 추세가 보임 계졀성도 있어보임(특히 1년주기) 또 점점 분산이 증가하는 이분산성을 보이는데 따라서 로그 변환을 해준다.\n\n\ntmp.data <- data.table(\n    day = seq.Date(as.Date(\"1984-01-01\"),\n                   by = 'month', length.out = length(z)),\n    z = z\n    )\n\ntmp.data[, lndep := log(z)] # 로그변환\ntmp.data[, y := as.factor(as.integer(cycle(dep)))] # factor씌우는 게 그냥 넣으면 그대로 안 받아들여져서\ntmp.data[, trend := 1:length(z)]\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\np1 <- ggplot(tmp.data, aes(day, z)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\np2 <- ggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot after log transformation\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n로그 변환 이후 분산 폭이 줄어듦을 볼 수 있다.\n\n\np1\np2 # 로그변환한 거\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n지시함수(Indicater)를 사용하고 싶다면, \\(\\beta_0\\) = 0 or \\(\\sum \\beta_i\\) = 0 or \\(\\beta_1\\) = 0 셋 중 하나를 가정해야함. 아래는 \\(\\beta_0\\) = 0 가정\n\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\nreg <- lm(lndep ~ 0 + trend + y, data = tmp.data)\nsummary(reg)\n\n\nCall:\nlm(formula = lndep ~ 0 + trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n       Estimate Std. Error t value Pr(>|t|)    \ntrend 0.0106603  0.0001925   55.39   <2e-16 ***\ny1    6.0641904  0.0122952  493.21   <2e-16 ***\ny2    6.0807995  0.0123718  491.50   <2e-16 ***\ny3    6.3811183  0.0124509  512.50   <2e-16 ***\ny4    6.2953455  0.0125325  502.32   <2e-16 ***\ny5    6.2132392  0.0126164  492.47   <2e-16 ***\ny6    6.2197771  0.0127027  489.64   <2e-16 ***\ny7    6.5885065  0.0127914  515.08   <2e-16 ***\ny8    6.1842831  0.0128823  480.06   <2e-16 ***\ny9    6.1001148  0.0129754  470.13   <2e-16 ***\ny10   6.3334505  0.0130707  484.56   <2e-16 ***\ny11   6.3417116  0.0131681  481.60   <2e-16 ***\ny12   7.1104816  0.0132676  535.93   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 3.199e+05 on 13 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : coefficients에서 trend 보면 매월 0.0106603씩 증가함을 볼 수 있음. 로그 취한 것이기에 6.0641904, 6.0807995등은 각각 로그매출액의 1월의 평균, 2월의 평균을 의미(쭉쭉 12월까지) 미국은 블랙 프라이데이등으로 인해 12월 매출이 높은 것을 볼 수 있음, 또 높은 구간은 여름(7월)이고 이는 그래프에서도 나타남.\n\n\n\\(\\beta_1\\) = 0 가정 위 처럼 0 안넣으면 자동으로 “\\(\\beta_1\\) = 0 가정” 들어간다.\n\n\nreg2 <- lm(lndep ~ trend + y, data = tmp.data)\nsummary(reg2)\ncontrasts(tmp.data$y)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.0641904  0.0122952 493.215  < 2e-16 ***\ntrend       0.0106603  0.0001925  55.388  < 2e-16 ***\ny2          0.0166091  0.0160024   1.038   0.3046    \ny3          0.3169279  0.0160059  19.801  < 2e-16 ***\ny4          0.2311551  0.0160117  14.437  < 2e-16 ***\ny5          0.1490488  0.0160198   9.304 3.12e-12 ***\ny6          0.1555867  0.0160302   9.706 8.32e-13 ***\ny7          0.5243161  0.0160429  32.682  < 2e-16 ***\ny8          0.1200927  0.0160579   7.479 1.54e-09 ***\ny9          0.0359244  0.0160752   2.235   0.0302 *  \ny10         0.2692601  0.0160948  16.730  < 2e-16 ***\ny11         0.2775212  0.0161166  17.220  < 2e-16 ***\ny12         1.0462912  0.0161407  64.823  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n\nA matrix: 12 × 11 of type dbl\n\n    23456789101112\n\n\n    100000000000\n    210000000000\n    301000000000\n    400100000000\n    500010000000\n    600001000000\n    700000100000\n    800000010000\n    900000001000\n    1000000000100\n    1100000000010\n    1200000000001\n\n\n\n\n\n해석 : 따라서 coefficients 보면 y1없는데 \\(\\beta_1\\) = 0이라 여기 안 나온거임, 그래서 여기서는 Intercept값이 y1(1월)값임(즉, Intercept값이 \\(\\beta_0\\)값). 해석하면 1월이 기준점이 되는거기에 y2는 2월과 1월의 차이를 의미, y3는 3월과 1월의 차이 y2 맨 뒤 보면 별표3개 안 붙어 있는데 이거는 밑에 신뢰성 유의하지 않다는 의미(0.001만큼), 이유가 1월과 2월의 차이는 별로 의미없다는 것이라서 contrasts를 보면 1월이 다 0인 것을 볼 수 있는데, 이를 보아 1월이 기준점임을 알 수 있음.\n\n\n\\(\\sum \\beta_i\\) = 0 가정\n\n\nreg3 <- lm(lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\nsummary(reg3)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3260849  0.0067177 941.703  < 2e-16 ***\ntrend        0.0106603  0.0001925  55.388  < 2e-16 ***\ny1          -0.2618944  0.0108845 -24.061  < 2e-16 ***\ny2          -0.2452853  0.0108675 -22.571  < 2e-16 ***\ny3           0.0550335  0.0108538   5.070 6.63e-06 ***\ny4          -0.0307393  0.0108436  -2.835  0.00674 ** \ny5          -0.1128456  0.0108368 -10.413 8.53e-14 ***\ny6          -0.1063078  0.0108334  -9.813 5.87e-13 ***\ny7           0.2624217  0.0108334  24.223  < 2e-16 ***\ny8          -0.1418018  0.0108368 -13.085  < 2e-16 ***\ny9          -0.2259700  0.0108436 -20.839  < 2e-16 ***\ny10          0.0073656  0.0108538   0.679  0.50071    \ny11          0.0156268  0.0108675   1.438  0.15708    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : 이번에는 y12가 빠졌는데, 위에서 \\(\\sum \\beta_i\\) = 0라고 했는데 이는 자연스레 \\(\\beta_1 + \\beta_2 + \\beta_3 ... + \\beta_{12}\\) = 0임을 의미한다. 다시 말하면, \\(\\beta_{12} = -(\\beta_1 + \\beta_2 + \\beta_3 ... \\beta_{11})\\)라는 말이 된다. Intercept(6.3260849) 전체 평균을 의미(월별 상관없이) 즉, 1월은 전체 평균(6.3260849) 대비 -0.2618944한 거 만큼 의미 12월은 안나왔는데 12월은 위의 식처럼 평균대비 1~11을 다 빼면 나온다. 즉 ,0.7843966 + 6.3260849 = 7.1104815 -> 12월 거\n\n- coef 1~11 더한 거\n\nc(-0.2618944,-0.2452853,0.0550335,-0.0307393,-0.1128456,-0.1063078, 0.2624217,-0.1418018 ,-0.2259700,0.0073656,0.0156268) %>% sum\n\n-0.7843966\n\n\n\ntmp.data[, fitted_lndep := fitted(reg)]\n\n\nggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"department sales after log transformation vs estimated value\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n파랑색이 원래, 노랑색이 적합된 값 의미\n\n\n\n\n\ntmp.data[, res := resid(reg)]\n\n\nggplot(tmp.data, aes(day, res)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ngeom_hline(yintercept = 0, col = 'grey', lty = 2) +\nlabs(title = \"Time series plot of residuals\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n그림보면 양의 상관관계가 있어보임. 그래서 D.W test해보면\n\n\ndwtest(reg, alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  reg\nDW = 0.82642, p-value = 4.781e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n결과 독립성 확보 실패, 정확하게 1차 자기 상관관계가 있다. 특히 1차 양의 자기상관관계\n\n\n\n\n\n\ntmp.data_sub <- tmp.data[,.(lndep, trend)]\ntmp.data_sub %>% head\n\n\n\nA data.table: 6 × 2\n\n    lndeptrend\n    <dbl><int>\n\n\n    6.0473721\n    6.1268692\n    6.4085293\n    6.3350544\n    6.2841345\n    6.2841346\n\n\n\n\n- 데이터 생성\n\n아래 12, 6, 4 .. 은 주기 의미\n\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) sin(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:2)] <- paste(\"sin\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) cos(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:7)] <- paste(\"cos\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n                                            \ntmp.data_sub %>% head                                            \n\n\n\nA data.table: 6 × 12\n\n    lndeptrendsin_12sin_6sin_4sin_3sin_2.4cos_12cos_6cos_4cos_3cos_2.4\n    <dbl><int><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    6.04737215.000000e-01 8.660254e-01 1.000000e+00 8.660254e-01 5.000000e-01 8.660254e-01 0.5 6.123234e-17-0.5-8.660254e-01\n    6.12686928.660254e-01 8.660254e-01 1.224647e-16-8.660254e-01-8.660254e-01 5.000000e-01-0.5-1.000000e+00-0.5 5.000000e-01\n    6.40852931.000000e+00 1.224647e-16-1.000000e+00-2.449294e-16 1.000000e+00 6.123234e-17-1.0-1.836970e-16 1.0 3.061617e-16\n    6.33505448.660254e-01-8.660254e-01-2.449294e-16 8.660254e-01-8.660254e-01-5.000000e-01-0.5 1.000000e+00-0.5-5.000000e-01\n    6.28413455.000000e-01-8.660254e-01 1.000000e+00-8.660254e-01 5.000000e-01-8.660254e-01 0.5 3.061617e-16-0.5 8.660254e-01\n    6.28413461.224647e-16-2.449294e-16 3.673940e-16-4.898587e-16 6.123234e-16-1.000000e+00 1.0-1.000000e+00 1.0-1.000000e+00\n\n\n\n\n\n\n\nreg_2 <- lm(lndep ~., data = tmp.data_sub)\nsummary(reg_2)\n\n\nCall:\nlm(formula = lndep ~ ., data = tmp.data_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08232 -0.04855  0.00972  0.04645  0.08527 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3237250  0.0148062 427.100  < 2e-16 ***\ntrend        0.0107376  0.0004242  25.315  < 2e-16 ***\nsin_12      -0.0277129  0.0103066  -2.689 0.009829 ** \nsin_6       -0.0382551  0.0102107  -3.747 0.000481 ***\nsin_4       -0.1555546  0.0101931 -15.261  < 2e-16 ***\nsin_3        0.0666506  0.0101872   6.543 3.70e-08 ***\nsin_2.4      0.0128922  0.0101849   1.266 0.211691    \ncos_12       0.0857900  0.0101931   8.416 5.21e-11 ***\ncos_6        0.1675743  0.0101931  16.440  < 2e-16 ***\ncos_4        0.1592698  0.0101931  15.625  < 2e-16 ***\ncos_3        0.1267107  0.0101931  12.431  < 2e-16 ***\ncos_2.4      0.2000603  0.0101931  19.627  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.05578 on 48 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9749 \nF-statistic: 209.5 on 11 and 48 DF,  p-value: < 2.2e-16\n\n\n\n해석 : sin_2.4 하나 유의하지 않다고 나옴(별표) 원래 sin, cos함수는 1부터 -1까지 갖는데 Estimate 나온 숫자만큼 진폭을 줄여주거나 늘려줌.\n\n\ntmp.data_sub[, day := tmp.data$day]\ntmp.data_sub[, fitted_lndep := fitted(reg_2)]\n\n\nggplot(tmp.data_sub, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n\n\ntmp.data_sub[, res := resid(reg_2)]\nggplot(tmp.data_sub, aes(day, res)) +\ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n해석 : 1차 음의 자기상관관계가 있다. 다른 것보다 등분산성의 문제가 있어보인다.(그저 보기에) = 독립성문제\n\n\n\n\n\ndwtest(reg_2)\ndwtest(reg_2, alternative = \"two.side\")\ndwtest(reg_2, alternative = \"less\")\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1.269e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 6.346e-07\nalternative hypothesis: true autocorrelation is less than 0\n\n\n\nalternative 안 쓰면 default는 greater다 첫 번째 4에가까운 값이 나오면 two.side, less 둘 다 해보는게 좋음. two.side 결과보면 0이 아니다. -> 기각 less 결과보면 ’음의 상관관계가 있다’의 결과 p-value가 매우 작아 기각할 수 있다."
  },
  {
    "objectID": "posts/time-series/2022-10-02-시계열자료분석-학습1.html",
    "href": "posts/time-series/2022-10-02-시계열자료분석-학습1.html",
    "title": "(수업) 시계열 자료분석 실습 1",
    "section": "",
    "text": "불규칙, 추세성분, 주기성분의 이해\n\n\nCode\nlibrary('data.table')\nlibrary('tidyverse')\nlibrary('gridExtra') # grid.arrange 사용해주는(그림 한 화면에 그려주는, 사실 jupyter에서는 별로 쓸모 없음) \nlibrary('lmtest') # dwtest\n\n\n\n\n\n\nCode\nset.seed(1245)\nn = 100\n\n\n\n\nCode\nset.seed(1245)\nz <- 5000 + 20*rnorm(n)\nz %>% head\n\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n- 같은 방법\n\n\nCode\nset.seed(1245)\nrnorm(n, 5000, 20) %>% head\n\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n\n\nCode\nplot(rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n20곱하면 표준편차가 +- 20정도 증가\n\n\n\nCode\nplot(20*rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n\n5000더하면 평균도 5000증가\n\n\n\nCode\nplot(5000 + 20*rnorm(n), type = 'l')\nabline(h = 5000, lty = 2)\n\n\n\n\n\nts : TimeSeries로 바꿔주는 함수(시계열)\n\n\nCode\nz.ts <- ts(z,\n           start = c(1980,1), # 1980년 1월부터 시작\n           frequency = 12) # 12면 월별로, 4면 분기별로, 365면 일별로\nz.ts\n\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19805008.3834970.8834970.8824979.6874989.3384986.3285006.5185018.4514998.9835005.9444988.9784985.049\n    19815017.0354999.1034970.2894994.1244962.2044986.3115013.9224970.4944988.5714978.3634974.5295009.565\n    19824976.2174996.0124966.7555029.4895018.5755011.3985013.2095023.4214997.9015012.8204982.2455003.137\n    19835002.3525027.8035009.0284978.8744992.8705006.6864995.8024985.5614984.2865000.3535002.7724989.359\n    19845030.0114985.2724999.7675020.0354974.9765043.3494966.2285003.0274976.1265030.5124983.9015016.143\n    19854966.1775044.2414999.5144995.4454992.8184985.3865009.7784980.8184979.3394983.1665010.1625000.873\n    19864979.7124973.1134994.0885004.4155024.6815001.0015019.1754964.4174994.1124971.1705021.8705015.610\n    19874996.4874984.2194967.2795008.6345032.1914992.3095005.2094999.6485025.7374996.7664985.4084994.681\n    19885013.3425027.1085012.3205010.116                                                                \n\n\n\n\n\n\nCode\nz.ts %>% cycle # 주기알려줌\n\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1980 1 2 3 4 5 6 7 8 9101112\n    1981 1 2 3 4 5 6 7 8 9101112\n    1982 1 2 3 4 5 6 7 8 9101112\n    1983 1 2 3 4 5 6 7 8 9101112\n    1984 1 2 3 4 5 6 7 8 9101112\n    1985 1 2 3 4 5 6 7 8 9101112\n    1986 1 2 3 4 5 6 7 8 9101112\n    1987 1 2 3 4 5 6 7 8 9101112\n    1988 1 2 3 4                \n\n\n\n\n\n\nCode\nz.ts %>% time\n\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19801980.0001980.0831980.1671980.2501980.3331980.4171980.5001980.5831980.6671980.7501980.8331980.917\n    19811981.0001981.0831981.1671981.2501981.3331981.4171981.5001981.5831981.6671981.7501981.8331981.917\n    19821982.0001982.0831982.1671982.2501982.3331982.4171982.5001982.5831982.6671982.7501982.8331982.917\n    19831983.0001983.0831983.1671983.2501983.3331983.4171983.5001983.5831983.6671983.7501983.8331983.917\n    19841984.0001984.0831984.1671984.2501984.3331984.4171984.5001984.5831984.6671984.7501984.8331984.917\n    19851985.0001985.0831985.1671985.2501985.3331985.4171985.5001985.5831985.6671985.7501985.8331985.917\n    19861986.0001986.0831986.1671986.2501986.3331986.4171986.5001986.5831986.6671986.7501986.8331986.917\n    19871987.0001987.0831987.1671987.2501987.3331987.4171987.5001987.5831987.6671987.7501987.8331987.917\n    19881988.0001988.0831988.1671988.250                                                                \n\n\n\n\n\n\nCode\nz.ts %>% frequency\n\n\n12\n\n\n\n\nCode\nz.ts %>% start\n\n\n\n19801\n\n\n\n\nCode\nz.ts %>% end\n\n\n\n19884\n\n\n\n\nCode\nz.ts %>% tsp # 시작, 끝, 주기 알려줌\n\n\n\n19801988.2512\n\n\n\nts장점 : 기본적으로 linetype = l로 해줌, 부가 옵션들이 더 나옴\n\n\n\nCode\nts.plot(z.ts, xlab = \"date\", ylab = \"zt\",\n       main =\"irregular elements\")\nabline(h = 5000)\n\n\n\n\n\n- 예제)\n\n\nCode\na_ <- \"1980/1/1\"\na_ %>% class\nas.Date(a_) %>% class\n\n\n'character'\n\n\n'Date'\n\n\n\n보이기에 비슷해 보이는데 명확하게 분류되는게 작동면에서 유리\n\n\n\nCode\ntmp.data <- data.table(Time = seq.Date(as.Date(\"1980/1/1\"),\n                                       by = \"month\",\n                                       length.out = 100),\n                       z = z)\ntmp.data %>% head\n\n\n\n\nA data.table: 6 × 2\n\n    Timez\n    <date><dbl>\n\n\n    1980-01-015008.383\n    1980-02-014970.883\n    1980-03-014970.882\n    1980-04-014979.687\n    1980-05-014989.338\n    1980-06-014986.328\n\n\n\n\n\n\nCode\nggplot(tmp.data, aes(Time, z)) +\ngeom_line(col = 'steelblue') +\ngeom_hline(yintercept = 5000, col = 'grey80', lty = 2) + # 선 긋기\nggtitle(\"irregular elements\") +\nscale_x_date(date_breaks = \"year\", date_labels = \"%Y\") + # 연 단위로 보이게 만들기\ntheme_bw() +\ntheme(text = element_text(size = 16), # 글씨 크기 조절 옵션\n      axis.title = element_blank()) # x, y label 제거\n\n\n\n\n\n\n\n\n\n하는 방법 : 일단 추세를 하나 그리고 노이즈를 더해준다.\n\n\n\nCode\nset.seed(1234)\nn = 100\nt <- 1:n\nx <- 0.5*t # 추세\nz <- 0.5*t + rnorm(n) # 추세 + 오차\n\n\n\n\nCode\nplot(x, type = 'l')\n\n\n\n\n\n- 기본 추세 + 노이즈\n\n\nCode\nplot(z, type = 'l')\n\n\n\n\n\n- 노이즈 추가, 연도, 주기, 변경\n\n\nCode\nz.ts <- ts(z, start = c(1980, 1), frequency = 12)\nx.ts <- ts(x, start = c(1980, 1), frequency = 12)\n\n\n- 추세선 + (추세 + 노이즈)선\n\n\nCode\nts.plot(z.ts, x.ts)\n\n\n\n\n\n- 추세선, 추세 + 오차선 색 다르게해서 그리기\n\n\nCode\nts.plot(z.ts, x.ts,\n        col = c('blue', 'red'),\n        lty = 1:2,\n        xlab = \"date\",\n        ylab = \"zt\",\n        main = \"trend component\")\n\nlegend(\"topleft\", # 범례 추가\n       legend = c(\"series\", \"trend\"),\n       lty = 1:2,\n       col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\n\nCode\nn = 120 # 계절성분 120개\nt <- 1:n\na <- rnorm(n,0,1) # 오차\n\n\n\n\nCode\nplot(a, type = 'l')\n\n\n\n\n\n\n앞에 0.8곱해주면 분산을 줄여줌(오차를 줄이니까) 10더한 것은 평균 10증가 -> 불규칙성분만들기\n\n\n\nCode\nplot(10 + 0.8*a, type = 'l')\n\n\n\n\n\n- 주기가 있는 사인함수\n\n\nCode\nplot(sin((2*pi*t)/12),type = 'l')\n\n\n\n\n\n- z는 위의 sin함수에 노이즈가 더해진 형태\n\n\nCode\nz <- 10 + 3*sin((2*pi*t)/12) + 0.8*a\n\n\n\nsin함수에 오차가 섞여서 계절성을 띄는 성분이 됨.\n\n\n\nCode\nz.ts <- ts(z,\n           start = c(1985, 1),\n           frequency = 12)\nplot(z.ts,\n     xlab = \"date\",\n     ylab = \"zt\",\n     main = \"seasonal component\")\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nx <- seq(0, 48, 0.01)\ns <- 12\npar(mfrow = c(4, 1))\n\n\n\n\nCode\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\nplot(x, cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\nsin, cos 두 함수 더한 함수 아래는 각각 weight를 다르게 해 반영한 함수\n\n\n\nCode\nplot(x, sin(2*pi*x/s) + cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\nabline(v = seq(1.5, 48, by = s), lty = 2)\n\nplot(x, 1.5*sin(2*pi*x/s) + 0.7*cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\nabline(v = seq(1.5, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\nCode\npar(mfrow = c(4, 1))\n\n\n\n\nCode\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n주기는 6그대로인데 weight를 다르게하면 또 다른 다양한 형태가 나온다.\n\n\n\nCode\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\nplot(x, 2*sin(2*pi*x/12) + 0.8*sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\n\n\n\n\n\n\n\n\n\n\n\nCode\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 3\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n여러개 섞으면서 그리기 마지막 거는 추세까지 섞임\n\n\n\nCode\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny <- sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c : frequncy=, 12\")\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny2 <- x*0.5 + sin(2*pi*x/12) + sin(2*pi*x/6) +sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y2, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c frequency=12\")\nabline(a = 0, b = 0.5, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nn <- 100\nt <- 1:n\na1 <- -0.8 # 진폭\na2 <- 1.4 # 진폭\nphi1 <- pi/3\nphi2 <- 3*pi/4\nfirst <- a1*sin(pi*t/6 + phi1) # 첫 번째 주기성분(주기 6)\nsecond <- a2*sin(pi*t/3 + phi2) # 두 번째 주기성분(주기 3)\n\n\n\n\nCode\ndt <- data.table(t = t,\n                 first = first, # 첫 번째 주기 성분\n                 second = second,# 두 번째 주기 성분\n                 z = first + second)# 그 두 개 더한 성분\n\np1 <- ggplot(dt, aes(t, first)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np2 <- ggplot(dt, aes(t, second)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np3 <- ggplot(dt, aes(t, z)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\n\n\n\nCode\np1\np2\np3\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ngrid.arrange(p1, p2, p3, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nz <- scan(\"depart.txt\")\n\ndep <- ts(z, frequency = 12, start = c(1984, 1)) # TimeSeries로 바꿔도되고 안해도 되는데 여기서는 함\nplot(dep)\n\n\n\n\n\n\n매출액이 증가하는 추세가 보임 계졀성도 있어보임(특히 1년주기) 또 점점 분산이 증가하는 이분산성을 보이는데 따라서 로그 변환을 해준다.\n\n\n\nCode\ntmp.data <- data.table(\n    day = seq.Date(as.Date(\"1984-01-01\"),\n                   by = 'month', length.out = length(z)),\n    z = z\n    )\n\ntmp.data[, lndep := log(z)] # 로그변환\ntmp.data[, y := as.factor(as.integer(cycle(dep)))] # factor씌우는 게 그냥 넣으면 그대로 안 받아들여져서\ntmp.data[, trend := 1:length(z)]\n\ntmp.data %>% head\n\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\n\nCode\np1 <- ggplot(tmp.data, aes(day, z)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\np2 <- ggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot after log transformation\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n로그 변환 이후 분산 폭이 줄어듦을 볼 수 있다.\n\n\n\nCode\np1\np2 # 로그변환한 거\n\n\n\n\n\n\n\n\n\n\nCode\ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n\n지시함수(Indicater)를 사용하고 싶다면, \\(\\beta_0\\) = 0 or \\(\\sum \\beta_i\\) = 0 or \\(\\beta_1\\) = 0 셋 중 하나를 가정해야함. 아래는 \\(\\beta_0\\) = 0 가정\n\n\n\nCode\ntmp.data %>% head\n\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\n\nCode\nreg <- lm(lndep ~ 0 + trend + y, data = tmp.data)\nsummary(reg)\n\n\n\nCall:\nlm(formula = lndep ~ 0 + trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n       Estimate Std. Error t value Pr(>|t|)    \ntrend 0.0106603  0.0001925   55.39   <2e-16 ***\ny1    6.0641904  0.0122952  493.21   <2e-16 ***\ny2    6.0807995  0.0123718  491.50   <2e-16 ***\ny3    6.3811183  0.0124509  512.50   <2e-16 ***\ny4    6.2953455  0.0125325  502.32   <2e-16 ***\ny5    6.2132392  0.0126164  492.47   <2e-16 ***\ny6    6.2197771  0.0127027  489.64   <2e-16 ***\ny7    6.5885065  0.0127914  515.08   <2e-16 ***\ny8    6.1842831  0.0128823  480.06   <2e-16 ***\ny9    6.1001148  0.0129754  470.13   <2e-16 ***\ny10   6.3334505  0.0130707  484.56   <2e-16 ***\ny11   6.3417116  0.0131681  481.60   <2e-16 ***\ny12   7.1104816  0.0132676  535.93   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 3.199e+05 on 13 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : coefficients에서 trend 보면 매월 0.0106603씩 증가함을 볼 수 있음. 로그 취한 것이기에 6.0641904, 6.0807995등은 각각 로그매출액의 1월의 평균, 2월의 평균을 의미(쭉쭉 12월까지) 미국은 블랙 프라이데이등으로 인해 12월 매출이 높은 것을 볼 수 있음, 또 높은 구간은 여름(7월)이고 이는 그래프에서도 나타남.\n\n\n\\(\\beta_1\\) = 0 가정 위 처럼 0 안넣으면 자동으로 “\\(\\beta_1\\) = 0 가정” 들어간다.\n\n\n\nCode\nreg2 <- lm(lndep ~ trend + y, data = tmp.data)\nsummary(reg2)\ncontrasts(tmp.data$y)\n\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.0641904  0.0122952 493.215  < 2e-16 ***\ntrend       0.0106603  0.0001925  55.388  < 2e-16 ***\ny2          0.0166091  0.0160024   1.038   0.3046    \ny3          0.3169279  0.0160059  19.801  < 2e-16 ***\ny4          0.2311551  0.0160117  14.437  < 2e-16 ***\ny5          0.1490488  0.0160198   9.304 3.12e-12 ***\ny6          0.1555867  0.0160302   9.706 8.32e-13 ***\ny7          0.5243161  0.0160429  32.682  < 2e-16 ***\ny8          0.1200927  0.0160579   7.479 1.54e-09 ***\ny9          0.0359244  0.0160752   2.235   0.0302 *  \ny10         0.2692601  0.0160948  16.730  < 2e-16 ***\ny11         0.2775212  0.0161166  17.220  < 2e-16 ***\ny12         1.0462912  0.0161407  64.823  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n\nA matrix: 12 × 11 of type dbl\n\n    23456789101112\n\n\n    100000000000\n    210000000000\n    301000000000\n    400100000000\n    500010000000\n    600001000000\n    700000100000\n    800000010000\n    900000001000\n    1000000000100\n    1100000000010\n    1200000000001\n\n\n\n\n\n해석 : 따라서 coefficients 보면 y1없는데 \\(\\beta_1\\) = 0이라 여기 안 나온거임, 그래서 여기서는 Intercept값이 y1(1월)값임(즉, Intercept값이 \\(\\beta_0\\)값). 해석하면 1월이 기준점이 되는거기에 y2는 2월과 1월의 차이를 의미, y3는 3월과 1월의 차이 y2 맨 뒤 보면 별표3개 안 붙어 있는데 이거는 밑에 신뢰성 유의하지 않다는 의미(0.001만큼), 이유가 1월과 2월의 차이는 별로 의미없다는 것이라서 contrasts를 보면 1월이 다 0인 것을 볼 수 있는데, 이를 보아 1월이 기준점임을 알 수 있음.\n\n\n\\(\\sum \\beta_i\\) = 0 가정\n\n\n\nCode\nreg3 <- lm(lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\nsummary(reg3)\n\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3260849  0.0067177 941.703  < 2e-16 ***\ntrend        0.0106603  0.0001925  55.388  < 2e-16 ***\ny1          -0.2618944  0.0108845 -24.061  < 2e-16 ***\ny2          -0.2452853  0.0108675 -22.571  < 2e-16 ***\ny3           0.0550335  0.0108538   5.070 6.63e-06 ***\ny4          -0.0307393  0.0108436  -2.835  0.00674 ** \ny5          -0.1128456  0.0108368 -10.413 8.53e-14 ***\ny6          -0.1063078  0.0108334  -9.813 5.87e-13 ***\ny7           0.2624217  0.0108334  24.223  < 2e-16 ***\ny8          -0.1418018  0.0108368 -13.085  < 2e-16 ***\ny9          -0.2259700  0.0108436 -20.839  < 2e-16 ***\ny10          0.0073656  0.0108538   0.679  0.50071    \ny11          0.0156268  0.0108675   1.438  0.15708    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : 이번에는 y12가 빠졌는데, 위에서 \\(\\sum \\beta_i\\) = 0라고 했는데 이는 자연스레 \\(\\beta_1 + \\beta_2 + \\beta_3 ... + \\beta_{12}\\) = 0임을 의미한다. 다시 말하면, \\(\\beta_{12} = -(\\beta_1 + \\beta_2 + \\beta_3 ... \\beta_{11})\\)라는 말이 된다. Intercept(6.3260849) 전체 평균을 의미(월별 상관없이) 즉, 1월은 전체 평균(6.3260849) 대비 -0.2618944한 거 만큼 의미 12월은 안나왔는데 12월은 위의 식처럼 평균대비 1~11을 다 빼면 나온다. 즉 ,0.7843966 + 6.3260849 = 7.1104815 -> 12월 거\n\n- coef 1~11 더한 거\n\n\nCode\nc(-0.2618944,-0.2452853,0.0550335,-0.0307393,-0.1128456,-0.1063078, 0.2624217,-0.1418018 ,-0.2259700,0.0073656,0.0156268) %>% sum\n\n\n-0.7843966\n\n\n\n\nCode\ntmp.data[, fitted_lndep := fitted(reg)]\n\n\n\n\nCode\nggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"department sales after log transformation vs estimated value\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n파랑색이 원래, 노랑색이 적합된 값 의미\n\n\n\n\n\n\nCode\ntmp.data[, res := resid(reg)]\n\n\n\n\nCode\nggplot(tmp.data, aes(day, res)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ngeom_hline(yintercept = 0, col = 'grey', lty = 2) +\nlabs(title = \"Time series plot of residuals\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n그림보면 양의 상관관계가 있어보임. 그래서 D.W test해보면\n\n\n\nCode\ndwtest(reg, alternative = 'two.sided')\n\n\n\n    Durbin-Watson test\n\ndata:  reg\nDW = 0.82642, p-value = 4.781e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n결과 독립성 확보 실패, 정확하게 1차 자기 상관관계가 있다. 특히 1차 양의 자기상관관계\n\n\n\n\n\n\n\nCode\ntmp.data_sub <- tmp.data[,.(lndep, trend)]\ntmp.data_sub %>% head\n\n\n\n\nA data.table: 6 × 2\n\n    lndeptrend\n    <dbl><int>\n\n\n    6.0473721\n    6.1268692\n    6.4085293\n    6.3350544\n    6.2841345\n    6.2841346\n\n\n\n\n- 데이터 생성\n\n아래 12, 6, 4 .. 은 주기 의미\n\n\n\nCode\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) sin(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:2)] <- paste(\"sin\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) cos(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:7)] <- paste(\"cos\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n                                            \ntmp.data_sub %>% head                                            \n\n\n\n\nA data.table: 6 × 12\n\n    lndeptrendsin_12sin_6sin_4sin_3sin_2.4cos_12cos_6cos_4cos_3cos_2.4\n    <dbl><int><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    6.04737215.000000e-01 8.660254e-01 1.000000e+00 8.660254e-01 5.000000e-01 8.660254e-01 0.5 6.123234e-17-0.5-8.660254e-01\n    6.12686928.660254e-01 8.660254e-01 1.224647e-16-8.660254e-01-8.660254e-01 5.000000e-01-0.5-1.000000e+00-0.5 5.000000e-01\n    6.40852931.000000e+00 1.224647e-16-1.000000e+00-2.449294e-16 1.000000e+00 6.123234e-17-1.0-1.836970e-16 1.0 3.061617e-16\n    6.33505448.660254e-01-8.660254e-01-2.449294e-16 8.660254e-01-8.660254e-01-5.000000e-01-0.5 1.000000e+00-0.5-5.000000e-01\n    6.28413455.000000e-01-8.660254e-01 1.000000e+00-8.660254e-01 5.000000e-01-8.660254e-01 0.5 3.061617e-16-0.5 8.660254e-01\n    6.28413461.224647e-16-2.449294e-16 3.673940e-16-4.898587e-16 6.123234e-16-1.000000e+00 1.0-1.000000e+00 1.0-1.000000e+00\n\n\n\n\n\n\n\n\nCode\nreg_2 <- lm(lndep ~., data = tmp.data_sub)\nsummary(reg_2)\n\n\n\nCall:\nlm(formula = lndep ~ ., data = tmp.data_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08232 -0.04855  0.00972  0.04645  0.08527 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3237250  0.0148062 427.100  < 2e-16 ***\ntrend        0.0107376  0.0004242  25.315  < 2e-16 ***\nsin_12      -0.0277129  0.0103066  -2.689 0.009829 ** \nsin_6       -0.0382551  0.0102107  -3.747 0.000481 ***\nsin_4       -0.1555546  0.0101931 -15.261  < 2e-16 ***\nsin_3        0.0666506  0.0101872   6.543 3.70e-08 ***\nsin_2.4      0.0128922  0.0101849   1.266 0.211691    \ncos_12       0.0857900  0.0101931   8.416 5.21e-11 ***\ncos_6        0.1675743  0.0101931  16.440  < 2e-16 ***\ncos_4        0.1592698  0.0101931  15.625  < 2e-16 ***\ncos_3        0.1267107  0.0101931  12.431  < 2e-16 ***\ncos_2.4      0.2000603  0.0101931  19.627  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.05578 on 48 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9749 \nF-statistic: 209.5 on 11 and 48 DF,  p-value: < 2.2e-16\n\n\n\n해석 : sin_2.4 하나 유의하지 않다고 나옴(별표) 원래 sin, cos함수는 1부터 -1까지 갖는데 Estimate 나온 숫자만큼 진폭을 줄여주거나 늘려줌.\n\n\n\nCode\ntmp.data_sub[, day := tmp.data$day]\ntmp.data_sub[, fitted_lndep := fitted(reg_2)]\n\n\n\n\nCode\nggplot(tmp.data_sub, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n\n\n\n\nCode\ntmp.data_sub[, res := resid(reg_2)]\nggplot(tmp.data_sub, aes(day, res)) +\ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n해석 : 1차 음의 자기상관관계가 있다. 다른 것보다 등분산성의 문제가 있어보인다.(그저 보기에) = 독립성문제\n\n\n\n\n\n\nCode\ndwtest(reg_2)\ndwtest(reg_2, alternative = \"two.side\")\ndwtest(reg_2, alternative = \"less\")\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1.269e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 6.346e-07\nalternative hypothesis: true autocorrelation is less than 0\n\n\n\nalternative 안 쓰면 default는 greater다 첫 번째 4에가까운 값이 나오면 two.side, less 둘 다 해보는게 좋음. two.side 결과보면 0이 아니다. -> 기각 less 결과보면 ’음의 상관관계가 있다’의 결과 p-value가 매우 작아 기각할 수 있다."
  },
  {
    "objectID": "posts/regression/2022-08-10_회귀분석.html",
    "href": "posts/regression/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "title: “회귀”\nauthor: “YunHo”\ndate: “2022-11-01”\ncategories: [news, code, analysis]\nimage: “image.jpg”\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  }
]