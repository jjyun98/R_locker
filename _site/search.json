[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R_locker",
    "section": "",
    "text": "통계학과를 다니면서 배운 내용을 정리한 곳입니다!\n여기는 R을 사용한 자료만 모여 있습니다.\n\n\n\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 5\n\n\n\n\n\n\n\nR\n\n\nlesson\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 4\n\n\n\n\n\n\n\nR\n\n\nlesson\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 3\n\n\n\n\n\n\n\nR\n\n\nlesson\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 2\n\n\n\n\n\n\n\nR\n\n\nlesson\n\n\n\n\n\n\n\n\n\n\n\nOct 5, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n(수업) 시계열 자료분석 실습 1\n\n\n\n\n\n\n\nR\n\n\nlesson\n\n\n\n\n\n\n\n\n\n\n\nOct 4, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\npurr와 broom\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 14, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n모델링 b\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n모델링 a\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nSep 11, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n회귀분석\n\n\n\n\n\n\n\nR\n\n\ntheory\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nstring\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 21, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nmutate\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\ntidy data\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 19, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\ntibble, parsing\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 18, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n반복문\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\n반복문\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nvector\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 15, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nfactor\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 6, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nData handling b\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 2, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nData handling a\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nggplot b\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2022\n\n\n조윤호\n\n\n\n\n\n\n\n\nggplot a\n\n\n\n\n\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n조윤호\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "통계학과 3학년의 학습내용을 담은 블로그입니다."
  },
  {
    "objectID": "posts/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 조윤호\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "toc:true\nbranch: master\nbadges: true\ncomments: true\nauthor: 조윤호\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "href": "posts/2022-08-10/2022-08-10_회귀분석.html",
    "title": "Yun98",
    "section": "",
    "text": "title: “회귀”\nauthor: “YunHo”\ndate: “2022-11-01”\ncategories: [news, code, analysis]\nimage: “image.jpg”\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/2022-10-02-시계열자료분석-학습1.html",
    "href": "posts/2022-10-02-시계열자료분석-학습1.html",
    "title": "Yun98",
    "section": "",
    "text": "불규칙, 추세성분, 주기성분의 이해 - toc:true - branch: master - badges: true - comments: true - author: 조윤호\n\n\nlibrary('data.table')\nlibrary('tidyverse')\nlibrary('gridExtra') # grid.arrange 사용해주는(그림 한 화면에 그려주는, 사실 jupyter에서는 별로 쓸모 없음) \nlibrary('lmtest') # dwtest\n\n\n\n\nset.seed(1245)\nn = 100\n\n\nset.seed(1245)\nz <- 5000 + 20*rnorm(n)\nz %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n- 같은 방법\n\nset.seed(1245)\nrnorm(n, 5000, 20) %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n\nplot(rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n20곱하면 표준편차가 +- 20정도 증가\n\n\nplot(20*rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n5000더하면 평균도 5000증가\n\n\nplot(5000 + 20*rnorm(n), type = 'l')\nabline(h = 5000, lty = 2)\n\n\n\n\nts : TimeSeries로 바꿔주는 함수(시계열)\n\nz.ts <- ts(z,\n           start = c(1980,1), # 1980년 1월부터 시작\n           frequency = 12) # 12면 월별로, 4면 분기별로, 365면 일별로\nz.ts\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19805008.3834970.8834970.8824979.6874989.3384986.3285006.5185018.4514998.9835005.9444988.9784985.049\n    19815017.0354999.1034970.2894994.1244962.2044986.3115013.9224970.4944988.5714978.3634974.5295009.565\n    19824976.2174996.0124966.7555029.4895018.5755011.3985013.2095023.4214997.9015012.8204982.2455003.137\n    19835002.3525027.8035009.0284978.8744992.8705006.6864995.8024985.5614984.2865000.3535002.7724989.359\n    19845030.0114985.2724999.7675020.0354974.9765043.3494966.2285003.0274976.1265030.5124983.9015016.143\n    19854966.1775044.2414999.5144995.4454992.8184985.3865009.7784980.8184979.3394983.1665010.1625000.873\n    19864979.7124973.1134994.0885004.4155024.6815001.0015019.1754964.4174994.1124971.1705021.8705015.610\n    19874996.4874984.2194967.2795008.6345032.1914992.3095005.2094999.6485025.7374996.7664985.4084994.681\n    19885013.3425027.1085012.3205010.116                                                                \n\n\n\n\n\nz.ts %>% cycle # 주기알려줌\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1980 1 2 3 4 5 6 7 8 9101112\n    1981 1 2 3 4 5 6 7 8 9101112\n    1982 1 2 3 4 5 6 7 8 9101112\n    1983 1 2 3 4 5 6 7 8 9101112\n    1984 1 2 3 4 5 6 7 8 9101112\n    1985 1 2 3 4 5 6 7 8 9101112\n    1986 1 2 3 4 5 6 7 8 9101112\n    1987 1 2 3 4 5 6 7 8 9101112\n    1988 1 2 3 4                \n\n\n\n\n\nz.ts %>% time\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19801980.0001980.0831980.1671980.2501980.3331980.4171980.5001980.5831980.6671980.7501980.8331980.917\n    19811981.0001981.0831981.1671981.2501981.3331981.4171981.5001981.5831981.6671981.7501981.8331981.917\n    19821982.0001982.0831982.1671982.2501982.3331982.4171982.5001982.5831982.6671982.7501982.8331982.917\n    19831983.0001983.0831983.1671983.2501983.3331983.4171983.5001983.5831983.6671983.7501983.8331983.917\n    19841984.0001984.0831984.1671984.2501984.3331984.4171984.5001984.5831984.6671984.7501984.8331984.917\n    19851985.0001985.0831985.1671985.2501985.3331985.4171985.5001985.5831985.6671985.7501985.8331985.917\n    19861986.0001986.0831986.1671986.2501986.3331986.4171986.5001986.5831986.6671986.7501986.8331986.917\n    19871987.0001987.0831987.1671987.2501987.3331987.4171987.5001987.5831987.6671987.7501987.8331987.917\n    19881988.0001988.0831988.1671988.250                                                                \n\n\n\n\n\nz.ts %>% frequency\n\n12\n\n\n\nz.ts %>% start\n\n\n19801\n\n\n\nz.ts %>% end\n\n\n19884\n\n\n\nz.ts %>% tsp # 시작, 끝, 주기 알려줌\n\n\n19801988.2512\n\n\n\nts장점 : 기본적으로 linetype = l로 해줌, 부가 옵션들이 더 나옴\n\n\nts.plot(z.ts, xlab = \"date\", ylab = \"zt\",\n       main =\"irregular elements\")\nabline(h = 5000)\n\n\n\n\n- 예제)\n\na_ <- \"1980/1/1\"\na_ %>% class\nas.Date(a_) %>% class\n\n'character'\n\n\n'Date'\n\n\n\n보이기에 비슷해 보이는데 명확하게 분류되는게 작동면에서 유리\n\n\ntmp.data <- data.table(Time = seq.Date(as.Date(\"1980/1/1\"),\n                                       by = \"month\",\n                                       length.out = 100),\n                       z = z)\ntmp.data %>% head\n\n\n\nA data.table: 6 × 2\n\n    Timez\n    <date><dbl>\n\n\n    1980-01-015008.383\n    1980-02-014970.883\n    1980-03-014970.882\n    1980-04-014979.687\n    1980-05-014989.338\n    1980-06-014986.328\n\n\n\n\n\nggplot(tmp.data, aes(Time, z)) +\ngeom_line(col = 'steelblue') +\ngeom_hline(yintercept = 5000, col = 'grey80', lty = 2) + # 선 긋기\nggtitle(\"irregular elements\") +\nscale_x_date(date_breaks = \"year\", date_labels = \"%Y\") + # 연 단위로 보이게 만들기\ntheme_bw() +\ntheme(text = element_text(size = 16), # 글씨 크기 조절 옵션\n      axis.title = element_blank()) # x, y label 제거\n\n\n\n\n\n\n\n\n하는 방법 : 일단 추세를 하나 그리고 노이즈를 더해준다.\n\n\nset.seed(1234)\nn = 100\nt <- 1:n\nx <- 0.5*t # 추세\nz <- 0.5*t + rnorm(n) # 추세 + 오차\n\n\nplot(x, type = 'l')\n\n\n\n\n- 기본 추세 + 노이즈\n\nplot(z, type = 'l')\n\n\n\n\n- 노이즈 추가, 연도, 주기, 변경\n\nz.ts <- ts(z, start = c(1980, 1), frequency = 12)\nx.ts <- ts(x, start = c(1980, 1), frequency = 12)\n\n- 추세선 + (추세 + 노이즈)선\n\nts.plot(z.ts, x.ts)\n\n\n\n\n- 추세선, 추세 + 오차선 색 다르게해서 그리기\n\nts.plot(z.ts, x.ts,\n        col = c('blue', 'red'),\n        lty = 1:2,\n        xlab = \"date\",\n        ylab = \"zt\",\n        main = \"trend component\")\n\nlegend(\"topleft\", # 범례 추가\n       legend = c(\"series\", \"trend\"),\n       lty = 1:2,\n       col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nn = 120 # 계절성분 120개\nt <- 1:n\na <- rnorm(n,0,1) # 오차\n\n\nplot(a, type = 'l')\n\n\n\n\n\n앞에 0.8곱해주면 분산을 줄여줌(오차를 줄이니까) 10더한 것은 평균 10증가 -> 불규칙성분만들기\n\n\nplot(10 + 0.8*a, type = 'l')\n\n\n\n\n- 주기가 있는 사인함수\n\nplot(sin((2*pi*t)/12),type = 'l')\n\n\n\n\n- z는 위의 sin함수에 노이즈가 더해진 형태\n\nz <- 10 + 3*sin((2*pi*t)/12) + 0.8*a\n\n\nsin함수에 오차가 섞여서 계절성을 띄는 성분이 됨.\n\n\nz.ts <- ts(z,\n           start = c(1985, 1),\n           frequency = 12)\nplot(z.ts,\n     xlab = \"date\",\n     ylab = \"zt\",\n     main = \"seasonal component\")\n\n\n\n\n\n\n\n\n\n\nx <- seq(0, 48, 0.01)\ns <- 12\npar(mfrow = c(4, 1))\n\n\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\nplot(x, cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\nsin, cos 두 함수 더한 함수 아래는 각각 weight를 다르게 해 반영한 함수\n\n\nplot(x, sin(2*pi*x/s) + cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\nabline(v = seq(1.5, 48, by = s), lty = 2)\n\nplot(x, 1.5*sin(2*pi*x/s) + 0.7*cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\nabline(v = seq(1.5, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(4, 1))\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\n주기는 6그대로인데 weight를 다르게하면 또 다른 다양한 형태가 나온다.\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\nplot(x, 2*sin(2*pi*x/12) + 0.8*sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\n\n\n\n\n\n\n\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 3\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n여러개 섞으면서 그리기 마지막 거는 추세까지 섞임\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny <- sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c : frequncy=, 12\")\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny2 <- x*0.5 + sin(2*pi*x/12) + sin(2*pi*x/6) +sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y2, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c frequency=12\")\nabline(a = 0, b = 0.5, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\nn <- 100\nt <- 1:n\na1 <- -0.8 # 진폭\na2 <- 1.4 # 진폭\nphi1 <- pi/3\nphi2 <- 3*pi/4\nfirst <- a1*sin(pi*t/6 + phi1) # 첫 번째 주기성분(주기 6)\nsecond <- a2*sin(pi*t/3 + phi2) # 두 번째 주기성분(주기 3)\n\n\ndt <- data.table(t = t,\n                 first = first, # 첫 번째 주기 성분\n                 second = second,# 두 번째 주기 성분\n                 z = first + second)# 그 두 개 더한 성분\n\np1 <- ggplot(dt, aes(t, first)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np2 <- ggplot(dt, aes(t, second)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np3 <- ggplot(dt, aes(t, z)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\n\np1\np2\np3\n\n\n\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, p3, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- scan(\"depart.txt\")\n\ndep <- ts(z, frequency = 12, start = c(1984, 1)) # TimeSeries로 바꿔도되고 안해도 되는데 여기서는 함\nplot(dep)\n\n\n\n\n\n매출액이 증가하는 추세가 보임 계졀성도 있어보임(특히 1년주기) 또 점점 분산이 증가하는 이분산성을 보이는데 따라서 로그 변환을 해준다.\n\n\ntmp.data <- data.table(\n    day = seq.Date(as.Date(\"1984-01-01\"),\n                   by = 'month', length.out = length(z)),\n    z = z\n    )\n\ntmp.data[, lndep := log(z)] # 로그변환\ntmp.data[, y := as.factor(as.integer(cycle(dep)))] # factor씌우는 게 그냥 넣으면 그대로 안 받아들여져서\ntmp.data[, trend := 1:length(z)]\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\np1 <- ggplot(tmp.data, aes(day, z)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\np2 <- ggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot after log transformation\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n로그 변환 이후 분산 폭이 줄어듦을 볼 수 있다.\n\n\np1\np2 # 로그변환한 거\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n지시함수(Indicater)를 사용하고 싶다면, \\(\\beta_0\\) = 0 or \\(\\sum \\beta_i\\) = 0 or \\(\\beta_1\\) = 0 셋 중 하나를 가정해야함. 아래는 \\(\\beta_0\\) = 0 가정\n\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\nreg <- lm(lndep ~ 0 + trend + y, data = tmp.data)\nsummary(reg)\n\n\nCall:\nlm(formula = lndep ~ 0 + trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n       Estimate Std. Error t value Pr(>|t|)    \ntrend 0.0106603  0.0001925   55.39   <2e-16 ***\ny1    6.0641904  0.0122952  493.21   <2e-16 ***\ny2    6.0807995  0.0123718  491.50   <2e-16 ***\ny3    6.3811183  0.0124509  512.50   <2e-16 ***\ny4    6.2953455  0.0125325  502.32   <2e-16 ***\ny5    6.2132392  0.0126164  492.47   <2e-16 ***\ny6    6.2197771  0.0127027  489.64   <2e-16 ***\ny7    6.5885065  0.0127914  515.08   <2e-16 ***\ny8    6.1842831  0.0128823  480.06   <2e-16 ***\ny9    6.1001148  0.0129754  470.13   <2e-16 ***\ny10   6.3334505  0.0130707  484.56   <2e-16 ***\ny11   6.3417116  0.0131681  481.60   <2e-16 ***\ny12   7.1104816  0.0132676  535.93   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 3.199e+05 on 13 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : coefficients에서 trend 보면 매월 0.0106603씩 증가함을 볼 수 있음. 로그 취한 것이기에 6.0641904, 6.0807995등은 각각 로그매출액의 1월의 평균, 2월의 평균을 의미(쭉쭉 12월까지) 미국은 블랙 프라이데이등으로 인해 12월 매출이 높은 것을 볼 수 있음, 또 높은 구간은 여름(7월)이고 이는 그래프에서도 나타남.\n\n\n\\(\\beta_1\\) = 0 가정 위 처럼 0 안넣으면 자동으로 “\\(\\beta_1\\) = 0 가정” 들어간다.\n\n\nreg2 <- lm(lndep ~ trend + y, data = tmp.data)\nsummary(reg2)\ncontrasts(tmp.data$y)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.0641904  0.0122952 493.215  < 2e-16 ***\ntrend       0.0106603  0.0001925  55.388  < 2e-16 ***\ny2          0.0166091  0.0160024   1.038   0.3046    \ny3          0.3169279  0.0160059  19.801  < 2e-16 ***\ny4          0.2311551  0.0160117  14.437  < 2e-16 ***\ny5          0.1490488  0.0160198   9.304 3.12e-12 ***\ny6          0.1555867  0.0160302   9.706 8.32e-13 ***\ny7          0.5243161  0.0160429  32.682  < 2e-16 ***\ny8          0.1200927  0.0160579   7.479 1.54e-09 ***\ny9          0.0359244  0.0160752   2.235   0.0302 *  \ny10         0.2692601  0.0160948  16.730  < 2e-16 ***\ny11         0.2775212  0.0161166  17.220  < 2e-16 ***\ny12         1.0462912  0.0161407  64.823  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n\nA matrix: 12 × 11 of type dbl\n\n    23456789101112\n\n\n    100000000000\n    210000000000\n    301000000000\n    400100000000\n    500010000000\n    600001000000\n    700000100000\n    800000010000\n    900000001000\n    1000000000100\n    1100000000010\n    1200000000001\n\n\n\n\n\n해석 : 따라서 coefficients 보면 y1없는데 \\(\\beta_1\\) = 0이라 여기 안 나온거임, 그래서 여기서는 Intercept값이 y1(1월)값임(즉, Intercept값이 \\(\\beta_0\\)값). 해석하면 1월이 기준점이 되는거기에 y2는 2월과 1월의 차이를 의미, y3는 3월과 1월의 차이 y2 맨 뒤 보면 별표3개 안 붙어 있는데 이거는 밑에 신뢰성 유의하지 않다는 의미(0.001만큼), 이유가 1월과 2월의 차이는 별로 의미없다는 것이라서 contrasts를 보면 1월이 다 0인 것을 볼 수 있는데, 이를 보아 1월이 기준점임을 알 수 있음.\n\n\n\\(\\sum \\beta_i\\) = 0 가정\n\n\nreg3 <- lm(lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\nsummary(reg3)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3260849  0.0067177 941.703  < 2e-16 ***\ntrend        0.0106603  0.0001925  55.388  < 2e-16 ***\ny1          -0.2618944  0.0108845 -24.061  < 2e-16 ***\ny2          -0.2452853  0.0108675 -22.571  < 2e-16 ***\ny3           0.0550335  0.0108538   5.070 6.63e-06 ***\ny4          -0.0307393  0.0108436  -2.835  0.00674 ** \ny5          -0.1128456  0.0108368 -10.413 8.53e-14 ***\ny6          -0.1063078  0.0108334  -9.813 5.87e-13 ***\ny7           0.2624217  0.0108334  24.223  < 2e-16 ***\ny8          -0.1418018  0.0108368 -13.085  < 2e-16 ***\ny9          -0.2259700  0.0108436 -20.839  < 2e-16 ***\ny10          0.0073656  0.0108538   0.679  0.50071    \ny11          0.0156268  0.0108675   1.438  0.15708    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : 이번에는 y12가 빠졌는데, 위에서 \\(\\sum \\beta_i\\) = 0라고 했는데 이는 자연스레 \\(\\beta_1 + \\beta_2 + \\beta_3 ... + \\beta_{12}\\) = 0임을 의미한다. 다시 말하면, \\(\\beta_{12} = -(\\beta_1 + \\beta_2 + \\beta_3 ... \\beta_{11})\\)라는 말이 된다. Intercept(6.3260849) 전체 평균을 의미(월별 상관없이) 즉, 1월은 전체 평균(6.3260849) 대비 -0.2618944한 거 만큼 의미 12월은 안나왔는데 12월은 위의 식처럼 평균대비 1~11을 다 빼면 나온다. 즉 ,0.7843966 + 6.3260849 = 7.1104815 -> 12월 거\n\n- coef 1~11 더한 거\n\nc(-0.2618944,-0.2452853,0.0550335,-0.0307393,-0.1128456,-0.1063078, 0.2624217,-0.1418018 ,-0.2259700,0.0073656,0.0156268) %>% sum\n\n-0.7843966\n\n\n\ntmp.data[, fitted_lndep := fitted(reg)]\n\n\nggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"department sales after log transformation vs estimated value\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n파랑색이 원래, 노랑색이 적합된 값 의미\n\n\n\n\n\ntmp.data[, res := resid(reg)]\n\n\nggplot(tmp.data, aes(day, res)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ngeom_hline(yintercept = 0, col = 'grey', lty = 2) +\nlabs(title = \"Time series plot of residuals\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n그림보면 양의 상관관계가 있어보임. 그래서 D.W test해보면\n\n\ndwtest(reg, alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  reg\nDW = 0.82642, p-value = 4.781e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n결과 독립성 확보 실패, 정확하게 1차 자기 상관관계가 있다. 특히 1차 양의 자기상관관계\n\n\n\n\n\n\ntmp.data_sub <- tmp.data[,.(lndep, trend)]\ntmp.data_sub %>% head\n\n\n\nA data.table: 6 × 2\n\n    lndeptrend\n    <dbl><int>\n\n\n    6.0473721\n    6.1268692\n    6.4085293\n    6.3350544\n    6.2841345\n    6.2841346\n\n\n\n\n- 데이터 생성\n\n아래 12, 6, 4 .. 은 주기 의미\n\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) sin(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:2)] <- paste(\"sin\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) cos(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:7)] <- paste(\"cos\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n                                            \ntmp.data_sub %>% head                                            \n\n\n\nA data.table: 6 × 12\n\n    lndeptrendsin_12sin_6sin_4sin_3sin_2.4cos_12cos_6cos_4cos_3cos_2.4\n    <dbl><int><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    6.04737215.000000e-01 8.660254e-01 1.000000e+00 8.660254e-01 5.000000e-01 8.660254e-01 0.5 6.123234e-17-0.5-8.660254e-01\n    6.12686928.660254e-01 8.660254e-01 1.224647e-16-8.660254e-01-8.660254e-01 5.000000e-01-0.5-1.000000e+00-0.5 5.000000e-01\n    6.40852931.000000e+00 1.224647e-16-1.000000e+00-2.449294e-16 1.000000e+00 6.123234e-17-1.0-1.836970e-16 1.0 3.061617e-16\n    6.33505448.660254e-01-8.660254e-01-2.449294e-16 8.660254e-01-8.660254e-01-5.000000e-01-0.5 1.000000e+00-0.5-5.000000e-01\n    6.28413455.000000e-01-8.660254e-01 1.000000e+00-8.660254e-01 5.000000e-01-8.660254e-01 0.5 3.061617e-16-0.5 8.660254e-01\n    6.28413461.224647e-16-2.449294e-16 3.673940e-16-4.898587e-16 6.123234e-16-1.000000e+00 1.0-1.000000e+00 1.0-1.000000e+00\n\n\n\n\n\n\n\nreg_2 <- lm(lndep ~., data = tmp.data_sub)\nsummary(reg_2)\n\n\nCall:\nlm(formula = lndep ~ ., data = tmp.data_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08232 -0.04855  0.00972  0.04645  0.08527 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3237250  0.0148062 427.100  < 2e-16 ***\ntrend        0.0107376  0.0004242  25.315  < 2e-16 ***\nsin_12      -0.0277129  0.0103066  -2.689 0.009829 ** \nsin_6       -0.0382551  0.0102107  -3.747 0.000481 ***\nsin_4       -0.1555546  0.0101931 -15.261  < 2e-16 ***\nsin_3        0.0666506  0.0101872   6.543 3.70e-08 ***\nsin_2.4      0.0128922  0.0101849   1.266 0.211691    \ncos_12       0.0857900  0.0101931   8.416 5.21e-11 ***\ncos_6        0.1675743  0.0101931  16.440  < 2e-16 ***\ncos_4        0.1592698  0.0101931  15.625  < 2e-16 ***\ncos_3        0.1267107  0.0101931  12.431  < 2e-16 ***\ncos_2.4      0.2000603  0.0101931  19.627  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.05578 on 48 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9749 \nF-statistic: 209.5 on 11 and 48 DF,  p-value: < 2.2e-16\n\n\n\n해석 : sin_2.4 하나 유의하지 않다고 나옴(별표) 원래 sin, cos함수는 1부터 -1까지 갖는데 Estimate 나온 숫자만큼 진폭을 줄여주거나 늘려줌.\n\n\ntmp.data_sub[, day := tmp.data$day]\ntmp.data_sub[, fitted_lndep := fitted(reg_2)]\n\n\nggplot(tmp.data_sub, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n\n\ntmp.data_sub[, res := resid(reg_2)]\nggplot(tmp.data_sub, aes(day, res)) +\ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n해석 : 1차 음의 자기상관관계가 있다. 다른 것보다 등분산성의 문제가 있어보인다.(그저 보기에) = 독립성문제\n\n\n\n\n\ndwtest(reg_2)\ndwtest(reg_2, alternative = \"two.side\")\ndwtest(reg_2, alternative = \"less\")\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1.269e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 6.346e-07\nalternative hypothesis: true autocorrelation is less than 0\n\n\n\nalternative 안 쓰면 default는 greater다 첫 번째 4에가까운 값이 나오면 two.side, less 둘 다 해보는게 좋음. two.side 결과보면 0이 아니다. -> 기각 less 결과보면 ’음의 상관관계가 있다’의 결과 p-value가 매우 작아 기각할 수 있다."
  },
  {
    "objectID": "posts/time-series/2022-10-02-시계열자료분석-학습1.html",
    "href": "posts/time-series/2022-10-02-시계열자료분석-학습1.html",
    "title": "(수업) 시계열 자료분석 실습 1",
    "section": "",
    "text": "불규칙, 추세성분, 주기성분의 이해\n\nlibrary('data.table')\nlibrary('tidyverse')\nlibrary('gridExtra') # grid.arrange 사용해주는(그림 한 화면에 그려주는, 사실 jupyter에서는 별로 쓸모 없음) \nlibrary('lmtest') # dwtest\n\n\n\n\nset.seed(1245)\nn = 100\n\n\nset.seed(1245)\nz <- 5000 + 20*rnorm(n)\nz %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n- 같은 방법\n\nset.seed(1245)\nrnorm(n, 5000, 20) %>% head\n\n\n5008.382801322284970.883327897544970.882398360754979.687072561944989.338017215614986.32787849186\n\n\n\nplot(rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n20곱하면 표준편차가 +- 20정도 증가\n\n\nplot(20*rnorm(n), type = 'l')\nabline(h = 0, lty = 2)\n\n\n\n\n\n5000더하면 평균도 5000증가\n\n\nplot(5000 + 20*rnorm(n), type = 'l')\nabline(h = 5000, lty = 2)\n\n\n\n\nts : TimeSeries로 바꿔주는 함수(시계열)\n\nz.ts <- ts(z,\n           start = c(1980,1), # 1980년 1월부터 시작\n           frequency = 12) # 12면 월별로, 4면 분기별로, 365면 일별로\nz.ts\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19805008.3834970.8834970.8824979.6874989.3384986.3285006.5185018.4514998.9835005.9444988.9784985.049\n    19815017.0354999.1034970.2894994.1244962.2044986.3115013.9224970.4944988.5714978.3634974.5295009.565\n    19824976.2174996.0124966.7555029.4895018.5755011.3985013.2095023.4214997.9015012.8204982.2455003.137\n    19835002.3525027.8035009.0284978.8744992.8705006.6864995.8024985.5614984.2865000.3535002.7724989.359\n    19845030.0114985.2724999.7675020.0354974.9765043.3494966.2285003.0274976.1265030.5124983.9015016.143\n    19854966.1775044.2414999.5144995.4454992.8184985.3865009.7784980.8184979.3394983.1665010.1625000.873\n    19864979.7124973.1134994.0885004.4155024.6815001.0015019.1754964.4174994.1124971.1705021.8705015.610\n    19874996.4874984.2194967.2795008.6345032.1914992.3095005.2094999.6485025.7374996.7664985.4084994.681\n    19885013.3425027.1085012.3205010.116                                                                \n\n\n\n\n\nz.ts %>% cycle # 주기알려줌\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1980 1 2 3 4 5 6 7 8 9101112\n    1981 1 2 3 4 5 6 7 8 9101112\n    1982 1 2 3 4 5 6 7 8 9101112\n    1983 1 2 3 4 5 6 7 8 9101112\n    1984 1 2 3 4 5 6 7 8 9101112\n    1985 1 2 3 4 5 6 7 8 9101112\n    1986 1 2 3 4 5 6 7 8 9101112\n    1987 1 2 3 4 5 6 7 8 9101112\n    1988 1 2 3 4                \n\n\n\n\n\nz.ts %>% time\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    19801980.0001980.0831980.1671980.2501980.3331980.4171980.5001980.5831980.6671980.7501980.8331980.917\n    19811981.0001981.0831981.1671981.2501981.3331981.4171981.5001981.5831981.6671981.7501981.8331981.917\n    19821982.0001982.0831982.1671982.2501982.3331982.4171982.5001982.5831982.6671982.7501982.8331982.917\n    19831983.0001983.0831983.1671983.2501983.3331983.4171983.5001983.5831983.6671983.7501983.8331983.917\n    19841984.0001984.0831984.1671984.2501984.3331984.4171984.5001984.5831984.6671984.7501984.8331984.917\n    19851985.0001985.0831985.1671985.2501985.3331985.4171985.5001985.5831985.6671985.7501985.8331985.917\n    19861986.0001986.0831986.1671986.2501986.3331986.4171986.5001986.5831986.6671986.7501986.8331986.917\n    19871987.0001987.0831987.1671987.2501987.3331987.4171987.5001987.5831987.6671987.7501987.8331987.917\n    19881988.0001988.0831988.1671988.250                                                                \n\n\n\n\n\nz.ts %>% frequency\n\n12\n\n\n\nz.ts %>% start\n\n\n19801\n\n\n\nz.ts %>% end\n\n\n19884\n\n\n\nz.ts %>% tsp # 시작, 끝, 주기 알려줌\n\n\n19801988.2512\n\n\n\nts장점 : 기본적으로 linetype = l로 해줌, 부가 옵션들이 더 나옴\n\n\nts.plot(z.ts, xlab = \"date\", ylab = \"zt\",\n       main =\"irregular elements\")\nabline(h = 5000)\n\n\n\n\n- 예제)\n\na_ <- \"1980/1/1\"\na_ %>% class\nas.Date(a_) %>% class\n\n'character'\n\n\n'Date'\n\n\n\n보이기에 비슷해 보이는데 명확하게 분류되는게 작동면에서 유리\n\n\ntmp.data <- data.table(Time = seq.Date(as.Date(\"1980/1/1\"),\n                                       by = \"month\",\n                                       length.out = 100),\n                       z = z)\ntmp.data %>% head\n\n\n\nA data.table: 6 × 2\n\n    Timez\n    <date><dbl>\n\n\n    1980-01-015008.383\n    1980-02-014970.883\n    1980-03-014970.882\n    1980-04-014979.687\n    1980-05-014989.338\n    1980-06-014986.328\n\n\n\n\n\nggplot(tmp.data, aes(Time, z)) +\ngeom_line(col = 'steelblue') +\ngeom_hline(yintercept = 5000, col = 'grey80', lty = 2) + # 선 긋기\nggtitle(\"irregular elements\") +\nscale_x_date(date_breaks = \"year\", date_labels = \"%Y\") + # 연 단위로 보이게 만들기\ntheme_bw() +\ntheme(text = element_text(size = 16), # 글씨 크기 조절 옵션\n      axis.title = element_blank()) # x, y label 제거\n\n\n\n\n\n\n\n\n하는 방법 : 일단 추세를 하나 그리고 노이즈를 더해준다.\n\n\nset.seed(1234)\nn = 100\nt <- 1:n\nx <- 0.5*t # 추세\nz <- 0.5*t + rnorm(n) # 추세 + 오차\n\n\nplot(x, type = 'l')\n\n\n\n\n- 기본 추세 + 노이즈\n\nplot(z, type = 'l')\n\n\n\n\n- 노이즈 추가, 연도, 주기, 변경\n\nz.ts <- ts(z, start = c(1980, 1), frequency = 12)\nx.ts <- ts(x, start = c(1980, 1), frequency = 12)\n\n- 추세선 + (추세 + 노이즈)선\n\nts.plot(z.ts, x.ts)\n\n\n\n\n- 추세선, 추세 + 오차선 색 다르게해서 그리기\n\nts.plot(z.ts, x.ts,\n        col = c('blue', 'red'),\n        lty = 1:2,\n        xlab = \"date\",\n        ylab = \"zt\",\n        main = \"trend component\")\n\nlegend(\"topleft\", # 범례 추가\n       legend = c(\"series\", \"trend\"),\n       lty = 1:2,\n       col = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nn = 120 # 계절성분 120개\nt <- 1:n\na <- rnorm(n,0,1) # 오차\n\n\nplot(a, type = 'l')\n\n\n\n\n\n앞에 0.8곱해주면 분산을 줄여줌(오차를 줄이니까) 10더한 것은 평균 10증가 -> 불규칙성분만들기\n\n\nplot(10 + 0.8*a, type = 'l')\n\n\n\n\n- 주기가 있는 사인함수\n\nplot(sin((2*pi*t)/12),type = 'l')\n\n\n\n\n- z는 위의 sin함수에 노이즈가 더해진 형태\n\nz <- 10 + 3*sin((2*pi*t)/12) + 0.8*a\n\n\nsin함수에 오차가 섞여서 계절성을 띄는 성분이 됨.\n\n\nz.ts <- ts(z,\n           start = c(1985, 1),\n           frequency = 12)\nplot(z.ts,\n     xlab = \"date\",\n     ylab = \"zt\",\n     main = \"seasonal component\")\n\n\n\n\n\n\n\n\n\n\nx <- seq(0, 48, 0.01)\ns <- 12\npar(mfrow = c(4, 1))\n\n\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\nplot(x, cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\nsin, cos 두 함수 더한 함수 아래는 각각 weight를 다르게 해 반영한 함수\n\n\nplot(x, sin(2*pi*x/s) + cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\nabline(v = seq(1.5, 48, by = s), lty = 2)\n\nplot(x, 1.5*sin(2*pi*x/s) + 0.7*cos(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin+cos::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\nabline(v = seq(1.5, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\npar(mfrow = c(4, 1))\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2)\n\n\n\n\n\n\n\n\n주기는 6그대로인데 weight를 다르게하면 또 다른 다양한 형태가 나온다.\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\nplot(x, 2*sin(2*pi*x/12) + 0.8*sin(2*pi*x/6), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 48, by = s), lty = 2) \n\n\n\n\n\n\n\n\n\n\ns <- 12\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 6\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\ns <- 3\nplot(x, sin(2*pi*x/s), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin::', \"frequncy=\", s))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = s), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n여러개 섞으면서 그리기 마지막 거는 추세까지 섞임\n\n\nplot(x, sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3), type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = paste0('sin + sin + sin::', \"frequncy=\", 12))\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny <- sin(2*pi*x/12) + sin(2*pi*x/6) + sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c : frequncy=, 12\")\nabline(h = 0, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\ny2 <- x*0.5 + sin(2*pi*x/12) + sin(2*pi*x/6) +sin(2*pi*x/3) + cos(2*pi*x/12) + cos(2*pi*x/6) + cos(2*pi*x/3)\n\nplot(x, y2, type = 'l', col = 'steelblue', lwd = 2,\n     xlab = \"\", ylab = \"\", main = \"s+s+s+c+c+c frequency=12\")\nabline(a = 0, b = 0.5, lty = 2)\nabline(v = seq(0, 24, by = 12), lty = 2)\n\n\n\n\n\n\n\n\n\n\n\nn <- 100\nt <- 1:n\na1 <- -0.8 # 진폭\na2 <- 1.4 # 진폭\nphi1 <- pi/3\nphi2 <- 3*pi/4\nfirst <- a1*sin(pi*t/6 + phi1) # 첫 번째 주기성분(주기 6)\nsecond <- a2*sin(pi*t/3 + phi2) # 두 번째 주기성분(주기 3)\n\n\ndt <- data.table(t = t,\n                 first = first, # 첫 번째 주기 성분\n                 second = second,# 두 번째 주기 성분\n                 z = first + second)# 그 두 개 더한 성분\n\np1 <- ggplot(dt, aes(t, first)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np2 <- ggplot(dt, aes(t, second)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\np3 <- ggplot(dt, aes(t, z)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue', size = 1) +\nylim(-2.5, 2) + xlab(\"\") +\nscale_x_continuous(breaks = seq(1, 100, by = 12)) +\ntheme_bw()\n\n\np1\np2\np3\n\n\n\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, p3, nrow = 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- scan(\"depart.txt\")\n\ndep <- ts(z, frequency = 12, start = c(1984, 1)) # TimeSeries로 바꿔도되고 안해도 되는데 여기서는 함\nplot(dep)\n\n\n\n\n\n매출액이 증가하는 추세가 보임 계졀성도 있어보임(특히 1년주기) 또 점점 분산이 증가하는 이분산성을 보이는데 따라서 로그 변환을 해준다.\n\n\ntmp.data <- data.table(\n    day = seq.Date(as.Date(\"1984-01-01\"),\n                   by = 'month', length.out = length(z)),\n    z = z\n    )\n\ntmp.data[, lndep := log(z)] # 로그변환\ntmp.data[, y := as.factor(as.integer(cycle(dep)))] # factor씌우는 게 그냥 넣으면 그대로 안 받아들여져서\ntmp.data[, trend := 1:length(z)]\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\np1 <- ggplot(tmp.data, aes(day, z)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\np2 <- ggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"monthly department store sales TimeSeries plot after log transformation\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n로그 변환 이후 분산 폭이 줄어듦을 볼 수 있다.\n\n\np1\np2 # 로그변환한 거\n\n\n\n\n\n\n\n\ngrid.arrange(p1, p2, nrow = 2)\n\n\n\n\n\n\n\n지시함수(Indicater)를 사용하고 싶다면, \\(\\beta_0\\) = 0 or \\(\\sum \\beta_i\\) = 0 or \\(\\beta_1\\) = 0 셋 중 하나를 가정해야함. 아래는 \\(\\beta_0\\) = 0 가정\n\n\ntmp.data %>% head\n\n\n\nA data.table: 6 × 5\n\n    dayzlndepytrend\n    <date><dbl><dbl><fct><int>\n\n\n    1984-01-014236.04737211\n    1984-02-014586.12686922\n    1984-03-016076.40852933\n    1984-04-015646.33505444\n    1984-05-015366.28413455\n    1984-06-015366.28413466\n\n\n\n\n\nreg <- lm(lndep ~ 0 + trend + y, data = tmp.data)\nsummary(reg)\n\n\nCall:\nlm(formula = lndep ~ 0 + trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n       Estimate Std. Error t value Pr(>|t|)    \ntrend 0.0106603  0.0001925   55.39   <2e-16 ***\ny1    6.0641904  0.0122952  493.21   <2e-16 ***\ny2    6.0807995  0.0123718  491.50   <2e-16 ***\ny3    6.3811183  0.0124509  512.50   <2e-16 ***\ny4    6.2953455  0.0125325  502.32   <2e-16 ***\ny5    6.2132392  0.0126164  492.47   <2e-16 ***\ny6    6.2197771  0.0127027  489.64   <2e-16 ***\ny7    6.5885065  0.0127914  515.08   <2e-16 ***\ny8    6.1842831  0.0128823  480.06   <2e-16 ***\ny9    6.1001148  0.0129754  470.13   <2e-16 ***\ny10   6.3334505  0.0130707  484.56   <2e-16 ***\ny11   6.3417116  0.0131681  481.60   <2e-16 ***\ny12   7.1104816  0.0132676  535.93   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:      1, Adjusted R-squared:      1 \nF-statistic: 3.199e+05 on 13 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : coefficients에서 trend 보면 매월 0.0106603씩 증가함을 볼 수 있음. 로그 취한 것이기에 6.0641904, 6.0807995등은 각각 로그매출액의 1월의 평균, 2월의 평균을 의미(쭉쭉 12월까지) 미국은 블랙 프라이데이등으로 인해 12월 매출이 높은 것을 볼 수 있음, 또 높은 구간은 여름(7월)이고 이는 그래프에서도 나타남.\n\n\n\\(\\beta_1\\) = 0 가정 위 처럼 0 안넣으면 자동으로 “\\(\\beta_1\\) = 0 가정” 들어간다.\n\n\nreg2 <- lm(lndep ~ trend + y, data = tmp.data)\nsummary(reg2)\ncontrasts(tmp.data$y)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 6.0641904  0.0122952 493.215  < 2e-16 ***\ntrend       0.0106603  0.0001925  55.388  < 2e-16 ***\ny2          0.0166091  0.0160024   1.038   0.3046    \ny3          0.3169279  0.0160059  19.801  < 2e-16 ***\ny4          0.2311551  0.0160117  14.437  < 2e-16 ***\ny5          0.1490488  0.0160198   9.304 3.12e-12 ***\ny6          0.1555867  0.0160302   9.706 8.32e-13 ***\ny7          0.5243161  0.0160429  32.682  < 2e-16 ***\ny8          0.1200927  0.0160579   7.479 1.54e-09 ***\ny9          0.0359244  0.0160752   2.235   0.0302 *  \ny10         0.2692601  0.0160948  16.730  < 2e-16 ***\ny11         0.2775212  0.0161166  17.220  < 2e-16 ***\ny12         1.0462912  0.0161407  64.823  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n\nA matrix: 12 × 11 of type dbl\n\n    23456789101112\n\n\n    100000000000\n    210000000000\n    301000000000\n    400100000000\n    500010000000\n    600001000000\n    700000100000\n    800000010000\n    900000001000\n    1000000000100\n    1100000000010\n    1200000000001\n\n\n\n\n\n해석 : 따라서 coefficients 보면 y1없는데 \\(\\beta_1\\) = 0이라 여기 안 나온거임, 그래서 여기서는 Intercept값이 y1(1월)값임(즉, Intercept값이 \\(\\beta_0\\)값). 해석하면 1월이 기준점이 되는거기에 y2는 2월과 1월의 차이를 의미, y3는 3월과 1월의 차이 y2 맨 뒤 보면 별표3개 안 붙어 있는데 이거는 밑에 신뢰성 유의하지 않다는 의미(0.001만큼), 이유가 1월과 2월의 차이는 별로 의미없다는 것이라서 contrasts를 보면 1월이 다 0인 것을 볼 수 있는데, 이를 보아 1월이 기준점임을 알 수 있음.\n\n\n\\(\\sum \\beta_i\\) = 0 가정\n\n\nreg3 <- lm(lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\nsummary(reg3)\n\n\nCall:\nlm(formula = lndep ~ trend + y, data = tmp.data, contrasts = list(y = \"contr.sum\"))\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.038679 -0.018689 -0.001468  0.015185  0.057288 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3260849  0.0067177 941.703  < 2e-16 ***\ntrend        0.0106603  0.0001925  55.388  < 2e-16 ***\ny1          -0.2618944  0.0108845 -24.061  < 2e-16 ***\ny2          -0.2452853  0.0108675 -22.571  < 2e-16 ***\ny3           0.0550335  0.0108538   5.070 6.63e-06 ***\ny4          -0.0307393  0.0108436  -2.835  0.00674 ** \ny5          -0.1128456  0.0108368 -10.413 8.53e-14 ***\ny6          -0.1063078  0.0108334  -9.813 5.87e-13 ***\ny7           0.2624217  0.0108334  24.223  < 2e-16 ***\ny8          -0.1418018  0.0108368 -13.085  < 2e-16 ***\ny9          -0.2259700  0.0108436 -20.839  < 2e-16 ***\ny10          0.0073656  0.0108538   0.679  0.50071    \ny11          0.0156268  0.0108675   1.438  0.15708    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0253 on 47 degrees of freedom\nMultiple R-squared:  0.9959,    Adjusted R-squared:  0.9948 \nF-statistic: 949.2 on 12 and 47 DF,  p-value: < 2.2e-16\n\n\n\n해석 : 이번에는 y12가 빠졌는데, 위에서 \\(\\sum \\beta_i\\) = 0라고 했는데 이는 자연스레 \\(\\beta_1 + \\beta_2 + \\beta_3 ... + \\beta_{12}\\) = 0임을 의미한다. 다시 말하면, \\(\\beta_{12} = -(\\beta_1 + \\beta_2 + \\beta_3 ... \\beta_{11})\\)라는 말이 된다. Intercept(6.3260849) 전체 평균을 의미(월별 상관없이) 즉, 1월은 전체 평균(6.3260849) 대비 -0.2618944한 거 만큼 의미 12월은 안나왔는데 12월은 위의 식처럼 평균대비 1~11을 다 빼면 나온다. 즉 ,0.7843966 + 6.3260849 = 7.1104815 -> 12월 거\n\n- coef 1~11 더한 거\n\nc(-0.2618944,-0.2452853,0.0550335,-0.0307393,-0.1128456,-0.1063078, 0.2624217,-0.1418018 ,-0.2259700,0.0073656,0.0156268) %>% sum\n\n-0.7843966\n\n\n\ntmp.data[, fitted_lndep := fitted(reg)]\n\n\nggplot(tmp.data, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\nlabs(title = \"department sales after log transformation vs estimated value\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n파랑색이 원래, 노랑색이 적합된 값 의미\n\n\n\n\n\ntmp.data[, res := resid(reg)]\n\n\nggplot(tmp.data, aes(day, res)) + \ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ngeom_hline(yintercept = 0, col = 'grey', lty = 2) +\nlabs(title = \"Time series plot of residuals\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n그림보면 양의 상관관계가 있어보임. 그래서 D.W test해보면\n\n\ndwtest(reg, alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  reg\nDW = 0.82642, p-value = 4.781e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n결과 독립성 확보 실패, 정확하게 1차 자기 상관관계가 있다. 특히 1차 양의 자기상관관계\n\n\n\n\n\n\ntmp.data_sub <- tmp.data[,.(lndep, trend)]\ntmp.data_sub %>% head\n\n\n\nA data.table: 6 × 2\n\n    lndeptrend\n    <dbl><int>\n\n\n    6.0473721\n    6.1268692\n    6.4085293\n    6.3350544\n    6.2841345\n    6.2841346\n\n\n\n\n- 데이터 생성\n\n아래 12, 6, 4 .. 은 주기 의미\n\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) sin(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:2)] <- paste(\"sin\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n\ntmp.data_sub <- cbind(tmp.data_sub,\n                      tmp.data_sub[, lapply(as.list(1:5),\n                                            function(i) cos(2*pi*i/12*trend))])\n                                            \nnames(tmp.data_sub)[-(1:7)] <- paste(\"cos\", c(12, 6, 4, 3, 2.4), sep = \"_\")\n                                            \ntmp.data_sub %>% head                                            \n\n\n\nA data.table: 6 × 12\n\n    lndeptrendsin_12sin_6sin_4sin_3sin_2.4cos_12cos_6cos_4cos_3cos_2.4\n    <dbl><int><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    6.04737215.000000e-01 8.660254e-01 1.000000e+00 8.660254e-01 5.000000e-01 8.660254e-01 0.5 6.123234e-17-0.5-8.660254e-01\n    6.12686928.660254e-01 8.660254e-01 1.224647e-16-8.660254e-01-8.660254e-01 5.000000e-01-0.5-1.000000e+00-0.5 5.000000e-01\n    6.40852931.000000e+00 1.224647e-16-1.000000e+00-2.449294e-16 1.000000e+00 6.123234e-17-1.0-1.836970e-16 1.0 3.061617e-16\n    6.33505448.660254e-01-8.660254e-01-2.449294e-16 8.660254e-01-8.660254e-01-5.000000e-01-0.5 1.000000e+00-0.5-5.000000e-01\n    6.28413455.000000e-01-8.660254e-01 1.000000e+00-8.660254e-01 5.000000e-01-8.660254e-01 0.5 3.061617e-16-0.5 8.660254e-01\n    6.28413461.224647e-16-2.449294e-16 3.673940e-16-4.898587e-16 6.123234e-16-1.000000e+00 1.0-1.000000e+00 1.0-1.000000e+00\n\n\n\n\n\n\n\nreg_2 <- lm(lndep ~., data = tmp.data_sub)\nsummary(reg_2)\n\n\nCall:\nlm(formula = lndep ~ ., data = tmp.data_sub)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.08232 -0.04855  0.00972  0.04645  0.08527 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  6.3237250  0.0148062 427.100  < 2e-16 ***\ntrend        0.0107376  0.0004242  25.315  < 2e-16 ***\nsin_12      -0.0277129  0.0103066  -2.689 0.009829 ** \nsin_6       -0.0382551  0.0102107  -3.747 0.000481 ***\nsin_4       -0.1555546  0.0101931 -15.261  < 2e-16 ***\nsin_3        0.0666506  0.0101872   6.543 3.70e-08 ***\nsin_2.4      0.0128922  0.0101849   1.266 0.211691    \ncos_12       0.0857900  0.0101931   8.416 5.21e-11 ***\ncos_6        0.1675743  0.0101931  16.440  < 2e-16 ***\ncos_4        0.1592698  0.0101931  15.625  < 2e-16 ***\ncos_3        0.1267107  0.0101931  12.431  < 2e-16 ***\ncos_2.4      0.2000603  0.0101931  19.627  < 2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.05578 on 48 degrees of freedom\nMultiple R-squared:  0.9796,    Adjusted R-squared:  0.9749 \nF-statistic: 209.5 on 11 and 48 DF,  p-value: < 2.2e-16\n\n\n\n해석 : sin_2.4 하나 유의하지 않다고 나옴(별표) 원래 sin, cos함수는 1부터 -1까지 갖는데 Estimate 나온 숫자만큼 진폭을 줄여주거나 늘려줌.\n\n\ntmp.data_sub[, day := tmp.data$day]\ntmp.data_sub[, fitted_lndep := fitted(reg_2)]\n\n\nggplot(tmp.data_sub, aes(day, lndep)) + \ngeom_line(col = 'skyblue', lwd = 1) +\ngeom_line(aes(day, fitted_lndep), col = 'orange', lwd = 1) +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n\n\n\ntmp.data_sub[, res := resid(reg_2)]\nggplot(tmp.data_sub, aes(day, res)) +\ngeom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\nscale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\ntheme_bw() +\ntheme(axis.title = element_blank())\n\n\n\n\n\n해석 : 1차 음의 자기상관관계가 있다. 다른 것보다 등분산성의 문제가 있어보인다.(그저 보기에) = 독립성문제\n\n\n\n\n\ndwtest(reg_2)\ndwtest(reg_2, alternative = \"two.side\")\ndwtest(reg_2, alternative = \"less\")\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 1.269e-06\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n    Durbin-Watson test\n\ndata:  reg_2\nDW = 3.2703, p-value = 6.346e-07\nalternative hypothesis: true autocorrelation is less than 0\n\n\n\nalternative 안 쓰면 default는 greater다 첫 번째 4에가까운 값이 나오면 two.side, less 둘 다 해보는게 좋음. two.side 결과보면 0이 아니다. -> 기각 less 결과보면 ’음의 상관관계가 있다’의 결과 p-value가 매우 작아 기각할 수 있다."
  },
  {
    "objectID": "posts/regression/2022-08-10_회귀분석.html",
    "href": "posts/regression/2022-08-10_회귀분석.html",
    "title": "회귀분석",
    "section": "",
    "text": "기초통계이론, 선형회귀, 중회귀\n\n배운 내용정리\n\n\nlibrary('tidyverse')\n\n\n\n\n\n\nex1 <- tribble(\n    ~x, ~y,\n    1, 150,\n    2, 160,\n    3, 170,\n    4, 150,\n    5, 140,\n    6, 160,\n    7, 190\n    )\n\n\nex1\n\n\n\nA tibble: 7 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    1150\n    2160\n    3170\n    4150\n    5140\n    6160\n    7190\n\n\n\n\n\nhistplot\n\n\nex1$y %>% hist()\n\n\n\n\n\n히스토그램은 계급 구간의 수가 중요하다(보통 10개 내외 사용)\n\n\nboxplot\n\n\nex1$y %>% boxplot()\n\n\n\n\n맨 위아래 가로바 밖은 이상치(outlier)들 박스 맨 아래는 Q1, 가운데 선은 Q2(평균), 박스 맨 위는 Q3를 의미한다. 이 때 Q3-Q1 = h라고 하며 맨 위의 가로바, 맨 아래의 가로바는 각각 Q3 + 1.5h, Q1 - 1.5h인 지점이다.\n\n\n\n모수(parameter) : 모집단이나 변수의 통계적 특성을 어떤 수치로 표현한 것 모수의 예로는 모집단의 중심위치를 나타내는 평균, 중간값, 최빈값과 값들이 중심에서 퍼져있는 정도, 즉 산포도를 나타내는 범위, 편차, 표준편차, 분산등이 있다. 이들 모수의 값은 대부분의 경우 알려져 있지 않으므로 표본을 이용하여 이들 값을 추정하게 된다.  통계랑(statisic) : 모수에 대응하여 표본의 특성을 잘 나타내는 수치 통계량은 표본을 이용하여 계산되므로 각 모수에다 ’표본’을 붙여 통계량을 나타낸다.ex) 표본 평균, 표본 분산 두 개 이상의 변수들의 관계에 대한 측도로는 공분산과 상관계수 등이 사용된다.\n\n\n\n확률변수(random variable) : 분석대상인 변수들이 갖는 각 결과에 하나의 실수값을 대응시켜주는 함수 확률(random)의 의미 : 확률변수의 값은 실제로 관측하기 전에는 어떠한 값이 될지 알 수 없다 확률분포(probability distribution) : 확률변수의 모든 가능한 값에 확률을 대응시킨 것 확률분포는 이산확률변수의 경우 표, 그림, 수식으로 나타내어지고, 연속확률변수의 경우 그림, 수식으로 주어진다.\n\n\n\\(E[Y] = \\sum\\limits_{i=1}^d{y_if_Y(y_i)}\\)\n기댓값은 다음과 같이 정의 되는데 위의 의미는 이산확률변수 Y의 기댓값은 \\(f_y(y_i)\\)가 가중치로 주어지는 가중평균이라는 것이다.\n\n\n\n공분산(covariance)는 두 변수간의 선형관계를 나타내는 측도로 다음과 같이 정의된다.\n\\(cov(Y_1, Y_2) = E[(Y_1 - \\mu Y_1)(Y_2 - \\mu Y_2)]\\)\n\n\n\n\\(\\rho = \\frac{cov(Y_1, Y_2)}{\\sigma Y1, \\sigma Y2}\\)\n상관계수 \\(\\rho\\)는 다음과 같이 해석된다. > 1) \\(\\rho\\)는 변수의 종류나 특정단위에 관계없는 측도로 -1과 +1 사이의 값을 가지며, \\(\\rho\\)의 값이 +1에 가까울수록 강한 양의 상관관계를,-1에 가까울수록 강한 음의 상관관계를 나타내며, \\(\\rho\\)의 값이 0에 가까울수록 선형관계는 약해진다. 2) \\(Y_1\\)과 \\(Y_2\\)의 대응되는 모든 값들이 한 직선 상에 위치하면 \\(\\rho\\)의 값은 -1이나 +1의 값을 가진다. 3) 상관계수 \\(\\rho\\)는 단지 두 변수간의 선형관계만을 나타내는 측도이다. 그러므로 \\(\\rho\\) = 0인 경우에 두 변수의 선형상관관계는 없지만 다른 관계는 가질 수 있다.\n\n\n\n여러가지 이산확률분포들 중에서 회귀분석과 관련이 있는 분포는 이항분포(binomial distribution)와 포아송분포(poisson distribution)이다. 먼저 이항분포는 베르누이 시행(bernoulli trial)에 의해 정의되는데, 어느 실험이 1) 오직 두 가지의 가능한 결과만을 가지고, 2) 매 번 시행에서 성공의 확률이 같아야 하며, 3) 각 시행은 서로 독립이라는 세 가지 조건을 만족하면 이를 베르누이 시행이라 한다.\n동전던지기(앞 or 뒤), 품질검사(양품 or 불량품)가 이에 해당한다. 보통 일반적으로 베르누이 시행의 결과를 성공과 실패로 나타낸다.\n이항분포 : 베르누이 시행을 독립적으로 n번 반복할 때 나타나는 성공의 개수가 갖는 확률분포\n포아송분포 : 단위 시간당 또는 단위 영역당 발생하는 사건의 횟수를 나타내기 위한 분포\n예를들어, 어느 시간대에 가게에 찾아오는 고객의 수, 어느 도시에서 하루동안 발생하는 교통사고의 수 등은 포아송분포를 따른다. 사건발생 평균횟수가 \\(\\lambda\\)인 포아송분포를 따르는 확률변수 Y의 확률분포는 다음과 같이 주어진다.\n\\(f(y) = \\frac{e^{-\\lambda}\\lambda^y}{y!}\\)\n포아송분포의 특성은 평균과 분산이 모두 \\(\\lambda\\)로 같다.\n\n\n\n- 정규분포의 대표적인 성질 하나의 정규분포를 따르는 확률변수의 선형함수 역시 정규분포를 따른다. 즉, 확률변수 Y가 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2\\)인 정규분포를 따를 때 선형함수 a + bY는 평균이 a + \\(b\\mu\\)이고 분산이 \\(b^2\\sigma^2\\)인 정규분포를 따른다. 이것 때문에 표준화가 가능함.\n정규분포는 통계학에서 가장 많이 사용되는 확률분포이다. 그러나 모순적인 것은 정규분포를 정확하게 따르는 변수는 현실적으로 없다는 것이다. 왜냐하면 정규분포는 우선(-\\(\\infty\\), \\(\\infty\\))에서 정의되어야하고, 모든 구간에서의 확률이 0보다 커야 한다는 조건이 주어지기 때문이다. 그러므로 이를테면 항상 양수값만을 갖는 학생들의 신장이 정규분포를 따른다고 가정하는 것은 엄격하게 보면 잘못된 것일 수 있다. 그렇지만 이 가정이 타당성을 갖는 이유는 정규분포에서는 (\\(\\mu -3\\sigma, \\mu +3\\sigma\\))정도의 구간에 99.74%라는 거의 모든 확률이 포함되어 있기 때문이다. 신장의 경우 표준편차 \\(\\sigma\\)가 아주 크지 않는 경우에는 음수부분은 거의 확률이 존재하지 않는 것으로 보아도 무방하게 된다.\n중심극한정리(central limit theorem) : 확률변수 \\(Y1, Y2, ..., Y_n\\)들이 평균이 \\(\\mu\\)이고 분산이 \\(\\sigma^2 < \\infty\\)인 확률분포를 따르며  서로 독립일 때, 표본의 크기 n이 적당히 크면 표본평균의 분포는 근사적으로 정규분포에 가까워진다."
  },
  {
    "objectID": "posts/time-series/2022-10-05-시계열자료분석-학습2.html",
    "href": "posts/time-series/2022-10-05-시계열자료분석-학습2.html",
    "title": "(수업) 시계열 자료분석 실습 2",
    "section": "",
    "text": "평활법(MA, 단순지수, 이중지수, Holt-Winter)\n\nlibrary('tidyverse')\nlibrary('forecast')\nlibrary('lmtest')\nlibrary('TTR')# SMA\nlibrary('data.table')\nlibrary('gridExtra')\n\n\nkings = scan(\"https://robjhyndman.com/tsdldata/misc/kings.dat\", skip = 3) # 영국 왕 수명 데이터\n\n\nkingstimeseries = ts(kings)\nplot.ts(kingstimeseries)\n\n\n\n\n\n\n\n윈도우 크기가 3인 Moving Averages 원래 데이터에 평활한 거 같이 그려짐\n\n\nkingstimeseriesSMA3 <- SMA(kingstimeseries, n = 3)\nplot.ts(kingstimeseries)\nlines(kingstimeseriesSMA3, col = 'red', lty = 2)\nlines(SMA(kingstimeseriesSMA3, n = 10), col = 'blue', lty = 2) # window 10개짜리\n\n\n\n\n\n\n\ntmp.dat <- data.table(kings = kings,\n                      t = 1:length(kings))\ntmp.dat[, sma3 := SMA(kingstimeseries, n = 3)]\ntmp.dat[, sma10 := SMA(kingstimeseries, n = 10)]\n\nggplot(tmp.dat, aes(t, kings)) + geom_line(col = 'skyblue') +\ngeom_point(col = 'steelblue') +\ntheme_bw() +\ntheme(axis.title.x = element_blank())\n\n\n\n\n\nmelt.tmp <- melt(tmp.dat, id = 't')\n\nggplot(melt.tmp, aes(t, value, col = variable, size = variable, lty = variable)) +\ngeom_line() +\ntheme_bw() +\nlabs(col = \"\") +\nscale_linetype_manual(values = c('solid', 'twodash', 'dashed')) +\nscale_color_manual(values = c('black', 'orange', 'steelblue')) +\nscale_size_manual(values = c(0.2, 1.2, 1.2)) +\nguides(lty = 'none', size = 'none') +\ntheme(axis.title.x = element_blank())\n\nWarning message:\n“Removed 11 row(s) containing missing values (geom_path).”\n\n\n\n\n\n\n모형을 평가하는 수치들 위의 3개는 window를 3개 가져갔을 때의 MSE들 아래 3개는 window를 10개 가져갔을 때의 MSE들\n\n\nmean((tmp.dat$kings- tmp.dat$sma3)^2, na.rm=T) ##MSE\nmean(abs(tmp.dat$kings- tmp.dat$sma3), na.rm=T) ##MAE\nmean(abs((tmp.dat$kings- tmp.dat$sma3)/tmp.dat$kings), na.rm=T)*100 ##MAPE\n\nmean((tmp.dat$kings- tmp.dat$sma10)^2, na.rm=T) ##MSE\nmean(abs(tmp.dat$kings- tmp.dat$sma10), na.rm=T) ##MAE\nmean(abs((tmp.dat$kings- tmp.dat$sma10)/tmp.dat$kings), na.rm=T)*100 ##MAPE\n\n128.752777777778\n\n\n9.025\n\n\n22.4739949863572\n\n\n229.22\n\n\n12.5272727272727\n\n\n31.8798030034434\n\n\n\n다른 자료\n\n\nz <- scan('mindex.txt')\nmindex <- ts(z, start = c(1986, 1), frequency = 12)\nmindex\n\n\n\nA Time Series: 9 × 12\n\n    JanFebMarAprMayJunJulAugSepOctNovDec\n\n\n    1986 9.310.713.314.117.818.119.418.819.118.418.017.0\n    198719.520.119.415.715.616.114.916.014.618.318.223.0\n    198822.222.118.817.713.812.716.515.616.310.710.4 7.0\n    1989 4.7 4.5 4.0 6.0 6.2 5.7 4.4 4.2 5.0 5.8 6.4 4.9\n    1990 7.9 8.211.810.011.111.712.415.214.015.212.918.0\n    199114.412.7 8.311.511.911.610.3 8.511.612.314.511.1\n    199211.812.412.7 9.810.010.2 9.6 6.9 5.3 4.8 4.6 1.9\n    1993 3.8 4.7 7.7 7.0 7.2 7.8 8.611.410.711.811.316.0\n    199413.212.0 8.511.4                                \n\n\n\n\n\ntmp.dat <- data.table(ind = z,\n                      t = 1:length(z))\n\ntmp.dat[, sma3 := SMA(mindex, n = 3)]\ntmp.dat[, sma10 := SMA(mindex, n = 10)]\n\nggplot(tmp.dat, aes(t, ind)) + geom_line(col = 'skyblue', size = 1) +\ngeom_point(col = 'steelblue') +\ntheme_bw() +\ntheme(axis.title.x = element_blank())\n\n\n\n\n\nwindow 3개, 10개 나눠서 합쳐서 그리기\n\n\n\n\n\n\nz <- scan(\"mindex.txt\")\n\nmindex <- ts(z, start = c(1986, 1), frequency = 12)\n\ntmp.dat <- data.table(day = seq.Date(as.Date(\"1986-01-01\"), \n                                     by='month', \n                                     length.out=length(z)),\n                      ind = z)\nhead(tmp.dat)\n\nggplot(tmp.dat, aes(day, ind))+geom_line(col='skyblue') +\n  geom_point(col='steelblue')+\n  ggtitle(\"Intermediate shipment index\")+\n  theme_bw()+\n  theme(plot.title = element_text(size=20),\n        axis.title = element_blank())\n\n\n\nA data.table: 6 × 2\n\n    dayind\n    <date><dbl>\n\n\n    1986-01-01 9.3\n    1986-02-0110.7\n    1986-03-0113.3\n    1986-04-0114.1\n    1986-05-0117.8\n    1986-06-0118.1\n\n\n\n\n\n\n\n\n평균 = level이라 표현함 예를 들어) 상수평균모형같은 경우 level이 시간에 상관없이 일정하다. 단순지수평활에서는 level이 국지적으로 비슷하지만 전체적으로 보면 변화한다. alpha가 level을 평활할 때 쓰는 평활상수의미\n\n\n### 단순지수평활 alpha=0.9\n\n\nHoltWinters는 단순지수, 이중지수, 계절평활 3가지 다 가능 이번에는 단순지수평활이라 기울기, 계절성분을 안 쓸거라서 FALSE해줬음.\n\n\nfit0 <- HoltWinters(mindex, \n                    alpha = 0.9, # 레벨\n                    beta = FALSE, # 기울기에 대한 평활상수\n                    gamma = FALSE) # 계절성분에 대한 평활상수\nls(fit0) # 어떤 정보 값들 가지는 지 보여줌\n\n\n'alpha''beta''call''coefficients''fitted''gamma''seasonal''SSE''x'\n\n\n\n그 중에서 SSE 보고싶어서 SSE 선택\n\n\nfit0$SSE\n\n437.636076191925\n\n\n\nses는 단순지수 평활만 사용가능\n\n\nfit01 <- ses(mindex, \n             alpha = 0.9, # 사실 알파 안써도 얘가 적당히 넣어주긴함\n             initial = 'simple',\n             h = 10) # 앞으로 몇 개 더 예측해줄지 개수 설정\nls(fit01)\n\n\n'fitted''level''lower''mean''method''model''residuals''series''upper''x'\n\n\n\nsummary(fit01)\n\n\nForecast method: Simple exponential smoothing\n\nModel Information:\nSimple exponential smoothing \n\nCall:\n ses(y = mindex, h = 10, initial = \"simple\", alpha = 0.9) \n\n  Smoothing parameters:\n    alpha = 0.9 \n\n  Initial states:\n    l = 9.3 \n\n  sigma:  2.092\nError measures:\n                     ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.02051593 2.091975 1.614844 -2.575694 16.57215 0.2947652\n                    ACF1\nTraining set -0.01462494\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80       Lo 95    Hi 95\nMay 1994       11.14643 8.465459 13.82741  7.04623710 15.24663\nJun 1994       11.14643 7.539551 14.75332  5.63018345 16.66268\nJul 1994       11.14643 6.806897 15.48597  4.50968590 17.78318\nAug 1994       11.14643 6.181200 16.11167  3.55276359 18.74010\nSep 1994       11.14643 5.625970 16.66690  2.70361248 19.58925\nOct 1994       11.14643 5.121693 17.17117  1.93238821 20.36048\nNov 1994       11.14643 4.656482 17.63638  1.22090910 21.07196\nDec 1994       11.14643 4.222457 18.07041  0.55712575 21.73574\nJan 1995       11.14643 3.814079 18.47879 -0.06743481 22.36030\nFeb 1995       11.14643 3.427276 18.86559 -0.65899942 22.95187\n\n\n\n해석 : ME, RMSE … 등 알려줌. Forecasts 보면 Point Forecast는 점 추정량으로서 각각의 level에 대한 예측값 그 옆은 80% 신뢰수준으로 상한, 하한 또 그 옆은 95% 신뢰수준으로 상한, 하한을 나타낸다. 참고) Point Forecast가 전부 같은 값으로 나오는 이유는 예를 들어 100번째 데이터까지를 바탕으로 결과를 도출한다면 어짜피 100개의 결과를 바탕으로 예측한 것이기에 바뀔 이유가 없다. 하지만 신뢰구간은 시간이 지날수록 믿을 수 없는 값이 많아지기 때문에(변동 증가) 시간이 지남에 따라 구간이 커진다.\nholt는 이중지수 평활에서 사용\n\n\nfit02 <- holt(mindex, \n              alpha = 0.9,\n              beta=0, # 기울기\n              phi=0,\n              initial ='simple',\n              h = 10)\nls(fit02)\n\n\n'fitted''level''lower''mean''method''model''residuals''series''upper''x'\n\n\n\nsummary(fit02)\n\n\nForecast method: Holt's method\n\nModel Information:\nHolt's method \n\nCall:\n holt(y = mindex, h = 10, initial = \"simple\", alpha = 0.9, beta = 0,  \n\n Call:\n     phi = 0) \n\n  Smoothing parameters:\n    alpha = 0.9 \n    beta  = 0 \n    phi   = 0 \n\n  Initial states:\n    l = 9.3 \n    b = 1.4 \n\n  sigma:  2.092\nError measures:\n                     ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.02051593 2.091975 1.614844 -2.575694 16.57215 0.2947652\n                    ACF1\nTraining set -0.01462494\n\nForecasts:\n         Point Forecast    Lo 80    Hi 80       Lo 95    Hi 95\nMay 1994       11.14643 8.465459 13.82741  7.04623710 15.24663\nJun 1994       11.14643 7.539551 14.75332  5.63018345 16.66268\nJul 1994       11.14643 6.806897 15.48597  4.50968590 17.78318\nAug 1994       11.14643 6.181200 16.11167  3.55276359 18.74010\nSep 1994       11.14643 5.625970 16.66690  2.70361248 19.58925\nOct 1994       11.14643 5.121693 17.17117  1.93238821 20.36048\nNov 1994       11.14643 4.656482 17.63638  1.22090910 21.07196\nDec 1994       11.14643 4.222457 18.07041  0.55712575 21.73574\nJan 1995       11.14643 3.814079 18.47879 -0.06743481 22.36030\nFeb 1995       11.14643 3.427276 18.86559 -0.65899942 22.95187\n\n\n\n해석: HoltWinters의 경우 원래 Point Forecast의 첫 칸 비워져서 나오는데 여기서는 0을 일부러 넣어서 칸 맞춤\n\n\nfit_data <- data.table(\n  fit_HoltWinters = c(0,fit0$fitted[,'xhat']),\n  fit_ses = fit01$fitted,\n  fit_holt = fit02$fitted\n)\n\nhead(fit_data)\n\n\n\nA data.table: 6 × 3\n\n    fit_HoltWintersfit_sesfit_holt\n    <dbl><ts><ts>\n\n\n     0.00000 9.30000 9.30000\n     9.30000 9.30000 9.30000\n    10.5600010.5600010.56000\n    13.0260013.0260013.02600\n    13.9926013.9926013.99260\n    17.4192617.4192617.41926\n\n\n\n\n\n\n\n평활지수 0.2, 0.9썼을 때 평활이 얼마나 달라지나?\n\n\ntmp.dat[, ses_0.2 := ses(mindex, alpha = 0.2)$fitted]\ntmp.dat[, ses_0.9 := ses(mindex, alpha = 0.9)$fitted]\n\nmelt.tmp <- melt(tmp.dat, id='day')\n\nggplot(melt.tmp, aes(day, value, col=variable, size=variable, lty=variable))+\n  geom_line() +\n  xlab(\"\")+ylab(\"\")+\n  theme_bw()+\n  scale_linetype_manual(values=c('solid',\"dashed\",\"dashed\" ))+\n  scale_color_manual(values=c('black','orange', 'steelblue'))+\n  scale_size_manual(values=c(0.2,1.2,1.2))+\n  guides(lty = 'none', size='none')+\n  theme(legend.position = c(0.85,0.8)) +\n  theme(legend.background = element_rect(linetype=\"solid\", \n                                         colour =\"darkblue\"))+\n  theme(legend.title = element_blank())\n\n\n\n\n\n\n\n최적의 평활상수 = SSE를 최소화 시켜주는 값\n\n\nw <-c(seq(0.1,0.8,0.1), \n      seq(0.81, 0.99, 0.01)) # weight\n\nsse <- sapply(w, function(x) \n  return(sum(ses(mindex, alpha = x)$residuals^2)))\n\n\nsse %>% head\n\n\n1459.644692556371010.03396147245768.279992410308630.729514475135547.181483975014494.617442566588\n\n\n\nw[which.min(sse)]  # 최적 평활상수값\nfit1 <- ses(mindex, alpha=w[which.min(sse)], h=6)\n\n0.9\n\n\n- 예측모형 plot\n\nw1 = w[-c(1:6)]  # xaxis from 0.7 to 1.0\nsse1 = sse[-c(1:6)]\nplot(w1,sse1, type=\"o\", xlab=\"weight\", ylab=\"sse\", pch=16,\n     main=\"Sum of squares of prediction error after 1 lag\")\n\n\n\n\n\n\n\n\nt.test(resid(fit1), mu=0)\n\n\n    One Sample t-test\n\ndata:  resid(fit1)\nt = 0.088676, df = 99, p-value = 0.9295\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.3985116  0.4357973\nsample estimates:\n mean of x \n0.01864288 \n\n\n\n해당 ses의 잔차 출력한 것에 평균 0인지 t.test검증\n\n\nalpha = 0.9\n\n\nplot(fit1, xlab=\"\", ylab=\"\", \n     main=\"Intermediate Goods Shipment Index and Simple Exponential Smoothing Value alpha=0.9\", \n     lty=1,col=\"black\" )\nlines(fitted(fit1), col=\"red\", lty=2)\nlegend(\"topright\", legend=c(\"Mindex\", \"alpha=0.9\"), \n       lty=1:2,col=c(\"black\",\"red\"))\n\n\n\n\n\n마지막 보면 파란색 줄로 쭉 이어지는게 더 이상 추가해줄 데이터가 없어서 예측이 같게 이어지는 거임. 하지만 시간이 지남에 따라 신뢰구간은 늘어나기에 범위적으로 늘어나는 표현이 일어남 마지막 자세히 보면 빨간 점선이 검은 선보다 아래에 있다. alpha = 0.9라는 것은 최근 실제 정보를 9만큼, 예측값을 1만큼 내분한 점을 표현하는 것이기에 보면 파란색 줄은 검은선보다 10%정도만큼 살짝 내려온 곳에 위치하게 된다.\n\n\nplot(fit1$residuals, ylab=\"residual\",\n     main=\"Time Series Plot of Prediction Errors : alpha=0.9\"); abline(h=0)\n\n\n\n\n\nalpha = 0.2\n\n\nfit2 <- ses(mindex, alpha=0.2, h=6) \nplot(fit2, xlab=\"year\", ylab=\"mindex\", \n     main=\"Intermediate Goods Shipment Index and Simple Exponential Smoothing Value alpha=0.2\", \n     lty=1,col=\"black\")\nlines(fitted(fit2), col=\"red\", lty=2)\nlegend(\"topright\", legend=c(\"Mindex\",\"alpha=0.2\"), \n       lty=1:2,col=c(\"black\",\"red\"))\n\n\n\n\n\nplot(fit2$residuals, ylab=\"residual\",\n     main=\"Time Series Plot of Prediction Errors : alpha=0.2\"); abline(h=0)\n\n\n\n\n\n\n\n\n\nround(rbind(accuracy(fit1), accuracy(fit2)), digit=3)\n\n\n\nA matrix: 2 × 7 of type dbl\n\n    MERMSEMAEMPEMAPEMASEACF1\n\n\n    Training set 0.0192.0921.616 -2.59616.5890.295-0.015\n    Training set-0.1623.1782.595-13.10430.6500.474 0.736\n\n\n\n\n\n\n\n\nfit3 <- ses(mindex,h=6)\nfit3$model\n\nSimple exponential smoothing \n\nCall:\n ses(y = mindex, h = 6) \n\n  Smoothing parameters:\n    alpha = 0.9031 \n\n  Initial states:\n    l = 9.4594 \n\n  sigma:  2.1131\n\n     AIC     AICc      BIC \n614.1310 614.3810 621.9466 \n\n\n\nalpha 따로 입력안하면 알아서 최적으로 생각하는 alpha 입력해줌 여기서는 Smoothing parameters : alpha = 0.9031로 해줌.\n\n\nplot(fit3, xlab=\"\", ylab=\"\", main=\"\",\n     # main=\"중간재 출하지수와 단순지수평활값 : alpha estimated\", \n     lty=1, col=\"black\")\nlines(fit3$fitted, col = \"red\", lty = 2)\nlegend(\"topright\", legend=c(\"Mindex\",\"estimated alpha\"), \n       lty=1:2,col=c(\"black\",\"red\"))\nplot(fit3$residuals, ylab=\"residual\",  \n     main=\"Time Series Plot of Prediction Errors : estimated alpha\"); abline(h=0)\n\n\n\n\n\n\n\n\n\n\n\n\nz <- scan(\"stock.txt\") \nstock <- ts(z, start=c(1984,1), frequency=12)\n\ntmp.data <- data.table(\n  day = seq.Date(as.Date(\"1984-01-01\"), \n                 by='month', length.out=length(z)),\n  z=z  \n)\n\nggplot(tmp.data, aes(day, z)) + geom_line(col='skyblue') +\n  geom_point(col='steelblue')+\n  # scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y-%m\") +\n  theme_bw()+ggtitle(\"monthly stock index\")+\n  theme(plot.title = element_text(size=20),\n        axis.title = element_blank())\n\n\n\n\n\n전체적으로 증가하는 추세라고 볼 수도 있지만 증가하다가 감소하다 다시 잠잠해지는 즉, 일반적인 선형추세모형을 사용하기는 어렵다.\n\n\nplot.ts(stock, main = 'monthly stock index')\n\n\n\n\n\n\n\nalpha, beta 동일하게 사용하므로 1모수\n\n\nfit4 = holt(stock, alpha=0.6, beta=0.6, h=6) \nfit4$model\n\nHolt's method \n\nCall:\n holt(y = stock, h = 6, alpha = 0.6, beta = 0.6) \n\n  Smoothing parameters:\n    alpha = 0.6 \n    beta  = 0.6 \n\n  Initial states:\n    l = 115.6009 \n    b = 6.8098 \n\n  sigma:  40.2546\n\n     AIC     AICc      BIC \n1149.575 1149.836 1157.268 \n\n\n\nplot(fit4, ylab=\"\", xlab=\"\",  lty=1, col=\"black\",\n     main=\"Stock index and double exponential smoothing: alpha=beta=0.6\"\n     )\nlines(fitted(fit4), col=\"red\", lty=2)\nlegend(\"topleft\", lty=1:2, col=c(\"black\",\"red\"), c(\"Index\", \"Double\"), bty = \"n\")\n\n\n\n\n\n뒤에 예측한 것을 보면 마지막 시점에서 추세가 아래로 내려가고 있으므로 쭉 내려가는 것으로 예측이 된거임. 딱히 예측에 좋은 거 같지는 않음.\n\n\nplot(resid(fit4), main=\"Time series plot of forecasting error\"); abline(h=0)\n\n\n\n\n\n\n\n\nalpha, beta 선택하지 않으면 알아서 선택해서 돌려줌.\n\n\nfit5 = holt(stock, h=6)\nfit5$model\n\nHolt's method \n\nCall:\n holt(y = stock, h = 6) \n\n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.1071 \n\n  Initial states:\n    l = 124.1137 \n    b = 3.4954 \n\n  sigma:  31.8609\n\n     AIC     AICc      BIC \n1108.677 1109.343 1121.498 \n\n\n\n여기서는 0.999, 0.1로 선택됨.\nbeta를 0.6으로 쓸 때보다는 기울기가 훨씬 완만한 모습을 보인다.\n\n\nplot(fit5, ylab=\"Index\", xlab=\"year\",  lty=1, col=\"black\",\n     main=\"Intermediate Goods Shipment Index and Double Exponential Smoothing Value : alpha, beta estimated\")\nlines(fitted(fit5), col=\"red\", lty=2)\nlegend(\"topleft\", lty=1:2, col=c(\"black\",\"red\"), c(\"Index\", \"Double\"))\n\n\n\n\n\nplot(resid(fit5), main=\"Time series plot of forecasting error: alpha, beta estimated\")\nabline(h=0)\n\n\n\n\n\n\n\n\n- 항공사 데이터 사용\n\nz <- scan(\"koreapass.txt\")\npass <- ts(z, start=c(1981,1), frequency=12) \n\nplot.ts(pass)\n\ntmp.data <- data.table(\n  day = seq.Date(as.Date(\"1981-01-01\"), \n                 by='month', length.out=length(z)),\n  z=z  \n)\n\n\n\n\n\n보면 분산이 점점 증가하는 형태이기에 평활모형에서 승법모형을 사용해야 한다. or 로그변환한 가법모형사용\n\n\n\n\n가법이면 seasonal=\"additive\" 승법이면 seasonal=\"multiplicative\"\n\n\nfit6 = hw(pass, seasonal=\"additive\", h=12) # 1년 예측이라 12\nfit6$model\n\nHolt-Winters' additive method \n\nCall:\n hw(y = pass, h = 12, seasonal = \"additive\") \n\n  Smoothing parameters:\n    alpha = 0.5963 \n    beta  = 0.0177 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 129763.5823 \n    b = 799.4119 \n    s = -29016.96 -855.2679 13617.18 -4624.62 37697.04 16768.22\n           9720.317 14214.29 317.4589 -5632.175 -31459.7 -20745.79\n\n  sigma:  11509.58\n\n     AIC     AICc      BIC \n2542.155 2548.955 2587.751 \n\n\n\nalpha, beta, gamma 따로 입력하지 않았으므로 알아서 해줌.\n\n\nplot(fit6,  ylab=\"passenger\", xlab=\"year\", lty=1, col=\"blue\",\n     main=\"Winters Additive Seasonal Exponential plot of Smooth Material\")\nlines(fit6$fitted, col=\"red\", lty=2)\nlegend(\"topleft\", lty=1:2, col=c(\"blue\",\"red\"), c(\"Pass\", \"Additive\"),  bty = \"n\")\n\n\n\n\n\nts.plot(resid(fit6), ylab=\"residual\", \n        main=\"Prediction error of additive model\"); abline(h=0)\n\n\n\n\n\ndwtest(lm(resid(fit6)~1), alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  lm(resid(fit6) ~ 1)\nDW = 2.0779, p-value = 0.683\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n더빈왓슨에서 ~1의 형태로 하면 상수평활형태로 결과 나옴. 여튼저튼 잔차 그 자체의 결과로 나오게 됨.\n\n\n\n\n\nfit7= hw(pass, seasonal=\"multiplicative\",h=12) \nfit7$model\n\nHolt-Winters' multiplicative method \n\nCall:\n hw(y = pass, h = 12, seasonal = \"multiplicative\") \n\n  Smoothing parameters:\n    alpha = 0.4231 \n    beta  = 0.1209 \n    gamma = 0.0014 \n\n  Initial states:\n    l = 128311.2252 \n    b = 914.1471 \n    s = 0.8553 0.9918 1.0572 0.9742 1.1913 1.0935\n           1.0469 1.0668 0.9952 0.9699 0.8389 0.9189\n\n  sigma:  0.051\n\n     AIC     AICc      BIC \n2506.102 2512.902 2551.699 \n\n\n\nplot(fit7,  ylab=\"passenger\", xlab=\"year\", lty=1, col=\"blue\",\n     main=\"Winters Time series plot of multiplicative seasonal exponential smoothed data\")\nlines(fit7$fitted, col=\"red\", lty=2)\nlegend(\"topleft\", lty=1:2, col=c(\"blue\",\"red\"), c(\"Pass\", \"Multiplicative\"),  bty = \"n\")\n\n\n\n\n\n해석 : 가법모형에서는 예측 구간에서 앞에 있는 것을 붙여 놓은 것 마냥, 사실 분산이 점점 증가하고 있기에 예측 구간의 폭도 같이 늘어나야 하는데 그렇지 못한 반면, 승법모형의 경우 분산이 커지는 것을 고려해서 진폭이 커지는 형태를 표현해준다.\n\n\nts.plot(z-fit7$fitted, ylab=\"residual\", \n        main=\"Prediction error of multiplicative model\"); abline(h=0)\n\n\n\n\n\ndwtest(lm(resid(fit7)~1), alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  lm(resid(fit7) ~ 1)\nDW = 1.6079, p-value = 0.03973\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n\n\nsmoothing을 하려고 할 때 살펴 보아야 할 것 level만 있다면 -> ses trend가 있다면 -> holt seasonality가 있다면 -> hw 그 중에서도 가법쓸 지, 승법 쓸 지"
  },
  {
    "objectID": "posts/time-series/2022-10-08-시계열자료분석-학습3.html",
    "href": "posts/time-series/2022-10-08-시계열자료분석-학습3.html",
    "title": "(수업) 시계열 자료분석 실습 3",
    "section": "",
    "text": "분해법 - 가법모형, 승법모형, 이동평균(단순, 중심, stl, decompose)\n\nlibrary('tidyverse')\nlibrary('TTR')\nlibrary('forecast')\nlibrary('lmtest')\n\n\n\n\nz <- scan(\"food.txt\")\nt <- 1:length(z)\nfood <- ts(z, start = c(1981, 1), frequency = 12)\n\n\nplot.ts(food)\n\n\n\n\n\n\n\n승법모형 써도 되지만 여기서는 로그변환하고 가법모형 사용할 예정\n\n\nlog_food <- log(food)\nplot.ts(log_food)\n\n\n\n\n\n\n\n\nfit <- lm(log_food ~ t)\nsummary(fit)\n\n\nCall:\nlm(formula = log_food ~ t)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.251154 -0.042190  0.009368  0.051058  0.147910 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 3.705715   0.012870  287.94   <2e-16 ***\nt           0.007216   0.000154   46.86   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.07682 on 142 degrees of freedom\nMultiple R-squared:  0.9393,    Adjusted R-squared:  0.9388 \nF-statistic:  2195 on 1 and 142 DF,  p-value: < 2.2e-16\n\n\n\n해석 : p-value보면 유의하고 R-squared도 매우 높게 나옴.\n\n\ntrend <- fitted(fit)\n\n\nts.plot(log_food, trend, col = 1:2, lty = 1:2, lwd = 1:2, ylab = \"food\", xlab = \n        \"Log-transformed time series and trend component by decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"ln(z)\", \"trend component\"))\n\n\n\n\n\n\n\n\n추세성분을 구했으니 원래데이터에서 추세성분을 빼준다. 그러면 계절성분과 불규칙성분만 남음. 거기서 계절성분까지 빼주려면 계절성분도 구해야한다.\n\n\nadjtrend = log_food-trend\nplot.ts(adjtrend)\n\n\n\n\n\n\n\n\n계절성분에 추세법을 이용하기 위해서는 sin함수 이용하거나 지시함수를 이용하면되는데 여기서는 지시함수 이용함. 사이클 자체를 설명변수로 넣을거임. 근데 여기서 cycle은 숫자가 아니라 1월, 2월의 의미이기에 factor형으로 바꿔준다. factor형으로 바꿔주면 Level이 생김.\n\n\ny = factor(cycle(adjtrend))\ny\n\n\n123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112123456789101112\n\n\n    \n        Levels:\n    \n    \n    '1''2''3''4''5''6''7''8''9''10''11''12'\n\n\n\n\n지시함수를 사용하기 위해 여기서는 intercept를 0으로 놓았음.\n\n\nfit1 <- lm(adjtrend ~ 0 + y)\nsummary(fit1)\n\n\nCall:\nlm(formula = adjtrend ~ 0 + y)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.182321 -0.028501  0.000597  0.025663  0.146887 \n\nCoefficients:\n    Estimate Std. Error t value Pr(>|t|)    \ny1  -0.06883    0.01423  -4.837 3.61e-06 ***\ny2  -0.13853    0.01423  -9.735  < 2e-16 ***\ny3  -0.01290    0.01423  -0.907 0.366289    \ny4   0.03840    0.01423   2.699 0.007872 ** \ny5   0.08825    0.01423   6.201 6.69e-09 ***\ny6   0.03871    0.01423   2.720 0.007401 ** \ny7   0.01061    0.01423   0.746 0.457221    \ny8   0.05972    0.01423   4.197 4.94e-05 ***\ny9   0.03776    0.01423   2.653 0.008945 ** \ny10 -0.01856    0.01423  -1.304 0.194518    \ny11 -0.05041    0.01423  -3.542 0.000549 ***\ny12  0.01577    0.01423   1.108 0.269816    \n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.0493 on 132 degrees of freedom\nMultiple R-squared:  0.6172,    Adjusted R-squared:  0.5824 \nF-statistic: 17.73 on 12 and 132 DF,  p-value: < 2.2e-16\n\n\n\nseasonal <- fitted(fit1)\nts.plot(seasonal, main = \"Estimated seasonal component\")\n\n\n\n\n\n\n\n\npred <- trend + seasonal\n\n\ntrend는 단순선형을 사용해서 구했고, seasoanl은 지시함수를 사용해서 구했음.\n\n\nts.plot(log_food, pred, col = 1:2, lty = 1:2, lwd = 1:2, ylab = \"food\", xlab = \"time\",\n        main=\"Estimated value by log-transformed time series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"ln(z)\", \"estimated value\"))\n\n\n\n\n\n\n\n\n최종적으로 잔차에 대해서 보려고 했기에 살펴보면\n\n\nirregular <- log_food - pred\nts.plot(irregular)\nabline(h = 0)\n\n\n\n\n\n겉 보기에 문제는 별로 없어보이지만 더빈왓슨 테스트를 해보면\n\n\ndwtest(lm(irregular ~ 1), alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  lm(irregular ~ 1)\nDW = 1.0803, p-value = 2.748e-08\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n자기상관관계가 있다고 나옴, 이런건 모델링을 해주어야하는데 5장 이후에 알려줌.\n\n\n\n\n\n\nplot.ts(food)\n\n\n\n\n\n\n\ntrend 잘 안잡힌것 같아서 t^2추가해도 됨. 이거 lm에 추가할 때 I()하고 넣어야 들어감. 바로 쓰면 추가 안됨.\n\n\nfit3 <- lm(food ~ t) #+ I(t^2))\nsummary(fit3)\n\n\nCall:\nlm(formula = food ~ t)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.0331  -3.4505  -0.1355   4.2911  15.3948 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 35.28614    0.95561   36.92   <2e-16 ***\nt            0.50557    0.01143   44.21   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 5.704 on 142 degrees of freedom\nMultiple R-squared:  0.9323,    Adjusted R-squared:  0.9318 \nF-statistic:  1955 on 1 and 142 DF,  p-value: < 2.2e-16\n\n\n\ntrend <- fitted(fit3)\n\n\nts.plot(food, trend, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Trend component by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"trend component\"))\n\n\n\n\n\n가법모형과 비슷해 보이지만 다름.\n\n\n\n\n\n나눠주면 계절성분과 불규칙 성분만 남음.\n\n\nadjtrend = food/trend\nplot.ts(adjtrend)\n\n\n\n\n\n\n\n\ny = factor(cycle(adjtrend))\n\n\n추세가 제거된 모형\n\n\nfit4 <- lm(adjtrend ~ 0+y)\nfit4 %>% summary\n\n\nCall:\nlm(formula = adjtrend ~ 0 + y)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.161461 -0.039085 -0.006972  0.032830  0.296240 \n\nCoefficients:\n    Estimate Std. Error t value Pr(>|t|)    \ny1   0.94148    0.01922   48.98   <2e-16 ***\ny2   0.87529    0.01922   45.54   <2e-16 ***\ny3   0.99012    0.01922   51.51   <2e-16 ***\ny4   1.04123    0.01922   54.17   <2e-16 ***\ny5   1.09340    0.01922   56.88   <2e-16 ***\ny6   1.04083    0.01922   54.15   <2e-16 ***\ny7   1.01069    0.01922   52.58   <2e-16 ***\ny8   1.06149    0.01922   55.22   <2e-16 ***\ny9   1.03869    0.01922   54.04   <2e-16 ***\ny10  0.98045    0.01922   51.01   <2e-16 ***\ny11  0.94939    0.01922   49.39   <2e-16 ***\ny12  1.01452    0.01922   52.78   <2e-16 ***\n---\nSignif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n\nResidual standard error: 0.06658 on 132 degrees of freedom\nMultiple R-squared:  0.996, Adjusted R-squared:  0.9956 \nF-statistic:  2733 on 12 and 132 DF,  p-value: < 2.2e-16\n\n\n\nseasonal <- fitted(fit4)\nts.plot(seasonal, main = \"Estimated seasonal component\")\n\n\n\n\n\n\n\n\npred <- trend * seasonal\n\n\nts.plot(food, pred, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Estimated value by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"estimated value\"))\n\n\n\n\n\n\n\n\nirregular <- food/pred\n\n\nts.plot(irregular)\nabline(h = 1, lty = 2)\n\n\n\n\n\ndwtest(lm(irregular ~ 1), alternative = 'two.sided')\n\n\n    Durbin-Watson test\n\ndata:  lm(irregular ~ 1)\nDW = 0.57136, p-value < 2.2e-16\nalternative hypothesis: true autocorrelation is not 0\n\n\n\n\n\n\n- 원래 데이터\n\nz <- scan('mindex.txt')\nmindex <- ts(z, start = c(1986, 1), frequency = 12)\nplot.ts(mindex)\n\n\n\n\n\n단순이동평균 : smoothing해주려고 사용 예를 들어 단순이동평균의 경우 window가 5라고 하면 앞에 4개는 결과가 없음. but, 중심이동평균은 5개이면 위는 4번째까지 합해서 5번째부터 결과 나타나는 식이라면 중심이동은 5개의 중심값 3번째부터 결과나옴. 좀 더 유연한 결과 예측에서는 사용 불가, 왜냐하면 5개의 경우 하나는 현재 2개는 과거 2개는 미래정보를 사용하기에\n\n\nplot.ts(mindex, ylab = \"\", xlab = \"\")\nlines(SMA(mindex, n = 5), col = 'red', lwd = 2) #처음 4개 안나오는 거 볼 수 있음\nlines(ma(mindex, order = 5), col = 'blue', lty = 2, lwd = 2) # 두칸 일찍 나오는 거 보임\nlegend('topright', lty = c(1,1,2), col = c('black', 'red', 'blue'),\n       lwd = c(1, 1, 2),\n       c('primitive series', \"SMA(m=5)\", \"CSMA(l=2)\"),\n       bty = 'n')\n\n\n\n\n\n\n\n\nplot.ts(log_food)\nlines(ma(log_food, 3), col = 'blue', lwd = 2)\nlines(ma(log_food, 12), col = 'red', lwd = 2) # 거의 추세만 남아버림.(왜냐면 12개씩이면 1년씩이 묶인거라 계절성이 없어짐)\n\n\n\n\n\n함수 stl, decompose 두개 다 사용가능\n\n\n\n\n원하는 3개의 성분으로 쪼개서 보여줌\n\n\nstl_fit1 <- stl(log_food, s.window = 12)\nstl_fit1$time.series %>% head\n\n\n\nA Time Series: 6 × 3\n\n    seasonaltrendremainder\n\n\n    Jan 1981-0.090355043.789108 0.09223150\n    Feb 1981-0.147931393.787232 0.04957932\n    Mar 1981-0.019896143.785355-0.03017285\n    Apr 1981 0.038295803.783478-0.04901299\n    May 1981 0.094538723.782254-0.04815173\n    Jun 1981 0.043787293.781031-0.01593573\n\n\n\n\n\nplot(stl_fit1)\n\n\n\n\n\n실제 예측값은 trend + seasonal\n\n\npred_stl <- stl_fit1$time.series[,1] + stl_fit1$time.series[,2]\n\nts.plot(log_food, pred_stl, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Estimated value by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"estimated value\"))\n\n\n\n\n\n\n\n\n밑에 additive써줬는데 안써도 되긴함.\n\n\ndec_fit <- decompose(log_food, 'additive')\ndec_fit$trend[1:10]\nma(log_food, 12)[1:10]\n\n\n<NA><NA><NA><NA><NA><NA>3.776909155269433.768171473872113.765649627472043.77219261288612\n\n\n\n<NA><NA><NA><NA><NA><NA>3.776909155269433.768171473872113.765649627472043.77219261288612\n\n\n\ndec_fit$seasonal[1:24]\n\n\n-0.0799020938844753-0.146043800620445-0.01274493183601310.04049677614460120.09068184389565770.03967866993284980.01048177141592280.0587619091303550.041341551797343-0.0179374241117825-0.04690019248569370.0220859206216802-0.0799020938844753-0.146043800620445-0.01274493183601310.04049677614460120.09068184389565770.03967866993284980.01048177141592280.0587619091303550.041341551797343-0.0179374241117825-0.04690019248569370.0220859206216802\n\n\n\n계절성분이라는 것은 12개월마다 반복되는 것이라 12까지 돌고 똑같이 나옴.\n\n\nplot.ts(log_food - dec_fit$trend)\n\n\n\n\n- 1~12월까지의 평균\n\nx <- log_food - dec_fit$trend\nb <- tapply(x, cycle(x), function(y) mean(y, na.rm = T))\nb - mean(b)\n\n1-0.07990209388447532-0.1460438006204453-0.012744931836013140.040496776144601250.090681843895657760.039678669932849870.010481771415922880.05876190913035590.04134155179734310-0.017937424111782511-0.0469001924856937120.0220859206216802\n\n\n\ndec_fit$random[1:10]\n\n\n<NA><NA><NA><NA><NA><NA>-0.00547660660422888-0.0314441938302674-0.03883854426093690.0276591313067893\n\n\n\nplot(dec_fit)\n\n\n\n\n\npredict = trend + seasonal\n\n\npred_dec <- dec_fit$trend + dec_fit$seasonal\n\n\nts.plot(log_food, pred_dec, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Estimated value by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"Estimated value\"))\n\n\n\n\n\n\n\n\nts.plot(pred_stl, pred_dec, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"stl vs decompose\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"stl\", \"decompose\"))\n\n\n\n\n\n거의 비슷하게 나온다?\n\n\n\n\n\ndec_fit2 <- decompose(food, type = \"multiplicative\")\ndec_fit2$trend[1:10]\ndec_fit2$seasonal[1:15]\ndec_fit2$random[1:10]\n\n\n<NA><NA><NA><NA><NA><NA>43.729166666666743.379166666666743.291666666666743.5875\n\n\n\n0.9219246356829520.8621213373421160.9844960475951441.038004198013531.091650489534581.037859336820561.008002905607491.059170985651181.042754035631620.9807591720335130.9523824968151361.020874359272170.9219246356829520.8621213373421160.984496047595144\n\n\n\n<NA><NA><NA><NA><NA><NA>0.995936238493310.9685292269139350.9591835261281731.0269284401149\n\n\n\nplot(dec_fit2)\n\n\n\n\n\npred_dec2 <- dec_fit2$trend*dec_fit2$seasonal\n\n\nts.plot(food, pred_dec2, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Estimated value by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"estimated value\"))\n\n\n\n\n\n\n\n\nts.plot(exp(pred_dec), pred_dec2, col = 1:2, lty = 1:2, ylab = \"food\", xlab = \"time\",\n        main = \"Estimated value by primitive series and decomposition method\")\nlegend(\"topleft\", lty = 1:2, col = 1:2, c(\"primitive series\", \"estimated value\"))\n\n\n\n\n\n비슷하게 나온다. 추세모형은 회귀모형을 써서 예측값이 좀 다르게 나오는데 이건 좀 비슷하다.\n결론 : 이분산성이 있는 경우 승법모형을 써야되지만 로그변환이후 가법모형을 사용해도 된다. 분해법에는 추세이용, 평활법이 있다. 평활법을 이용할 때에는 일반적인 이동법과 중심이동법이 있는데 분해법에서 사용하는 평활을 위해서는 중심이동평균 쓰는 것이 더 좋다."
  },
  {
    "objectID": "posts/time-series/2022-10-14-시계열자료분석-학습5.html",
    "href": "posts/time-series/2022-10-14-시계열자료분석-학습5.html",
    "title": "(수업) 시계열 자료분석 실습 5",
    "section": "",
    "text": "AR, MA, ARMA\n\nlibrary('tidyverse')\nlibrary('gridExtra')\nlibrary('forecast')\n\n\n\n\n\n\n함수로 생성하기\nn개 보다 100개 더 생성하는 이유 : 초기값을 만들고 업데이트할 때 초기값의 영향을 줄여주기 위해 앞에 100개 없애기 위해서 쌩으로 n개만 쓰면 초기값 영향 많이 받음.\n\n\nsim_ar1 <- function(n, phi, mu, sigma){\n    z <- rep(mu, n + 100)\n    for(k in 2 : (n + 100)){\n        z[k] <- mu + phi*(z[k-1] - mu) + rnorm(1, 0, sigma)\n        }\n    return(z[-(1:100)])\n    }\n\n- 전체중에서 앞에꺼 100개 떼고 생성\n\n정상시계열이 되기 위해서는 \\(\\phi\\)가 1보다 작기만 하면 됨. 평균은 그냥 간단하게 0으로 함.\n\n\nn <- 100\nphi <- -0.5\nmu <- 0\nsigma <- 1\n\n\ntmp.data <- data.frame(\n    t = 1:n,\n    z = sim_ar1(n, phi, mu, sigma)\n    )\n\n\np1 <- ggplot(tmp.data, aes(t, z)) +\ngeom_line(col = 'steelblue', lwd = 1.2) +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\nggtitle(paste0(\"Time series plot : AR(1) - phi = \", phi)) +\ntheme_bw() +\ntheme(axis.title.y = element_blank())\n\np2 <- ggAcf(tmp.data$z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) + \nggtitle(\"SACF\") +\ntheme(axis.title.y = element_blank())\n\np3 <- ggPacf(tmp.data$z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle('SPACF') +\ntheme(axis.title.y = element_blank())\n\n\ngrid.arrange(p1, p2, p3, nrow = 2,\n             layout_matrix = rbind(c(1, 1),\n                                   c(2, 3)))\n\n\n\n\n\n해석 : 0을 기준으로 대칭적으로 움직임(정상 시계열: 추세도 없고 계절도 없어보임), AR(1)은 pacf를 봐야하는데 첫 번째와 두 번째가 유의하게 나옴. 근데 원래 알기로는 첫 번째만 유의하고 두 번째부터 유의하지 않아야하는데 이거는 100개의 sampling이라 약간의 오차 표본을 10000개씩 뽑아보면 이론에 근접하게 나옴.\n\n\n\n\n\\(Z_t = \\delta + \\phi_1*Z_{t-1} +\\) … $ + p * Z{t-p} + _t$\n\nsim_ar <- function(n, mu, phi, sigma){\n    p <- length(phi) # 차수\n    z <- rep(mu, (100 + n))\n    delta <- (1-sum(phi))*mu \n    \n    for(k in (length(phi) + 1) : (n + 100)){\n        \n        z[k] <- delta + sum(z[(k-1):(k-p)]*phi) + rnorm(1, 0, sigma)\n        }\n    return(z[-(1:100)])\n    }\n\n- 예를들어 AR(1)면\n\nz <- sim_ar(100, 0, phi = c(0.5), 1)\n\n\nlayout.matrix <- matrix(c(1, 2, 1, 3), nrow = 2, ncol = 2)\nlayout(mat = layout.matrix)\nplot.ts(z)\nacf(z)\npacf(z)\n\n\n\n\n- 예를들어 AR(2)면\n\nz <- sim_ar(100, 0, phi = c(1.3, -0.7), 1)\n\nlayout.matrix <- matrix(c(1, 2, 1, 3), nrow = 2, ncol = 2)\nlayout(mat = layout.matrix)\nplot.ts(z)\nacf(z)\npacf(z)\n\n\n\n\n\n해석 : pacf보면 2개만 유의한 것을 볼 수 있음.\n\n\n\n\n\n저렇게 손으로 코드 안짜도 되는 것이 이미 패키지 모델 만들어져 있음.\n\n\nz <- arima.sim(n = 100, # 이름이 .sim인 이유는 simulation이라서\n               list(order = c(1, 0, 0), ar = 0.5), # order = c(p, d, q)인데 ARMA는 d가 0인거임, 여기는 AR이니 d, q를 0으로\n               # 뒤에 ar = phi의미\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(2, 0, 0), ar = c(0.5, -0.4)), # sd옵션 추가하면 분산도 변경가능 궁금한 것은 help가서 보기\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\nggplot으로 그리기\n\n\np1 <- ggplot(data.frame(t = 1:length(z), z = as.numeric(z)), aes(t, z)) +\ngeom_line(col = 'steelblue', lwd = 1.2) +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\nggtitle(\"Time series plot : AR(1)\") +\ntheme_bw() +\ntheme(axis.title.y = element_blank())\n\np2 <- ggAcf(z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle(\"SACF\") +\ntheme(axis.title.y = element_blank())\n\np3 <- ggPacf(z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle(\"SPACF\") +\ntheme(axis.title.y = element_blank())\n\ngrid.arrange(p1, p2, p3, nrow = 2,\n             layout_matrix = rbind(c(1, 1),\n                                   c(2, 3)))\n\n\n\n\n\n\n\n\n\n\n\n함수로 생성하기\n\n$Z_t = _t - 1 * {t-1} + \\(...\\) + q * {t-q}$\n\nsim_ma <- function(n, mu, theta, sigma){\n    q <- length(theta)\n    ep <- rnorm(n + 100, 0, sigma)\n    z <- ep\n    \n    for(k in (q+1) : (n + 100)){\n        z[k] <- mu + ep[k] - sum(ep[(k-1):(k-q)]*theta)\n        }\n    return(z[-(1:100)])\n    }\n\n- 예를들어 MA(1)면\n\nz <- sim_ma(100, 0, theta = 0.9, 1)\n\nts.plot(z)\nacf(z)\npacf(z)\n\n\n\n\n\n\n\n\n\n\n\n해석 : MA의 경우 acf보면 되는데 2번째 것까지 유의하게 나오니 맞다.\n이 역시 패키지로 만들어져 있다.\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(0,0,1), ma = -0.9), # 이거 help가서 패키지 짜여진 식을 보면 위에서 손으로 짠 식과 부호가 반대임 그래서 \"-\"붙임.\n               rand.gen = rnorm)\n\nts.plot(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(0,0,2), ma = c(0.5, -0.2)),\n               rand.gen = rnorm)\n\nts.plot(z)\nacf(z, lag.max = 20)\npacf(z, lag.max = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n역시 함수 짜서 해도 된다. 여기서는 패키지 써서\n\n\nz <- arima.sim(n = 10000, list(order = c(1, 0, 1),\n                               ar = -0.5, ma = -0.3),\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 20)\npacf(z, lag.max = 20)\n\n\n\n\n\n\n\n\n\n\n\n해석 : acf, pacf 둘 다 감소하고 있다. -> “ARMA모형이네” 참고로 위의 그림에서 acf로만 보면 MA(5)정도를 사용해야할 것 같고, pacf로만 보면 AR(4)정도 사용해야 할 것 같은데 종합해서 ARMA(1, 1)를 사용해버리면 추정해야될 것이 5개, 4개에서 2개로 줄어들기에 더 이득이라 볼 수 있다."
  },
  {
    "objectID": "posts/time-series/2022-10-12-시계열자료분석-학습4.html",
    "href": "posts/time-series/2022-10-12-시계열자료분석-학습4.html",
    "title": "(수업) 시계열 자료분석 실습 4",
    "section": "",
    "text": "ACF, PACF, WN\n\nlibrary('tidyverse')\nlibrary('forecast')\nlibrary('gridExtra')\nlibrary('data.table')\n\n\n\n\nz <- rnorm(200)\n\n\ntmp.data <- data.frame(\n    t = 1:length(z),\n    z = z\n    )\n\n\nggplot(tmp.data, aes(t, z)) +\ngeom_line(col = 'steelblue') +\nxlab(\"\") + ylab(\"\") +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\ntheme_bw()\n\n\n\n\n\n추세가 없고 분산이 일정한 시계열(정상 시계열)이 나옴. 다만 시도표만 보아서는 이게 확실한 정상 시계열인가가 판별 불가\n\n\n\n\n결국 \\(z_t\\) = \\(\\mu + e_t\\) - \\(\\theta\\)*\\(e_{t-1}\\) 그리고\\(e_t\\) ~ \\(wn(0, \\sigma^2)\\)\n\n\nma1_sim <- function(mu, theta, sigma, n){\n    z <- rep(0, n*2)\n    e <- rnorm(n*2, 0, sigma^2)\n    z[1] <- mu + e[1] # 첫 번째는 손으로 입력\n    \n    for(k in 2:(n*2)){\n        z[k] <- mu + e[k] - theta*e[k-1]\n        }\n    \n    return(z[-(1:n)]) # 우리는 100개만 생성하고 싶었으므로 200개 만든 것중 뒤에 거 100개만 선택\n    }\n\n\ntmp.data <- data.frame(\n    t = 1:100,\n    z1 = ma1_sim(10, 0.7, 2, 100),\n    z2 = ma1_sim(10, 0.3, 2, 100),\n    z3 = ma1_sim(10, -0.3, 2, 100),\n    z4 = ma1_sim(10, -0.7, 2, 100)\n    )\n\n\ntmp.data %>% head\n\n\n\nA data.frame: 6 × 5\n\n    tz1z2z3z4\n    <int><dbl><dbl><dbl><dbl>\n\n\n    1115.973064-0.2144137 4.004808 1.559836\n    22 6.40464211.582887210.782340 1.866126\n    33 8.45145511.984286212.98844912.938498\n    4415.287295 6.072400613.23536314.149592\n    5512.02400715.9900225 8.69964115.053175\n    66 9.81308312.847507813.40341410.649353\n\n\n\n\n\ntheta <- c(0.7, 0.3, -0.3, -0.7)\nfor(k in 1:4){\n    plot(tmp.data$t, tmp.data[, (k+1)], type = 'l',\n         col = 'steelblue',\n         main = paste0(' theta = ', theta[k]),\n         xlab = 't',\n         ylab = 'z')\n    abline(h = 10, col = 'grey', lty = 2)\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n분산이 다름. 0.3이 덜 왔다갔다함. 0.7이 더 큼. 3번째는 덜 함. 2번째보다 4번째는 3번째보다도 덜 함. TimeSeriesModel만 보아서는 이게 \\(ma(1)\\)모델인지 알아 볼 수 없음.\n\n\n\n\nfor(k in 1:4){\n    acf(tmp.data[, (k+1)],\n        main = paste0(' theta = ', theta[k]))\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n해석 : 일단, ACF에서 첫번째 시차가 0인 경우는 무조건 ACF가 1임. 그래서 첫 번째 값을 보면 \\(\\theta\\) = 0.7, 0.3일 때 ACF = 0.5, -0.4정도 나오는데 작아지는 모습을 보임. \\(\\theta\\) = 0.7, -0.7인 경우를 비교하면 전자는 acf의 첫번째 시차의 acf가 음수인데, 후자의 경우 양수가 나옴. 이유는 corr이 음수면 방향이 계속 바뀔려고 하고 corr이 양수면 같은 부호에서 머물려고함. \\(\\theta\\)의 절댓값에 커짐에 따라 변동폭이 커짐.\n파란선은 귀무가설을 기각하기 위한 임계치선 0.2에 선이 그어진 이유가 \\(H_0\\) : \\(\\rho\\) = 0의 기각역이 \\(2/\\sqrt{n}\\) 에서 n = 100이여서(2는 사실 엄밀히 1.96) 간혹 삐쭉삐쭉 나온 것들 있는데 그정도는 무시 즉, 정리하면 파란선 안쪽은 다 0이다. 첫 번째 시차만 살아남고(=\\(\\rho_1\\)) 나머지는 다 0 이러한 ACF의 형태까지 보면 우리는 이거 MA모형인가 식별가능\n\n\n\n\n\nfor(k in 1:4){\n    pacf(tmp.data[, (k+1)],\n         main = paste0(' theta = ', theta[k]))\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n해석 : 맨 처음 값들은 \\(\\rho_1\\)들이고 이는 \\(\\phi_{11}\\) 이다. 두 번째 \\(\\theta\\) = 0.3인 경우를 보면 \\(\\theta\\)가 작아서 그런지 유의하지 않게 나옴. ACF같은 경우 첫 번째 시차만 살아남고 나머지 다 0이고 PACF의 경우 살아남은 것들이 좀 더 있지만 부호가 바뀌면서(sin곡선을 그리며) 감소하는 추세를 보임. 그래서 우리는 ACF, PACF를 그려보고 MA모형인지 AR모형인지 등등 알아내면 된다.\n\n\n\n\n\n\nz <- rnorm(100)\n\ntmp.data <- data.table(\n  t = 1:length(z),\n  z = z\n)\n\n\n예쁘게 그리기 ggplot에서 ACF쓸려면 ggAcf사용하면된다. PACF사용하려면 ggPacf사용하면 됨.\n\n\np1 <- ggplot(tmp.data, aes(t, z)) +\ngeom_line(col = 'steelblue', lwd = 1) +\nxlab(\"\") + ylab(\"\") +\nggtitle('Time series plot of iid N(0,1)') +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\ntheme_bw()\n\np2 <- ggAcf(z) +\ntheme_bw() + ylim(-1, 1) +\ntheme(plot.title = element_blank())\n\np3 <- ggPacf(z) +\ntheme_bw() + ylim(-1, 1) +\ntheme(plot.title = element_blank())\n\n\ngrid.arrange(p1, p2, p3, nrow = 2,\n             layout_matrix = rbind(c(1, 1),\n                                   c(2, 3)))\n\n\n\n\n\np1\np2\np3\n\n\n\n\n\n\n\n\n\n\n\nwn이기에 \\(\\rho\\)들은 거의 다 0이여야한다. 실제로 보면 전부다 0에 가까운 숫자들임. 나중에 잔차 검증할 때에도 사용\n\n\nlayout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE))\nplot(z~t, tmp.data, type = 'l',\ncol = 'steelblue',\nmain = paste0(' iid N(0,1)'),\nxlab = 't',\nylab = 'z')\nabline(h = 0, col = 'grey', lty = 2)\n\nacf(z)\npacf(z)\ngraphics.off()\n\n\n\n\n\nacf(z)\npacf(z)\ngraphics.off()\n\n\n\n\n\n\n\n\n\n\n\n\n\n추세법이나 분해법 사용시 sin함수 사용한 것처럼, 위에서 시작해서 위까지 즉, 밑에 보면 주기가 6인 사인함수\n\n\nt <- 1:100\ny <- sin(t*pi/3)\nplot(z[1:30], type = 'o', ylab = '', xlab = '')\n\n\n\n\n\nlayout(matrix(c(1, 1, 2, 3), 2, 2, byrow = TRUE))\nplot(t, y, type = 'l',\n     col = 'steelblue',\n     xlab = 't',\n     ylab = 'z')\nabline(h = 0, col = 'grey', lty = 2)\n\nacf(z)\npacf(z)\ngraphics.off()\n\n\n\n\n\nacf(z)\npacf(z)\n\n\n\n\n\n\n\n\n해석 : ACF보면 주기가 6인 사인함수이기에 6마다 corr이 1인 모습을 볼 수 있음. 그리고 3칸가면 무조건 부호 바뀜. 따라서 위의 ACF그림 같은 경우는 3, 9.. 마다 -인 것을 볼 수 있음. PACF보면 6넘어가는 시점부터는 거의 다 0임. 이게 주기가 6이다 보니 6정도 지나면 PACF라는 것이 딱 두 개만의 관계를 설명하고 나머지를 배제하는 것이기에 이미 한 바퀴 돈 시점부터 이전까지의 process는 설명이 끝남. 이후는 같은 내용 반복이므로 설명할 내용이 없기에 PACF = 0에 가까이 나옴.\n추세가 있는 경우도 마찬가지. 앞의 것들이 이미 설명함.\n\n\n\n\n\n36p 비행기 그림보면 선형성 강하게 나오는 것들 있는데 1, 12완전 직선 느낌 등등 -> 계절성이 있구나 4, 5는 별 거 없다 -> 연관 별로 없구나"
  },
  {
    "objectID": "posts/datascience-for-r/2022-07-06-ggplot1.html",
    "href": "posts/datascience-for-r/2022-07-06-ggplot1.html",
    "title": "ggplot a",
    "section": "",
    "text": "aes, facet_, geom_, mapping, filter\n\nlibrary('tidyverse')\nlibrary('maps') # 위도, 경도 가져오는 library\n\n\n\n\ncolor\n\n\nggplot(data = mpg) + geom_point(mapping = aes(x= displ, y= hwy, color = class))\n\n\n\n\n\nsize\n\n\nggplot(data = mpg) + geom_point(mapping = aes(x= displ, y= hwy, size = class))\n\nWarning message:\n“Using size for a discrete variable is not advised.”\n\n\n\n\n\n\nalpha\n\n\nggplot(data = mpg) + \ngeom_point(mapping = aes(x= displ, y = hwy, alpha = class))\n\nWarning message:\n“Using alpha for a discrete variable is not advised.”\n\n\n\n\n\n\nshape\n\n\nggplot(data = mpg) + \ngeom_point(mapping = aes(x= displ, y = hwy, shape = class))\n\nWarning message:\n“The shape palette can deal with a maximum of 6 discrete values because\nmore than 6 becomes difficult to discriminate; you have 7. Consider\nspecifying shapes manually if you must have them.”\nWarning message:\n“Removed 62 rows containing missing values (geom_point).”\n\n\n\n\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y= hwy), color = 'blue')\n\n\n\n\n\n\n\n\n\n- 차 종류(class)에 따라 나눈 모습 nrow = 줄 개수\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x=displ, y=hwy)) +\nfacet_wrap(~ class, nrow = 3)\n\n\n\n\n\n\n\n\nfacet grid에 적은 항목들의 결과 plot 보여줌.\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y= hwy)) +\nfacet_grid(drv ~ cyl)\n\n\n\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y= hwy),shape =23)\n\n\n\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y =hwy)) +\nfacet_grid(drv ~ cyl)\n\n\n\n\n\nmpg %>% head\n\n\n\nA tibble: 6 × 11\n\n    manufacturermodeldisplyearcyltransdrvctyhwyflclass\n    <chr><chr><dbl><int><int><chr><chr><int><int><chr><chr>\n\n\n    audia41.819994auto(l5)  f1829pcompact\n    audia41.819994manual(m5)f2129pcompact\n    audia42.020084manual(m6)f2031pcompact\n    audia42.020084auto(av)  f2130pcompact\n    audia42.819996auto(l5)  f1626pcompact\n    audia42.819996manual(m5)f1826pcompact\n\n\n\n\n\nmpg$drv %>% unique()\n\n\n'f''4''r'\n\n\n\nmpg$cyl %>% unique()\n\n\n4685\n\n\n\n열이나 행으로 면분할 하고싶지 않다면 변수이름 대신 . 사용 아래는 cyl에 대한 내용만 나온 모습\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y =hwy)) +\nfacet_grid(. ~ cyl)\n\n\n\n\n\nggplot(data = mpg) +\ngeom_point(mapping = aes(x= displ, y = hwy))\n\n\n\n\n\n\n\n\n\n\n\n데이터에 적합된 평활선\n\n\nggplot(data = mpg) +\ngeom_smooth(mapping = aes(x = displ, y = hwy))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\nline자체의 shape은 선택 불가지만, line type은 선택 해줄 수 있음.\n\n\nggplot(data = mpg) +\ngeom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n- 오히려 구별 잘 안되는 듯\n\nggplot(data = mpg)+\ngeom_smooth(mapping = aes(x = displ, y = hwy, group = drv))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n색깔 입히기 가능\n\n\nggplot(data = mpg)+\ngeom_smooth(mapping = aes(x = displ, y = hwy, color = drv))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n- 위에 나온 옵션 다 합쳐서 그리기\n\nggplot(data = mpg)+ geom_point(mapping = aes(x = displ, y = hwy, color = drv))+\ngeom_smooth(mapping = aes(x = displ, y = hwy, color = drv, linetype = drv))\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nggplot(data = diamonds) +\ngeom_bar(mapping = aes(x = cut))\n\n\n\n\n\n\n\n\n\nggplot안에 mapping 해 놓으면 뒤에서 또 x = ~ 이런 거 안 써도 됨.\n\n\nggplot(data = mpg, mapping = aes(x= displ, y=hwy)) +\ngeom_point() +\ngeom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\nmapping 해 놓고 옵션추가 하고 싶다면 해당 geom에 가서 그 부분만 mapping하고 옵션주면 된다. 나머지는 그대로 작동\n\n\nggplot(data = mpg, mapping = aes(x= displ, y=hwy)) +\ngeom_point(mapping = aes(color = class)) +\ngeom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n특정 항목에 한해서만 smooth 하기위해 filter 사용 se = FALSE하면 그림자 꺼짐\n\n\nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +\ngeom_point(mapping = aes(color = class)) +\ngeom_smooth(\ndata = filter(mpg, class == 'subcompact'),\n    se = FALSE\n    )\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\nggplot(data = diamonds) +\ngeom_bar(mapping = aes(x = cut))\n\n\n\n\n\ngeom_bar와 똑같이 나옴\n\n\nggplot(data = diamonds)+\nstat_count(mapping = aes(x = cut))\n\n\n\n\n\n이것을 보면 geom_bar의 y축의 default값이 stat_count임을 알 수 있다 이 stat을 다른 값을 주면 y축 종류를 바꿀 수 있음\n\n- 다이아 예제를 위한 데이터 셋\n\ndemo <- tribble(\n    ~cut, ~freq,\n    \"Fair\", 1610,\n    \"Good\", 4906,\n    \"Very Good\", 12082,\n    \"Premium\", 13791,\n    \"Ideal\", 21551\n    )\n\ndemo\n\n\n\nA tibble: 5 × 2\n\n    cutfreq\n    <chr><dbl>\n\n\n    Fair      1610\n    Good      4906\n    Very Good12082\n    Premium  13791\n    Ideal    21551\n\n\n\n\n- 위의 데이터 셋에 geom_bar를 사용, 언급한대로 stat을 다른 값을 주니 y축이 count에서 frequncy로 바뀜.\n\nggplot(data = demo) +\ngeom_bar(mapping = aes(x = cut, y = freq), stat = 'identity')\n\n\n\n\n\nprop : 비율로 표시하기\n\n\nggplot(data = diamonds) +\ngeom_bar(\n    mapping = aes(x = cut, y = stat(prop), group = 1)\n    )\n\n\n\n\n\nstat_summary\n\n\nggplot(data = diamonds) +\nstat_summary(\n    mapping = aes(x = cut, y = depth),\n    fun.ymin = min,\n    fun.ymax = max,\n    fun.y = median\n    )\n\nWarning message:\n“`fun.y` is deprecated. Use `fun` instead.”\nWarning message:\n“`fun.ymin` is deprecated. Use `fun.min` instead.”\nWarning message:\n“`fun.ymax` is deprecated. Use `fun.max` instead.”\n\n\n\n\n\ngeom_bar에서 color 사용시 막대그래프의 테두리 색 선택 geom_bar에서 fill 사용시 막대그래프 자체 색 선택\n\n\n\nggplot(data = diamonds) +\ngeom_bar(mapping = aes(x= cut, color = cut))\nggplot(data = diamonds) +\ngeom_bar(mapping = aes(x= cut, fill = cut))\n\n\n\n\n\n\n\n- 다른 변수 추가해서 각각 얼마나 차지하는지 보이기\n\nggplot(data = diamonds) +\ngeom_bar(mapping = aes(x= cut, fill = clarity))\n\n\n\n\n\ndiamonds$clarity %>% unique\n\n\nSI2SI1VS1VS2VVS2VVS1I1IF\n\n\n    \n        Levels:\n    \n    \n    'I1''SI2''SI1''VS2''VS1''VVS2''VVS1''IF'\n\n\n\nposition = 'identity' : 각 객체를 그래프 문맥에 해당되는 곳에 정확히 배치한다. 다만, 막대그래프에서는 그리 유용하지 않음\n\nggplot(\n    data = diamonds,\n    mapping = aes(x = cut, fill = clarity)\n    )+\ngeom_bar(alpha = 0.3, position = 'identity')\n\n\n\n\n- 테두리만 색입히고 막대를 빈공간으로 만드는 것도 가능\n\nggplot(\n    data = diamonds,\n    mapping = aes(x = cut, color = clarity)\n    )+\ngeom_bar(fill = NA, position = 'identity')\n\n\n\n\nposition = 'fill' : 누적 막대인데 막대 높이를 동일하게 맞춤 비율 비교에 용이\n\nggplot(data = diamonds) +\ngeom_bar(\n    mapping = aes(x =cut, fill = clarity),\n    position = 'fill'\n    )\n\n\n\n\nposition = 'dodge' : 옆으로 쌓기 개별 값들의 비교 용이\n\nggplot(data = diamonds) +\ngeom_bar(\n    mapping = aes(x =cut, fill = clarity),\n    position = 'dodge'\n    )\n\n\n\n\n\n\n\nposition = 'jitter' : 중복된 값 진하게 표시\n\nggplot(data = mpg) +\ngeom_point(\n    mapping = aes(x =displ, y=hwy),\n    position = 'jitter'\n    )\n\n\n\n\ncoord_flip() : x축 y축 변경\n\nggplot(data = mpg, mapping = aes(x = class, y= hwy)) +\ngeom_boxplot()\nggplot(data = mpg, mapping = aes(x = class, y= hwy)) + \ngeom_boxplot() +\ncoord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\nnz <- map_data('nz')\nnz %>% head\n\n\n\nA data.frame: 6 × 6\n\n    longlatgrouporderregionsubregion\n    <dbl><dbl><dbl><int><chr><chr>\n\n\n    1172.7433-34.4421511North.Island NA\n    2172.7983-34.4556212North.Island NA\n    3172.8528-34.4484613North.Island NA\n    4172.8986-34.4178614North.Island NA\n    5172.9593-34.4250315North.Island NA\n    6173.0184-34.3989516North.Island NA\n\n\n\n\n\nggplot(nz, aes(long, lat, group = group)) +\ngeom_polygon(fill = 'white', color = 'black')\n\n\n\n\n\ncoord_quickmap() : 지도에 맞게 가로세로 비율 설정 공간 데이터 plot에서 중요\n\n\nggplot(nz, aes(long, lat, group = group)) + \ngeom_polygon(fill = 'white', color = 'black') +\ncoord_quickmap()\n\n\n\n\nlabs : NULL하면 x축이나 y축 이름 안보이게 함 theme(aspect.ratio) : 1이면 정사각형 모양, 그 이상은 세로 길어짐, 이하는 가로가 길어짐 width : 막대 뚱뚱한 정도 show.legend : 범주 표기 여부\n\nbar <- ggplot(data = diamonds) +\ngeom_bar(\n    mapping = aes(x = cut, fill = cut),\n    show.legend = FALSE,\n    width = 1\n    ) +\ntheme(aspect.ratio = 1)+\nlabs(x = NULL, y = NULL)\n\nbar + coord_flip()\n\n\n\n\n\ncoord_polar() : pie 차트로 변경\n\n\nbar + coord_polar()"
  },
  {
    "objectID": "posts/datascience-for-r/2022-07-07-ggplot2.html",
    "href": "posts/datascience-for-r/2022-07-07-ggplot2.html",
    "title": "ggplot b",
    "section": "",
    "text": "라벨, 주석, 스케일, 축, 눈금, 범례 키, 확대, 축소, 테마\n\nlibrary('tidyverse')\nlibrary('ggrepel')\nlibrary('viridis')\n\n\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth(se = FALSE) +\nlabs(title = \"engine size and fuel efficiency\",\n     subtitle = \"exception coupe\",\n     caption = \"source : fueleconomy.gov\"\n    )\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n기존의 지정된 것을 변경도 가능\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth(se = FALSE) +\nlabs(\n    x = \"displ(L)\",\n    y = \"highway fuel efficiency\",\n    color = \"car type\"\n    )\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n텍스트 문자열 대신 수식을 사용할 수 있다. \"\"를 quote()로 바꾸면 된다. 옵션에 관해서는 ?plotmath참고\n\n\ndf <- tibble(\n    x = runif(10),\n    y = runif(10)\n    )\nggplot(df, aes(x, y)) +\ngeom_point() +\nlabs(\n    x = quote(sum(x[i]^2, i== 1, n)),\n    y = quote(alpha + beta + frac(delta, theta))\n                  )\n\n\n\n\n\n\n\ngeom_text() : 개별 관측값이나 관측값 그룹에 라벨 붙이기\n\nbest_in_class <- mpg %>%\ngroup_by(class) %>%\nfilter(row_number(desc(hwy)) == 1)\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_text(aes(label = model), data = best_in_class)\n\n\n\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_label(\n    aes(label = model),\n    data = best_in_class,\n    nudge_y = 2,\n    alpha = 0.5\n    )\n\n\n\n\n\n11시 방향에 겹쳐있는 라벨 있음. 소형차와 경차 범주에서 뽑힌 차의 고속도로 연비와 배기량이 정확히 같아서 생긴 문제인데 아래는 해결 방안이다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_point(size = 3, shape = 1, data = best_in_class) +\nggrepel::geom_label_repel(\n    aes(label = model),\n    data = best_in_class\n    )\n\n\n\n\n\n플롯에 라벨을 직접 위치시켜 범례를 대체하기\n\n\nclass_avg <- mpg %>%\ngroup_by(class) %>%\nsummarize(\n    displ = median(displ),\n    hwy = median(hwy)\n    )\n\nggplot(mpg, aes(displ, hwy, color = class)) +\nggrepel::geom_label_repel(aes(label = class),\n                          data = class_avg,\n                          size = 6,\n                          label.size = 0,\n                          segment.color = NA\n                          ) +\ngeom_point() +\ntheme(legend.position = \"none\")\n\n\n\n\n\n모퉁이에 라벨 추가\n\n\nlabel <- mpg %>%\nsummarize(\n    displ = max(displ),\n    hwy = max(hwy),\n    label = paste(\n        \"IIncreasing engine size is \\nrelated to decreasing fuel economy\"\n        )\n    )\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point() +\ngeom_text(\n    aes(label = label),\n    data = label,\n    vjust = \"top\",\n    hjust = \"right\"\n    )\n\n\n\n\n\n텍스트를 플롯의 테두리에 정확하게 배치하려면 +Inf와 -Inf를 사용한다. mpg에서 위치를 더는 계산하지 않으므로 tibble()을 사용하여 데이터프레임을 만들 수 있다.\n\n\nlabel <- tibble(\n    displ = Inf,\n    hwy = Inf,\n    label = paste(\n        \"Increasing engine size is \\nrelated to\",\n        \"decreasing fuel economy\"\n        )\n    )\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point() +\ngeom_text(\n    aes(label = label),\n    data = label,\n    vjust = \"top\",\n    hjust = \"right\"\n    )\n\n\n\n\n\n여기서는 \\n을 사용하여 라벨을 수동을 줄바꿈했는데 다른 방법으로 stringr::str_wrap()을 사용하여 한 줄에 원하는 문자 수만큼 줄바꿈을 자동으로 추가한다.\n\n\n\"Increasing engine size is related to decreasing fuel economy.\" %>%\nstringr::str_wrap(width = 40) %>%\nwriteLines()\n\nIncreasing engine size is related to\ndecreasing fuel economy.\n\n\n\ngeom_text()이외의 플롯에 주석을 달 수 있는 여러 옵션\n\n\n\ngeom_hline(), geom_vline()을 사용하여 참조선을 추가한다. 참조선을 두껍게(size = 2), 흰색(color = white)으로 만들어 기본 데이터 레이어 아래에 그린다. 이렇게 하면 데이터로부터 시선을 빼앗지 않고도 쉽게 눈에 띈다.\ngeom_rect()를 사용하여 관심 지점 주위에 사각형을 그린다. 직사각형의 경계는 xmin, xmax, ymin, ymax 심미성으로 정의된다.\ngeom_segment()를 arrow 인수와 함께 사용하여 화살표로 점에 주의를 집중시킨다. x와 y 심미성을 사용하여 시작 위치를 정의하고 xend와 yend로 끝 위치를 정의한다.\n\n\n\n\n\n\n의사소통을 위해 플롯을 더 잘 만들 수 있는 세 번째 방법은 스케일을 조정하는 것이다. 스케일은 데이터 값에서 인식할 수 있는 것으로의 매핑을 조정한다. 일반적으로, ggplot2는 자동으로 스케일을 추가한다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class))\n\n\n\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\nscale_x_continuous() +\nscale_y_continuous() +\nscale_color_discrete()\n\n\n\n\n\n스케일의 명명 규칙을 주목해야한다. sclale_ 다음에 심미성의 이름, 그다음 _, 그다음엔 스케일의 이름이 온다. 기본 스케일은 정렬되는 변수의 유형(연속형(continuous), 이산형(discrete), 데이트-타임형(date-time), 데이트형(date))에 따라 명명된다. 기본 스케일은 다양한 입력에 맞추어 잘 작동하도록 신중하게 선택되었다. 그럼에도 불구하고 두 가지 이유로 기본값을 덮어쓰고자 할 것이다. \n기본 스케일의 파라미터 일부를 조정하고자 할 수 있다. 이렇게 하면 축의 눈금이나 범례의 키 라벨을 바꾸는 것과 같은 일을 할 수 있다.\n스케일을 완전히 대체하고 완전히 다른 알고리즘을 사용하고자 할 수 있다. 데이터에 대해 더 많이 알고 있기 때문에 기본값보다 더 잘 할 수 있는 경우가 종종 있다.\n\n\n\n\n\n축의 눈금(tick)과 범례의 키 모양에 영향을 주는 두 가지 주요 인수는 breaks와 labels이다. breaks는 눈금의 위치 또는 키와 관련된 값을 제어한다. labels는 각 눈금.키와 연관된 텍스트 라벨을 제어한다. breaks는 기본 선택을 무시하는 데 가장 일반적으로 사용된다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point() +\nscale_y_continuous(breaks = seq(15, 40, by = 5))\n\n\n\n\n\nlabels를 같은 방법으로 사용할 수 있지만(breaks와 같은 길이의 문자형 벡터) NULL로 설정하여 라벨을 모두 표시하지 않을 수도 있다. 지도 또는 절대 숫자를 공유할 수 없는 플롯을 그릴 때 유용하다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point() +\nscale_x_continuous(labels = NULL) +\nscale_y_continuous(labels = NULL)\n\n\n\n\n\nbreaks와 labels를 사용하여 범례의 외관을 조정할 수도 있다. 축과 범례를 가이드라고 부른다. 축은 x와 y의 심미성에 사용되고, 범례는 다른 모든 것에 사용된다. 데이터 포인트가 상대적으로 적은 경우 관측값이 발생한 정확한 위치를 강조하고 싶을 때도 breaks를 사용할 수 있다.\n\n- 예를 들어 각 미국 대통령의 임기가 시작하고 끝난 때를 보여주는 다음의 플롯을 보면\n\npresidential %>%\nmutate(id = 33 + row_number()) %>%\nggplot(aes(start, id)) +\ngeom_point() +\ngeom_segment(aes(xend = end, yend = id)) +\nscale_x_date(\n    NULL,\n    breaks = presidential$start,\n    date_labels = \"'%y\"\n    )\n\n\n\n\n\n데이트형과 데이트-타임형의 breaks와 labels의 명세가 약간 다른 것을 주의해야한다. \ndate_labels는 parse_datetime()과 같은 형식으로 형식지정을 사용한다.\n(여기에 사용되지 않은)date_breaks는 ’2일’이나 ’1개월’과 같은 문자열을 받아들인다.\n\n\n\n\n\n축을 조정하는데 breaks와 labels를 가장 자주 이용할 것인데 이 둘은 범례에도 적용할 수 있지만, 사용하기 쉬운 다른 기술 몇 가지가 있다. 범례의 전체 위치를 제어하려면 theme()설정을 사용해야 한다. 이 장의 마지막 부분에서 다시 돌아와 테마를 보겠지만 간단히 말하면, 이는 플롯의 데이터가 아닌 부분을 조정한다. legend.position theme설정은 범례가 배치될 위치를 조정한다.\n\n\nbase <- ggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class))\n\nbase + theme(legend.position = \"left\")\nbase + theme(legend.position = \"top\")\nbase + theme(legend.position = \"bottom\")\nbase + theme(legend.position = \"right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlegend.position = \"none\"을 사용하여 범례 표시를 모두 취소할 수도 있다. 개별 범례 표시를 제어하려면 guide_legend()나 guide_colorbar()와 함께 guides()를 사용하면 된다.\n\n- 다음 예제에서는 nrow로 범례가 사용하는 열의 개수를 조정하는 것과 점을 크게 하기 위해 심미성 하나를 재정의하는 것을 보여준다.\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth(se = FALSE) +\ntheme(legend.position = \"bottom\") +\nguides(\n    color = guide_legend(\n        nrow = 1,\n        override.aes = list(size = 4)\n        )\n    )\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n세부사항을 조금만 조정하는 대신 스케일을 모두 교체할 수 있다. 자주 교체되는 두 가지 유형의 스케일은 연속형 위치 스케일과 색상 스케일이다. 다행히도 다른 모든 심미성에 같은 원칙이 적용되므로 위치와 색상을 배우면 다른 스케일 대체물을 신속하게 이해할 수 있다.\n\n- 다이아몬드 예제 - 변수를 변형 후 플롯하면 매우 유용한데 아래에서 보면 carat과 price를 로그 변환하면 이들의 정확한 관계를 확인하기 쉽다.\n\nggplot(diamonds, aes(carat, price)) +\ngeom_bin2d()\n\n\n\n\n\nggplot(diamonds, aes(log10(carat), log10(price))) +\ngeom_bin2d()\n\n\n\n\n\n그러나 이 변환의 단점이 있는데, 축의 라벨이 변환된 값으로 지정되어 플롯을 해석하기 어렵게 된다. 변환을 심미성 매핑에서 수행하는 대신, 스케일을 이용해서 할 수 있는데 이 방법은 축이 원래 데이터 스케일로 라벨링된다는 점을 제외하고는 시각적으로 동일하다.\n\n\nggplot(diamonds, aes(carat, price)) +\ngeom_bin2d() +\nscale_x_log10() +\nscale_y_log10()\n\n\n\n\n\n자주 사용자 정의되는 또 다른 스케일은 색상이다. 기본 범주형 스케일에서는 커러휠 주위에 등간격에 위치한 색상이 선택된다. 흔히 나타나는 유형의 색맹인 사람들도 볼 수 있도록 조정된 ColorBrewer 스케일도 유용한 대안이다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = drv))\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = drv)) +\nscale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n색상의 개수가 많지 않으면 모양(shape) 매핑을 중복 추가할 수 있다. 이 방법은 플롯이 흑백에서도 구분될 수 있도록 도와주기도 한다.\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = drv, shape = drv)) +\nscale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n위의 Set1이라고 적은 곳을 옵션에서 찾아보면 다양한 색 조합 변경가능\n\n- 대통령 소속 정당을 색상에 매핑\n\npresidential %>%\n    mutate(id = 33 + row_number()) %>%\n    ggplot(aes(start, id, color = party)) +\n        geom_point() +\n        geom_segment(aes(xend = end, yend = id)) +\n        scale_color_manual(values = c(Republican = \"red\", Democratic = \"blue\"))\n\n\n\n\n\n연속형 색상의 경우, 기본적으로 제공된 scale_color_gradient()나 scale_fill_gradient()를 사용할 수 있다. 발산 스케일이 있다면 scale_color_gradient2()를 사용할 수 있다. 이 방법으로, 예를 들어 양수와 음수에 다른 색깔을 줄 수 있다. 이는 평균 이상이나 이하 점을 구분하고자 할 때 사용할 수 있는 유용한 방법이다.\n\n\ndf <- tibble(\n    x = rnorm(10000),\n    y = rnorm(10000)\n    )\n\n\nggplot(df, aes(x, y)) +\ngeom_hex() +\ncoord_fixed()\n\nggplot(df, aes(x, y)) +\ngeom_hex() +\nviridis::scale_fill_viridis() +\ncoord_fixed()\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\n\n\n\n\n\n\n플롯 범위를 조정하는 방법은 세 가지가 있다.\n\n\n플롯할 데이터 조정하기.\n각 스케일에서 범위 설정하기.\ncoord_cartesian()의 xlim()과 ylim() 설정하기.\n\n\n플롯 영역을 확대.축소하려면 coord_cartesian()을 사용하는 것이 일반적으로 제일 좋다.\n\n\nggplot(mpg, mapping = aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth() +\ncoord_cartesian(xlim = c(5, 7), ylim = c(10, 30))\n\nmpg %>%\nfilter(displ >= 5, displ <= 7, hwy >= 10, hwy <= 30) %>%\nggplot(aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n개별 스케일에 대한 범위를 설정할 수도 있다. 범위를 줄이는 방식은 기본적으로 데이터를 서브셋하는 것과 같다. 플롯들 사이에 스케일을 이치시키는 등의 목적으로 범위를 확장하려는 경우에 일반적으로 유용하다. 예를 들어 두 차종을 추출하여 각각 플롯을 그리면 세가지 스케일(x축, y축, 색상 심미성)의 범위가 서로 다르기 때문에 플롯을 비교하기가 어렵다.\n\n\nsuv <- mpg %>% filter(class == \"suv\")\ncompact <- mpg %>% filter(class == \"compact\")\n\nggplot(suv, aes(displ, hwy, color = drv)) +\ngeom_point()\n\nggplot(compact, aes(displ, hwy, color = drv)) +\ngeom_point()\n\n\n\n\n\n\n\n\n이 문제를 극복하는 방법 중 하나는, 여러 플롯 사이에 스케일을 공유하고, 전체 데이터의 limits로 스케일을 학습하는 것이다.\n\n\nx_scale <- scale_x_continuous(limits = range(mpg$displ))\ny_scale <- scale_y_continuous(limits = range(mpg$hwy))\ncol_scale <- scale_color_discrete(limits =  unique(mpg$drv))\n\nggplot(suv, aes(displ, hwy, color = drv)) +\ngeom_point() +\nx_scale +\ny_scale +\ncol_scale\n\nggplot(compact, aes(displ, hwy, color = drv)) +\ngeom_point() +\nx_scale +\ny_scale +\ncol_scale\n\n\n\n\n\n\n\n\n\n\n\nggplot(mpg, aes(displ, hwy)) +\ngeom_point(aes(color = class)) +\ngeom_smooth(se = FALSE) +\ntheme_bw()\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'"
  },
  {
    "objectID": "posts/datascience-for-r/2022-09-11_모델링.html",
    "href": "posts/datascience-for-r/2022-09-11_모델링.html",
    "title": "모델링 a",
    "section": "",
    "text": "회귀분석(회귀선, 예측값, 잔차, 변수간의 상호관계), 변환, 결측값, 다른 모델\n\nlibrary('tidyverse')\nlibrary('modelr')\n\n\n\n\n\n\n회귀분석을 원초적으로부터 시작해보기 일단 찍는다.\n\n\nggplot(sim1, aes(x, y)) +\ngeom_point()\n\n\n\n\n- 250개의 점을 찍고 그 점들 각각을 \\(B_0\\) 와 \\(B_1\\)으로 사용해서 선을 그은 모습\n\nmodels <- tibble(\n    a1 = runif(250, -20, 40),\n    a2 = runif(250, -5, 5)\n    )\n\n\nggplot(sim1, aes(x, y)) +\ngeom_abline(\n    aes(intercept = a1, slope = a2),\n    data = models, alpha = 1/4\n    ) +\ngeom_point()\n\n\n\n\n- 점들에 회귀선 추가해서 그리기\n\nggplot(sim1, aes(x, y)) +\ngeom_point() +\ngeom_abline(intercept = 7, slope = 1.5, color = \"BLUE\")\n\n\n\n\n- 선을 250개 긋는 것은 정확한 방법이 아닌 것 같으므로 거리 기반으로 선을 긋기 위해 높이 파악(y값) 기준은 위의 파란선으로부터\n\nmodel1 <- function(a, data){\n    a[1] + data$x * a[2]\n    }\nmodel1(c(7, 1.5), sim1)\n\n\n8.58.58.510101011.511.511.513131314.514.514.516161617.517.517.519191920.520.520.5222222\n\n\n- 평균 제곱근으로 거리 구하기(음의 거리 절댓값 씌워주기 위해) 일단 한 개\n\nmeasure_distance <- function(mod, data){\n    diff <- data$y - model1(mod, data)\n    sqrt(mean(diff^2))\n    }\n\nmeasure_distance(c(7, 1.5), sim1)\n\n2.66521206887029\n\n\n- 이 방법을 위의 250개의 데이터 셋에 적용\n\nsim1_dist <- function(a1, a2){\n    measure_distance(c(a1, a2), sim1)\n    }\n\nmodels <- models %>%\nmutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))\nmodels %>% head\n\n\n\nA tibble: 6 × 3\n\n    a1a2dist\n    <dbl><dbl><dbl>\n\n\n    -8.247004 0.69775664220.40099\n    -9.448927 2.42762320911.84420\n    19.508571-4.11947739325.81913\n    -3.733276 4.82187149310.99476\n    -1.019675-0.00029950417.67361\n    -2.200861 4.99527593613.09397\n\n\n\n\n- 이 방법으로 구한 회귀선을 점과 함께 그어보기 가장 좋은 10개의 점의 선만 보이게 함\n\nggplot(sim1, aes(x, y)) +\ngeom_point(size = 2, color = \"grey30\") +\ngeom_abline(\n    aes(intercept = a1, slope = a2, color = -dist),\n    data = filter(models, rank(dist) <= 10)\n    )\n\n\n\n\n- 가장 좋은 10개의 점은 빨간 색으로 강조 표시 나머지 250개 점도 이번에는 표기\n\nggplot(models, aes(a1, a2)) +\ngeom_point(\n    data = filter(models, rank(dist) <= 10),\n    size = 4, color = \"red\"\n    ) +\ngeom_point(aes(color = -dist))\n\n\n\n\n- 골고루 뿌려진(실제 모습) 형태가 아닌 같은 간격의 균등한 격자무늬에 어느 포지션에 위치하나를 보고 싶다면 사용할 수 있는 방법 이 방법을 grid search라 한다.\n\ngrid <- expand.grid(\n    a1 = seq(-5, 20, length = 25),\n    a2 = seq(1, 3, length = 25)\n    ) %>%\nmutate(dist = purrr::map2_dbl(a1, a2, sim1_dist))\n\n\ngrid %>%\nggplot(aes(a1, a2)) +\ngeom_point(\n    data = filter(grid, rank(dist) <= 10),\n    size = 4, color = \"red\"\n    ) +\ngeom_point(aes(color = -dist))\n\n\n\n\n\nggplot(sim1, aes(x, y)) +\ngeom_point(size = 2, color = \"grey30\") +\ngeom_abline(\n    aes(intercept = a1, slope = a2, color = -dist),\n    data = filter(grid, rank(dist) <= 10)\n    )\n\n\n\n\n최적의 모델을 선택할 때까지 그리드를 반복적으로 더욱 세밀하게 만드는 작업을 생각해볼 수 있다. 하지만 이 문제를 해결할 수 있는 더 좋은 방법인 뉴턴 랩슨 기법(Newton-Raphson search)이라 불리는 수치 최소화 도구가 있다. 뉴튼 랩슨 기법의 직관은 매우 간단하다. 시작점을 선택하고 가장 가파른 기울기를 찾기 위해 탐색한다. 그런 다음 가장 작은 값으로 갈 수 없을 때까지 기울기를 약간씩 기울이는 작업을 반복한다. R에서는 optim()을 사용하여 이 작업을 수행할 수 있다.\n\nbest <- optim(c(0, 0), measure_distance, data = sim1)\nbest$par\n\n\n4.222247799614622.05120381317836\n\n\noptim 기법을 이용해 얻은 회귀선\n\nggplot(sim1, aes(x, y)) +\ngeom_point(size = 2, color = \"grey30\") +\ngeom_abline(intercept = best$par[1], slope = best$par[2])\n\n\n\n\n사실 이 방법이 lm에서 회귀선을 구해주는 방식이다.\n\nsim1_mod <- lm(y ~ x, data = sim1)\ncoef(sim1_mod)\n\n(Intercept)4.22082190478565x2.05153307981692\n\n\n\n\n\n- 예측값 만들어 실제와 비교해보기 위해 예측값을 생성하기\ndata_grid : 해당 항목의 값만 뽑아서 보기(중복 제외)\n\ngrid <- sim1 %>%\ndata_grid(x)\n\ngrid\n\n\n\nA tibble: 10 × 1\n\n    x\n    <int>\n\n\n     1\n     2\n     3\n     4\n     5\n     6\n     7\n     8\n     9\n    10\n\n\n\n\n\ngrid <- grid %>%\nadd_predictions(sim1_mod)\n\ngrid\n\n\n\nA tibble: 10 × 2\n\n    xpred\n    <int><dbl>\n\n\n     1 6.272355\n     2 8.323888\n     310.375421\n     412.426954\n     514.478487\n     616.530020\n     718.581553\n     820.633087\n     922.684620\n    1024.736153\n\n\n\n\n\nggplot(sim1, aes(x)) +\ngeom_point(aes(y = y)) +\ngeom_line(\n    aes(y = pred),\n    data = grid,\n    color = \"red\",\n    size = 1\n    )\n\n\n\n\n\n\n\n\nsim1 <- sim1 %>%\nadd_residuals(sim1_mod)\n\n\nsim1 %>% head\n\n\n\nA tibble: 6 × 3\n\n    xyresid\n    <int><dbl><dbl>\n\n\n    1 4.199913-2.0724420\n    1 7.510634 1.2382791\n    1 2.125473-4.1468822\n    2 8.988857 0.6649694\n    210.243105 1.9192174\n    211.296823 2.9729351\n\n\n\n\ngeom_freqpoly : ggplot의 히스토그램 함수\n- 잔차의 빈도\n\nggplot(sim1, aes(resid)) +\ngeom_freqpoly(binwidth = 0.5)\n\n\n\n\ngeom_ref_line : ggplot에 참조선 추가해준다. > geom_ref_line(h, v, 크기 = 2, 색상 = “흰색”)\n- 잔차의 분포 랜덤하게 분포된 것을 보니 모델이 데이터셋에서 패턴을 잘 포착하였음을 의미한다.\n\nggplot(sim1, aes(x, resid)) +\ngeom_ref_line(h = 0) +\ngeom_point()\n\n\n\n\nmodel_matrix : 회귀모델을 matrix로 보여준다.\n\ndf <- tribble(\n    ~y, ~x1, ~x2,\n    4,2,5,\n    5,1,6\n    )\n\nmodel_matrix(df, y ~ x1)\n\n\n\nA tibble: 2 × 2\n\n    (Intercept)x1\n    <dbl><dbl>\n\n\n    12\n    11\n\n\n\n\n- 열 하나 줄이기\n\nmodel_matrix(df, y ~ x1 - 1)\n\n\n\nA tibble: 2 × 1\n\n    x1\n    <dbl>\n\n\n    2\n    1\n\n\n\n\n- x2변수까지 추가\n\nmodel_matrix(df, y ~ x1 + x2)\n\n\n\nA tibble: 2 × 3\n\n    (Intercept)x1x2\n    <dbl><dbl><dbl>\n\n\n    125\n    116\n\n\n\n\n-범주형 변수에서의 model_matrix\n\ndf <- tribble(\n    ~ sex, ~ response,\n    \"male\", 1,\n    \"female\", 2,\n    \"male\", 1\n    )\n\ndf\n\n\n\nA tibble: 3 × 2\n\n    sexresponse\n    <chr><dbl>\n\n\n    male  1\n    female2\n    male  1\n\n\n\n\n\nmodel_matrix(df, response ~ sex)\n\n\n\nA tibble: 3 × 2\n\n    (Intercept)sexmale\n    <dbl><dbl>\n\n\n    11\n    10\n    11\n\n\n\n\n\nggplot(sim2) +\ngeom_point(aes(x, y))\n\n\n\n\nadd_predictions : 해당 모델로 추정된 예측값 추가\n\nmod2 <- lm(y ~ x, data = sim2)\n\ngrid <- sim2 %>%\ndata_grid(x) %>%\nadd_predictions(mod2)\n\ngrid\n\n\n\nA tibble: 4 × 2\n\n    xpred\n    <chr><dbl>\n\n\n    a1.152166\n    b8.116039\n    c6.127191\n    d1.910981\n\n\n\n\n사실상 범주형 변수 x를 포함한 모델은 각 범주의 평균값을 예측한다.(그 이유는 각 범주의 평균값이 평균제곱근 편차를 최소화 하기 때문이다.) 이는 원 데이터 위에 예측값을 겹쳐서 그려보면 쉽게 확인할 수 있다.\n- “sim2” 데이터 셋에 예측값은 빨간 색으로 찍어 보았다. 평균 정도 위치에 있음을 볼 수 있다.\n\nggplot(sim2, aes(x)) +\ngeom_point(aes(y = y)) +\ngeom_point(\n    data = grid,\n    aes(y = pred),\n    color = \"red\",\n    size = 4\n    )\n\n\n\n\n\nggplot(sim3, aes(x1, y)) +\ngeom_point(aes(color = x2))\n\n\n\n\n\n\n\n+를 사용하여 변수를 추가하면 모델은 다른 모든 변수와 독립적인 각 효과를 추정한다. *을 사용하면 상호작용이라 불리는 항을 적합할 수 있다. 예를 들어 \\(y\\) ~ \\(x1 * x2\\)는 $ y = a_0 + a_1 * a1 + a_2 * a2 + a_{12} * a1 * a2$로 변환된다.\n- 이를 위해 두 가지 모델 사용 각각은 변수를 +, * 관계로 적용\n\nmod1 <- lm(y ~ x1 + x2, data = sim3)\nmod2 <- lm(y ~ x1 * x2, data = sim3)\n\n\ngrid <- sim3 %>%\ndata_grid(x1, x2) %>%\ngather_predictions(mod1, mod2)\ngrid %>% head\n\n\n\nA tibble: 6 × 4\n\n    modelx1x2pred\n    <chr><int><fct><dbl>\n\n\n    mod11a1.674928\n    mod11b4.562739\n    mod11c6.480664\n    mod11d4.034515\n    mod12a1.478190\n    mod12b4.366001\n\n\n\n\nfacet_wrap : 그룹별(범주)로 plot을 분할하여 보여준다.\n\nggplot(sim3, aes(x1, y, color = x2)) +\ngeom_point() +\ngeom_line(data = grid, aes(y = pred)) +\nfacet_wrap(~ model)\n\n\n\n\n+를 사용한 모델은 각 라인의 기울기는 같지만 y 절편값은 서로 다르다. *를 사용한 모델은 기울기와 y 절편값이 모두 다르다. 어떤 모델이 이 데이터에 잘 맞을까? 이는 잔차를 통해 확인할 수 있다. 여기서는 각 그룹 내의 패턴을 쉽게 확인하기 위해 모델과 x2로 면분할하였다.\n\nsim3 <- sim3 %>%\ngather_residuals(mod1, mod2)\n\nggplot(sim3, aes(x1, resid, color = x2)) +\ngeom_point() +\nfacet_grid(model ~ x2)\n\n\n\n\nmod의 잔차에서는 확실한 패턴이 거의 보이지 않는다. mod1의 잔차는 분명하게 모델이 b에서 어떤 패턴을 놓쳤다는 것을 나타내주며 b보다는 덜하지만 c와 d에서도 여전히 패턴이 존재하는 것을 알 수 있다.\n\n\n\n두개의 연속 변수로 이루어진 같은 모델로 시작한다.\n\n\nmod1 <- lm(y ~ x1 + x2, data = sim4)\nmod2 <- lm(y ~ x1 * x2, data = sim4)\n\n\ngrid <- sim4 %>%\ndata_grid(\n    x1 = seq_range(x1, 5),\n    x2 = seq_range(x2, 5)\n    ) %>%\ngather_predictions(mod1, mod2)\n\ngrid %>% head\n\n\n\nA tibble: 6 × 4\n\n    modelx1x2pred\n    <chr><dbl><dbl><dbl>\n\n\n    mod1-1.0-1.0 0.9963094\n    mod1-1.0-0.5-0.3949484\n    mod1-1.0 0.0-1.7862061\n    mod1-1.0 0.5-3.1774639\n    mod1-1.0 1.0-4.5687216\n    mod1-0.5-1.0 1.9071424\n\n\n\n\nseq_range : 최소값과 최대값 사이를 균일하게 간격을 나눈다.\n- 예시\n\nseq_range(c(1,2),5)\n\n\n11.251.51.752\n\n\n- seq_range 옵션 n은 안써도 됨, pretty = TRUE는 사람이 보기 좋게 만들어 줌(소수점 잘라서)\n\nseq_range(c(0.0123, 0.923423), n = 5)\n\n\n0.01230.240080750.46786150.695642250.923423\n\n\n\nseq_range(c(0.0123, 0.923423), n = 5, pretty = TRUE)\n\n\n00.20.40.60.81\n\n\nrcauchy : 코시분포 난수 생성 코시분포 : 모평균이 존재하지 않는 분포\n\nx1 <- rcauchy(100)\nseq_range(x1, n = 5)\n\n\n-30.6598727690423-20.2891777908305-9.918482812618690.45221216559313910.822907143805\n\n\ntrim = 0.10 : 꼬리 값 10% 제거 변수가 꼬리가 긴 분포를 갖고 있고 중심 근처의 값을 생성하고자 할 때 사용\n\nseq_range(x1, n = 5, trim = 0.10)\n\n\n-8.38143125026766-5.30064261199304-2.219853973718410.8609346645562083.94172330283083\n\n\nexpnad = 0.1 : trim()과 반대 기능, 범위를 10% 확장\n\nx2 <- c(0, 1)\nseq_range(x2, n = 5)\n\n\n00.250.50.751\n\n\n\nseq_range(x2, n = 5, expand = 0.10)\n\n\n-0.050.2250.50.7751.05\n\n\ngeom_tile : 히트맵 찍기\n\nggplot(grid, aes(x1, x2)) +\ngeom_tile(aes(fill = pred)) +\nfacet_wrap(~ model)\n\n\n\n\n\n위의 모습으로만 보면 덧셈을 사용한 모델과 곱을 사용한 모델에 별 차이가 없어 보인다.\n\n\nggplot(grid, aes(x1, pred, color = x2, group = x2)) +\ngeom_line() +\nfacet_wrap(~ model)\n\n\n\n\n\nggplot(grid, aes(x2, pred, color = x1, group = x1)) +\ngeom_line() +\nfacet_wrap(~ model)\n\n\n\n\n위 플롯은 두 개의 연속 변수 사이의 상호작용이 기본적으로 범주형과 연속형 변수의 상호작용과 같은 방식으로 동작함을 보여준다. 또한 이 플롯에서의 상호작용은 고정된 오프셋이 없다는 것을 나타낸다. 즉, y를 예측하기 위해서는 x1과 x2를 동시에 고려해야 한다.\n\n\n\n\n\n추후 보강함(좀 어려움) 지금은 옮겨 적는 것 위주로\n\n모델이 변환되는 방식이 헷갈린다면 model_matrix()를 사용하여 lm()이 모델을 적합하는 수식이 무엇인지 정확하게 확인할 수 있다.\n\ndf <- tribble(\n    ~y, ~x,\n    1,1,\n    2,2,\n    3,3\n    )\n\nmodel_matrix(df, y ~ x^2 + x)\n\n\n\nA tibble: 3 × 2\n\n    (Intercept)x\n    <dbl><dbl>\n\n\n    11\n    12\n    13\n\n\n\n\n\nmodel_matrix(df, y ~ I(x^2) + x)\n\n\n\nA tibble: 3 × 3\n\n    (Intercept)I(x^2)x\n    <dbl><dbl><dbl>\n\n\n    111\n    142\n    193\n\n\n\n\n변환은 비선형 함수를 근사하는 데 유용하게 사용할 수 있다. 미적분에서의 ’어떤 평활 함수도 다항식의 무한한 합으로 근사시킬 수 있다’라는 테일러 정리처럼 \\(y = a_1 + a_2 * x + a_3 * x^2 + a_4 * x ^3\\)과 같은 방정식을 적합하여 선형 함수를 임의의 평활함수에 가깝게 만들 수 있다는 것을 의미한다. 손으로 시퀀스를 타이핑하는 것은 번거롭기 때문에 R에서는 도우미 함수인 poly()를 사용할 수 있다.\n\nmodel_matrix(df, y ~ poly(x, 2))\n\n\n\nA tibble: 3 × 3\n\n    (Intercept)poly(x, 2)1poly(x, 2)2\n    <dbl><dbl><dbl>\n\n\n    1-7.071068e-01 0.4082483\n    1-7.850462e-17-0.8164966\n    1 7.071068e-01 0.4082483\n\n\n\n\n그러나 poly()를 사용하는 데는 한 가지 주요한 문제가 있다. 데이터의 범위를 벗어나면 다항식은 급격하게 양의 무한대 또는 음의 무한대로 발산하게 된다. 한 가지 안전한 대안은 본연의 스플라인(spline, 매끄러운 곡선)인 splines::ns()를 사용하는 것이다.\n\nlibrary('splines')\n\n\nmodel_matrix(df, y ~ ns(x, 2))\n\n\n\nA tibble: 3 × 3\n\n    (Intercept)ns(x, 2)1ns(x, 2)2\n    <dbl><dbl><dbl>\n\n\n    10.0000000 0.0000000\n    10.5662628-0.2108419\n    10.3440969 0.7706021\n\n\n\n\n\n비선형 함수를 근사할 때 어떻게 표현되는지 살펴보자\n\n\nsim5 <- tibble(\n    x = seq(0, 3.5 * pi, length = 50),\n    y = 4 * sin(x) + rnorm(length(x))\n    )\nggplot(sim5, aes(x, y)) +\ngeom_point()\n\n\n\n\n\n이 데이터에 다섯 가지 모델을 적용해볼 것이다.\n\n\nmod1 <- lm(y ~ ns(x, 1), data = sim5)\nmod2 <- lm(y ~ ns(x, 2), data = sim5)\nmod3 <- lm(y ~ ns(x, 3), data = sim5)\nmod4 <- lm(y ~ ns(x, 4), data = sim5)\nmod5 <- lm(y ~ ns(x, 5), data = sim5)\n\n\ngrid <- sim5 %>%\ndata_grid(x = seq_range(x, n = 50, expand = 0.1)) %>%\ngather_predictions(mod1, mod2, mod3, mod4, mod4, mod5, .pred = \"y\")\n\nggplot(sim5, aes(x, y)) +\ngeom_point() +\ngeom_line(data = grid, color = \"red\") +\nfacet_wrap(~ model)\n\n\n\n\n\n\n\n\ndf <- tribble(\n    ~x, ~y,\n    1, 2.2,\n    2, NA,\n    3, 3.5,\n    4, 8.3,\n    NA, 10\n    )\n\nmod <- lm(y ~ x, data = df)\n\n\n\n\n\n일반화 선형 모형 일반화 가법 모형 벌점 선형 모형 로버스트 선형 모형 트리 모형"
  },
  {
    "objectID": "posts/datascience-for-r/2022-09-12_모델링2.html",
    "href": "posts/datascience-for-r/2022-09-12_모델링2.html",
    "title": "모델링 b",
    "section": "",
    "text": "다이아몬드 예제, 항공기 운항 예제\n\nlibrary('tidyverse')\nlibrary('modelr')\nlibrary('nycflights13')\nlibrary('lubridate')\n\n\n데이터를 패턴과 잔차로 분리한 모델을 들여다보면서 생각해볼 수 있는 점들을 활용할 것이다. 시각화를 통해 패턴을 찾은 다음 모델을 사용하여 패턴을 구체적이고 정확하게 만들 것이다. 이 과정을 반복하며 이전의 반응 변수를 모델의 잔차로 대체할 것이다. 데이터와 머릿속의 내재적인 지식을 정량적 모델의 잔차로 대체할 것이다. 데이터와 머릿속의 내재적인 지식을 정량적 모델의 명시적인 지식으로 전환하는 것이 우리의 목표이다. 이는 새로운 도메인에 쉽게 적용할 수 있으며 다른 도메인에서 쉽게 사용하도록 해줄 것이다. 매우 크고 복잡한 데이터셋의 경우에는 많은 작업이 필요할 것이다. 그렇지만 분명한 개선 방안이 있다. 많은 기계학습 접근법은 단순히 모델의 예측력에 초점을 맞춘다. 이 접근 방식은 블랙박스 모델을 생성하는 경향이 있어 모델이 예측값을 생성하는 데는 훌륭하지만, 그 이유에 대해서는 알 수 없다. 이는 합리적인 접근 방식이지만 실제 지식을 모델에 적용하기에는 어렵다. 결과적으로 기본 원칙이 변함에 따라 장기적으로 모델이 계속 동작할 것인가를 평가하는 것이 어려워진다. 대부분의 실제 모델에서는 이 접근 방식에 더 일반적이고 자동화된 접근 방식을 조합하여 사용한다. 멈추어야 하는 순간을 아는 것은 쉽지 않다. 모델이 충분히 좋아지는 시점과 추가로 시도했을 때 성과가 발생하지 않는 시점을 알아내야 한다.\n\n- 필요한 데이터 셋 패키지\n\n\n\nggplot(diamonds, aes(cut, price)) + geom_boxplot()\nggplot(diamonds, aes(color, price)) + geom_boxplot()\nggplot(diamonds, aes(clarity, price)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n퀄리티가 떨어지는 다이아몬드가 평균 단가는 제일 높은 것을 확인할 수 있는데 이는 무게(carat)를 고려하지 않았기 때문이다. 일반적으로 품질이 떨어지는 다이아몬드가 더 무거운 경향이 있다.\n\n\nggplot(diamonds, aes(carat, price)) +\ngeom_hex(bins = 50)\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\ncarat의 효과를 분리하는 모델을 적합하여 다이아몬드의 다른 속성이 상대적으로 price에 어떻게 영향을 주는지 쉽게 알 수 있다. 먼저 작업하기 쉽도록 만들기 위해 아래의 두 가지 항목으로 다이아몬드 데이터셋을 변경한다.\n\n\n2.5캐럿보다 작은 다이아몬드(데이터의 99.7%에 해당)로 한정한다.\n캐럿과 가격 변수를 로그 변환한다.\n\n\ndiamonds2 <- diamonds %>%\nfilter(carat <= 2.5) %>%\nmutate(lprice = log2(price), lcarat = log2(carat))\n\n\ndiamonds2 %>% head\n\n\n\nA tibble: 6 × 12\n\n    caratcutcolorclaritydepthtablepricexyzlpricelcarat\n    <dbl><ord><ord><ord><dbl><dbl><int><dbl><dbl><dbl><dbl><dbl>\n\n\n    0.23Ideal    ESI2 61.5553263.953.982.438.348728-2.120294\n    0.21Premium  ESI1 59.8613263.893.842.318.348728-2.251539\n    0.23Good     EVS1 56.9653274.054.072.318.353147-2.120294\n    0.29Premium  IVS2 62.4583344.204.232.638.383704-1.785875\n    0.31Good     JSI2 63.3583354.344.352.758.388017-1.689660\n    0.24Very GoodJVVS262.8573363.943.962.488.392317-2.058894\n\n\n\n\n\n이 변환은 carat과 price의 관계를 알기 쉽게 만들어준다.\n\n\nggplot(diamonds2, aes(lcarat, lprice)) +\ngeom_hex(bins = 30)\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\n로그 변환은 해당 패턴을 작업하기에 가장 쉬운 선형 패턴을 만들어주기 때문에 매우 유용하다. 다음 단계로 넘어가서 강한 선형 패턴을 제거해보자. 먼저 모델을 적합하여 패턴을 명확하게 만든다.\n\n\nmod_diamond <- lm(lprice ~ lcarat, data = diamonds2)\nmod_diamond\n\n\nCall:\nlm(formula = lprice ~ lcarat, data = diamonds2)\n\nCoefficients:\n(Intercept)       lcarat  \n     12.194        1.681  \n\n\n\ngrid <- diamonds2 %>%\ndata_grid(carat = seq_range(carat, 20)) %>%\nmutate(lcarat = log2(carat)) %>%\nadd_predictions(mod_diamond, \"lprice\") %>%\nmutate(price = 2^lprice)\n\nggplot(diamonds2, aes(carat, price)) +\ngeom_hex(bins = 50) +\ngeom_line(data = grid, color = \"red\", size = 1)\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\n위 플롯은 데이터에 대해 흥미로운 사실을 알려준다. 우리의 모델을 신뢰한다면 크기가 큰 다이아몬드는 예측한 값보다 훨씬 저렴하다. 그것은 아마 이 데이터 셋에는 19,000달러가 넘는 다이아몬드가 존재하지 않기 때문이다. 이제 강한 선형 패턴을 제대로 제거했는지 확인하기 위해 잔차를 살펴볼 수 있다.\n\n\ndiamonds2 <- diamonds2 %>%\nadd_residuals(mod_diamond, \"lresid\")\n\nggplot(diamonds2, aes(lcarat, lresid)) +\ngeom_hex(bins = 50)\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\n비교적 고른 잔차분포를 볼 수 있다.\n\n\nggplot(diamonds2, aes(cut, lresid)) + geom_boxplot()\nggplot(diamonds2, aes(color, lresid)) + geom_boxplot()\nggplot(diamonds2, aes(clarity, lresid)) + geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n이제 예상했던 변수들의 관계를 확인할 수 있다. 다이아몬드의 품질이 좋아질수록 상대적인 가격도 높아진다. y축을 해석하기 위해 잔차의 의미와 스케일의 값에 대해 생각해볼 필요가 있다. 잔차가 -1이라는 것은 해당 변수만을 이용한 예측값보다 lprice가 한 단위 더 작다는 것을 나타낸다. \\(2^{-1}\\)은 1/2이므로 -1인 점은 예측한 가격의 절반에 해당하고, 잔차가 1인 점은 예측한 가격의 두 배를 나타낸다.\n\n\n\n\n원한다면 모델을 명시적으로 만들기 위해 관측한 효과를 모델로 이동하여 계속해서 모델을 발전시킬 수 있다. 예를 들어 color, cut 및 clarity 변수를 모델에 포함하여 이 세 개의 범주형 변수의 효과를 나타낼 수 있다.\n\n\nmod_diamond2 <- lm(\n    lprice ~ lcarat + color + cut + clarity,\n    data = diamonds2\n    )\n\n\n이제 이 모델은 네 개의 예측 변수를 포함하므로 시각화하는 것은 더 어려워진다. 그렇지만 모든 변수가 독립적이므로 네 개의 플롯으로 각각 그릴 수 있다. 이 과정을 좀 더 쉽게 만들기 위해 data_grid함수에 .model인수를 사용한다.\n\n\ngrid <- diamonds2 %>%\ndata_grid(cut, .model = mod_diamond2) %>%\nadd_predictions(mod_diamond2)\n\ngrid\n\n\n\nA tibble: 5 × 5\n\n    cutlcaratcolorclaritypred\n    <ord><dbl><chr><chr><dbl>\n\n\n    Fair     -0.5145732GVS211.20557\n    Good     -0.5145732GVS211.32050\n    Very Good-0.5145732GVS211.37396\n    Premium  -0.5145732GVS211.40627\n    Ideal    -0.5145732GVS211.43759\n\n\n\n\n\nggplot(grid, aes(cut, pred)) +\ngeom_point()\n\n\n\n\n\n명시적으로 제공되지 않는 변수를 모델이 필요로 한다면 data_grid()함수가 자동으로 ’대표적인 값’으로 채운다. 연속형 변수의 경우 중앙값을 사용하고, 범주형 변수의 경우 가장 빈번한 값을 사용한다.\n\n\ndiamonds2 <- diamonds2 %>%\nadd_residuals(mod_diamond2, \"lresid2\")\n\nggplot(diamonds2, aes(lcarat, lresid2)) +\ngeom_hex(bins = 50)\n\nWarning message:\n“Computation failed in `stat_binhex()`:\n”\n\n\n\n\n\n\n이 플롯은 잔차의 값이 큰 다이아몬드가 일부 존재한다는 것을 보여준다. 잔차가 2라는 것은 다이아몬드의 가격이 예상했던 가격의 4배라는 것을 나타낸다. 비정상적인 관측값을 개별적으로 탐색하면 유용할 때가 많다.\n\n\ndiamonds2 %>%\nfilter(abs(lresid2) > 1) %>%\nadd_predictions(mod_diamond2) %>%\nmutate(pred = round(2^pred)) %>%\nselect(price, pred, carat:table, x:z) %>%\narrange(price)\n\n\n\nA tibble: 16 × 11\n\n    pricepredcaratcutcolorclaritydepthtablexyz\n    <int><dbl><dbl><ord><ord><ord><dbl><dbl><dbl><dbl><dbl>\n\n\n     1013  2640.25Fair     FSI2 54.4644.304.232.32\n     1186  2840.25Premium  GSI2 59.0605.335.283.12\n     1186  2840.25Premium  GSI2 58.8605.335.283.12\n     1262 26441.03Fair     EI1  78.2545.725.594.42\n     1415  6390.35Fair     GVS2 65.9545.575.533.66\n     1415  6390.35Fair     GVS2 65.9545.575.533.66\n     1715  5760.32Fair     FVS2 59.6604.424.342.61\n     1776  4120.29Fair     FSI1 55.8604.484.412.48\n     2160  3140.34Fair     FI1  55.8624.724.602.60\n     2366  7740.30Very GoodDVVS260.6584.334.352.63\n     3360 13730.51Premium  FSI1 62.7625.094.963.15\n     3807 15400.61Good     FSI2 62.5655.365.293.33\n     3920 17050.51Fair     FVVS265.4604.984.903.23\n     4368 17050.51Fair     FVVS260.7665.215.113.13\n    10011 40481.01Fair     DSI2 64.6586.256.204.02\n    10470236222.46Premium  ESI2 59.7598.828.765.25\n\n\n\n\n\n여기서는 분명하게 눈에 띄는 것은 없지만, 모델에 문제가 있는지 혹은 데이터에 오류가 있는지 생각해보는 데 시간을 투자할 가치가 있다. 만약 데이터에 오류가 있다면 부정확하게 낮은 가격으로 가격이 매겨진 다이아몬드를 사게 될 수도 있다.\n\n\n\n\n\n- 일자별 항공편의 빈도수\n\ndaily <- flights %>%\nmutate(date = make_date(year, month, day)) %>%\ngroup_by(date) %>%\nsummarize(n = n())\n\ndaily %>% head\n\n\n\nA tibble: 6 × 2\n\n    daten\n    <date><int>\n\n\n    2013-01-01842\n    2013-01-02943\n    2013-01-03914\n    2013-01-04915\n    2013-01-05720\n    2013-01-06832\n\n\n\n\n\nggplot(daily, aes(date, n)) +\ngeom_line()\n\n\n\n\n\n\n\n요일 효과가 매우 강하게 존재하기 때문에 장기적인 트렌드를 이해하기 쉽지 않다. 먼저 요일별 항공편의 수에 대한 분포를 보면\n\n\ndaily <- daily %>%\nmutate(wday = wday(date, label = TRUE))\n\n\n한글로 나와서 오류떠서 영어로 바꿔줌\n\n\ndaily <- daily %>%\nmutate(wday = fct_recode(wday,\n                            \"Sun\"   = \"일\",\n                            \"Mon\"   = \"월\",\n                            \"Tues\"  = \"화\",\n                            \"Wed\"   = \"수\",\n                            \"Thurs\" = \"목\",\n                            \"Fri\"   = \"금\",\n                            \"Sat\"   = \"토\"\n                            ))\n\n\ndaily %>% head\n\n\n\nA tibble: 6 × 3\n\n    datenwday\n    <date><int><ord>\n\n\n    2013-01-01842Tues \n    2013-01-02943Wed  \n    2013-01-03914Thurs\n    2013-01-04915Fri  \n    2013-01-05720Sat  \n    2013-01-06832Sun  \n\n\n\n\n\nggplot(daily, aes(wday, n)) +\ngeom_boxplot()\n\n\n\n\n\n대부분 업무를 위해 비행기를 이용하므로 주말에는 항공편의 수가 적다. 그 효과는 특히 토요일에 두드러지게 나타난다. 월요일 아침 미팅을 위해 일요일에 떠나는 경우는 있지만, 토요일에는 가족과 함께 집에 있는 것을 택할 것이므로 토요일에 떠나는 경우는 거의 없다. 이 강력한 패턴을 제거하는 한 가지 방법은 모델을 사용하는 것이다. 먼저 모델을 생성하고 원 데이터에 예측값을 겹처서 나타낸다.\n\n\nmod <- lm(n ~ wday, data = daily)\n\ngrid <- daily %>%\ndata_grid(wday) %>%\nadd_predictions(mod, \"n\")\n\nggplot(daily, aes(wday, n)) +\ngeom_boxplot() +\ngeom_point(data = grid, color = \"red\", size = 4)\n\n\n\n\n\n다음으로 잔차를 계산한 후 시각화한다.\n\n\ndaily <- daily %>%\nadd_residuals(mod)\n\ndaily %>%\nggplot(aes(date, resid)) +\ngeom_ref_line(h = 0) +\ngeom_line()\n\n\n\n\n\ny축 변화를 보면 일자마다 예측한 비행 횟수의 편차를 확인할 수 있다. 요일 효과의 많은 부분을 제거하여 남아있는, 감지하기 어려운 패턴을 확인할 수 있으므로 이 플롯은 유용하다고 할 수 있다. 이 모델은 6월부터 잘 맞지 않는 것처럼 보인다. 여전히 모델이 포착하지 못한 규칙적이고 강한 패턴을 확인할 수 있다. 각 요일을 한 줄씩 플롯으로 그리면 그 원인을 쉽게 확인할 수 있다.\n\n\nggplot(daily, aes(date, resid, color = wday)) +\ngeom_ref_line(h = 0) +\ngeom_line()\n\n\n\n\n\n위의 모델은 플롯으로 보았을 때 토요일의 비행 횟수를 정확하게 예측하지 못한다. 여름에는 예측한 값보다 많은 항공편이 있고, 가을에는 더 적은 항공편이 있다.\n\n\ndaily %>%\nfilter(resid < -100)\n\n\n\nA tibble: 11 × 4\n\n    datenwdayresid\n    <date><int><ord><dbl>\n\n\n    2013-01-01842Tues -109.3585\n    2013-01-20786Sun  -105.4808\n    2013-05-26729Sun  -162.4808\n    2013-07-04737Thurs-228.7500\n    2013-07-05822Fri  -145.4615\n    2013-09-01718Sun  -173.4808\n    2013-11-28634Thurs-331.7500\n    2013-11-29661Fri  -306.4615\n    2013-12-24761Tues -190.3585\n    2013-12-25719Wed  -243.6923\n    2013-12-31776Tues -175.3585\n\n\n\n\n\n1년에 걸친 장기간의 매끄러운 추세가 나타나는 것처럼 보이는데 geom_smooth()을 사용하여 이러한 추세를 강조할 수 있다.\n\n\ndaily %>%\nggplot(aes(date, resid)) +\ngeom_ref_line(h = 0) +\ngeom_line(color = \"grey50\") +\ngeom_smooth(se = FALSE, span = 0.20)\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\n항공편의 수는 1월(그리고 12월)에 더 적고, 여름(5월~9월)에 더 많다. 데이터가 1년치밖에 없으므로 이 패턴을 정량적으로 많이 다룰 수 없다. 그렇지만 도메인 지식을 사용하여 잠재적인 이유를 생각해 낼 수 있다.\n\n\n\n\n\n먼저 토요일의 비행 횟수를 정확하게 예측하지 못한 문제를 다뤄보면 처음에는 토요일로 한정한 원 데이터로 돌아가는 것이 좋다.\n\n\ndaily %>%\nfilter(wday == \"Sat\") %>%\nggplot(aes(date, n)) +\ngeom_point() +\ngeom_line() +\nscale_x_date(\n    NULL,\n    date_breaks = \"1 month\",\n    date_labels = \"%b\"\n    )\n\n\n\n\n\n이 패턴은 여름 휴가로 인해 발생된 것으로 추측하다. 사람들은 대부분 여름에 휴가를 휴가를 위해 토요일에 출발하는 것을 개의치 않는다. 이 플롯을 보면 여름 휴가 기간은 6월 초에서 8월 말까지로 추측할 수 있다. 이 기간은 주립 학교의 여름방학 기간(2013년의 여름방학은 6월 26일부터 9월 9일까지)과 꽤 잘 맞는 것처럼 보인다. 가을보다 봄에 토요일 비행이 더 많은 이유는 무엇인가? 미국인 친구들에게 물어보니 가을에는 추수감사절과 크리스마스가 있어 가족 휴가를 계획하는 것이 일반적이지 않다는 의견을 주었다. 확신할 수 있는 데이터는 없지만 그럴듯한 가설인 것 같다. 대략 세 개의 학기를 포함하는 ’학기(term)’변수를 만들고 플롯으로 확인해보자.\n\n\nterm <- function(date){\n    cut(date,\n        breaks = ymd(20130101, 20130605, 20130825, 20140101),\n        labels = c(\"spring\", \"summer\", \"fall\")\n        )\n    }\n\ndaily <- daily %>%\nmutate(term = term(date))\n\n\ndaily %>%\nfilter(wday == \"Sat\") %>%\nggplot(aes(date, n, color = term)) +\n       geom_point(alpha = 1/3) +\n       geom_line() +\n       scale_x_date(\n           NULL,\n           date_breaks = \"1 month\",\n           date_labels = \"%b\"\n           )\n\n\n\n\n\n이 플롯에서는 변화를 잘 나타내기 위해 날짜를 수동으로 조정했다. 시각화를 사용하여 함수의 역할을 이용하도록 도와주는 것은 매우 강력하고 일반적인 기술이다. 이 새로운 변수가 다른 요인에 어떤 영향을 미치는지 확인하는 것은 유용하다.\n\n\ndaily %>%\nggplot(aes(wday, n, color = term)) +\ngeom_boxplot()\n\n\n\n\n\n학기 전반에 걸쳐 상당한 변동이 있는 것처럼 보이므로 각 학기에 대해 별도의 요일 효과를 적용하는 것이 합리적이다.  요일 효과는 모델을 개선하기는 하지만 기대할 수 있는 만큼은 아니다.\n\n\nmod1 <- lm(n ~ wday, data = daily)\nmod2 <- lm(n ~ wday * term, data = daily)\n\n\ndaily %>%\ngather_residuals(without_term = mod1, with_term = mod2) %>%\nggplot(aes(date, resid, color = model)) +\ngeom_line(alpha = 0.75)\n\n\n\n\n\n모델로 예측한 값을 원 데이터에 겹쳐 그리면 문제를 확인할 수 있다.\n\n\ngrid <- daily %>%\ndata_grid(wday, term) %>%\nadd_predictions(mod2, \"n\")\n\nggplot(daily, aes(wday, n)) +\ngeom_boxplot() +\ngeom_point(data = grid, color = \"red\") +\nfacet_wrap(~ term)\n\n\n\n\n모델은 평균 효과를 찾지만, 값이 큰 이상값들이 많이므로 평균값은 일반적인 값과 멀어지는 경향이 있다. 이 문제는 이상값에 영향을 덜 받는(robust)모델을 사용하여 완화할 수 있다. 바로 MASS::rlm()을 사용하는 것이다. 이 함수는 이상값이 추정값에 미치는 영향을 줄이고 요일 패턴을 제거하는 모델을 제공한다.\n\nmod3 <- MASS::rlm(n ~ wday * term, data = daily)\n\ndaily %>%\nadd_residuals(mod3, \"resid\") %>%\nggplot(aes(date, resid)) +\ngeom_hline(yintercept = 0, size = 2, color = \"white\") +\ngeom_line()\n\n\n\n\n장기적인 추세와 양과 음의 이상값을 훨씬 쉽게 확인할 수 있다.\n\n\n\n\n많은 모델과 시각화를 경험해보고 있다면 변수 생성 과정을 함수로 묶어 항상 같은 변형을 적용하는 것이 좋다. 예를 들어 다음과 같이 작성할 수 있다.\n\n\ncompute_vars <- function(data){\n    data %>%\n    mutate(\n        term = term(date),\n        wday = wday(date, label = TRUE)\n        )\n    }\n\n\n또 다른 옵션은 모델 수식셍 변형을 바로 넣는 것이다.\n\n\nwday2 <- function(x) wday(x, label = TRUE)\nmod3 <- lm(n ~ wday2(date) * term(date), data = daily)\n\n\n두 방법 모두 합리적이다. 변형된 변수를 명시적으로 만드는 것은 작업을 확인하거나 변수를 시각화에 사용하려는 경우 유용하다. 그러나 여러 열을 반환하는 변형(예: 스플라인)은 쉽게 사용할 수 없다. 모델 함수에 변형을 포함하면 모델 자체에서 변형되기 때문에 다양한 데이터셋으로 작업하는 경우에 좀 더 쉽게 사용할 수 있다.\n\n\n\n\n이전 절에서는 모델을 향상하기 위해 도메인 지식(미국의 학기가 여행에 미치는 영향)을 사용했다. 모델에 명시적으로 지식을 포함시키는 방법 대신 다차원의 데이터를 포함하도록 하는 방식도 있다. 그것은 더 유연한 모델을 사용하여 관심 있는 패턴을 포착하는 것이다. 이때 간단한 선형 추세는 적합하지 않기 때문에 1년의 기간에 대해서 매끄러운 곡선을 적합하기 위해 자연스러운 스플라인을 적용해볼 수 있다.\n\nlibrary('splines')\n\n\nmod <- MASS::rlm(n ~ wday * ns(date, 5), data = daily)\n\ndaily %>%\ndata_grid(wday, date = seq_range(date, n = 13)) %>%\nadd_predictions(mod) %>%\nggplot(aes(date, pred, color = wday)) +\ngeom_line() +\ngeom_point()\n\n\n\n\n\n토요일의 비행 횟수에서 강한 패턴을 확인할 수 있다. 이는 원 데이터에서 보았던 패턴이므로 안심할 수 있는 결과이다. 서로 다른 접근법으로 같은 시그널을 얻는다면 그건 좋은 신호라 할 수 있다."
  },
  {
    "objectID": "posts/time-series/시계열자료분석-실습5.html",
    "href": "posts/time-series/시계열자료분석-실습5.html",
    "title": "(수업) 시계열 자료분석 실습 5",
    "section": "",
    "text": "AR, MA, ARMA\n\nlibrary('tidyverse')\nlibrary('gridExtra')\nlibrary('forecast')\n\n\n\n\n\n\n함수로 생성하기\nn개 보다 100개 더 생성하는 이유 : 초기값을 만들고 업데이트할 때 초기값의 영향을 줄여주기 위해 앞에 100개 없애기 위해서 쌩으로 n개만 쓰면 초기값 영향 많이 받음.\n\n\nsim_ar1 <- function(n, phi, mu, sigma){\n    z <- rep(mu, n + 100)\n    for(k in 2 : (n + 100)){\n        z[k] <- mu + phi*(z[k-1] - mu) + rnorm(1, 0, sigma)\n        }\n    return(z[-(1:100)])\n    }\n\n- 전체중에서 앞에꺼 100개 떼고 생성\n\n정상시계열이 되기 위해서는 \\(\\phi\\)가 1보다 작기만 하면 됨. 평균은 그냥 간단하게 0으로 함.\n\n\nn <- 100\nphi <- -0.5\nmu <- 0\nsigma <- 1\n\n\ntmp.data <- data.frame(\n    t = 1:n,\n    z = sim_ar1(n, phi, mu, sigma)\n    )\n\n\np1 <- ggplot(tmp.data, aes(t, z)) +\ngeom_line(col = 'steelblue', lwd = 1.2) +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\nggtitle(paste0(\"Time series plot : AR(1) - phi = \", phi)) +\ntheme_bw() +\ntheme(axis.title.y = element_blank())\n\np2 <- ggAcf(tmp.data$z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) + \nggtitle(\"SACF\") +\ntheme(axis.title.y = element_blank())\n\np3 <- ggPacf(tmp.data$z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle('SPACF') +\ntheme(axis.title.y = element_blank())\n\n\ngrid.arrange(p1, p2, p3, nrow = 2,\n             layout_matrix = rbind(c(1, 1),\n                                   c(2, 3)))\n\n\n\n\n\n해석 : 0을 기준으로 대칭적으로 움직임(정상 시계열: 추세도 없고 계절도 없어보임), AR(1)은 pacf를 봐야하는데 첫 번째와 두 번째가 유의하게 나옴. 근데 원래 알기로는 첫 번째만 유의하고 두 번째부터 유의하지 않아야하는데 이거는 100개의 sampling이라 약간의 오차 표본을 10000개씩 뽑아보면 이론에 근접하게 나옴.\n\n\n\n\n\\(Z_t = \\delta + \\phi_1*Z_{t-1} + ... + \\phi_p * Z_{t-p} + \\epsilon_t\\)\n\nsim_ar <- function(n, mu, phi, sigma){\n    p <- length(phi) # 차수\n    z <- rep(mu, (100 + n))\n    delta <- (1-sum(phi))*mu \n    \n    for(k in (length(phi) + 1) : (n + 100)){\n        \n        z[k] <- delta + sum(z[(k-1):(k-p)]*phi) + rnorm(1, 0, sigma)\n        }\n    return(z[-(1:100)])\n    }\n\n- 예를들어 AR(1)면\n\nz <- sim_ar(100, 0, phi = c(0.5), 1)\n\n\nlayout.matrix <- matrix(c(1, 2, 1, 3), nrow = 2, ncol = 2)\nlayout(mat = layout.matrix)\nplot.ts(z)\nacf(z)\npacf(z)\n\n\n\n\n- 예를들어 AR(2)면\n\nz <- sim_ar(100, 0, phi = c(1.3, -0.7), 1)\n\nlayout.matrix <- matrix(c(1, 2, 1, 3), nrow = 2, ncol = 2)\nlayout(mat = layout.matrix)\nplot.ts(z)\nacf(z)\npacf(z)\n\n\n\n\n\n해석 : pacf보면 2개만 유의한 것을 볼 수 있음.\n\n\n\n\n\n저렇게 손으로 코드 안짜도 되는 것이 이미 패키지 모델 만들어져 있음.\n\n\nz <- arima.sim(n = 100, # 이름이 .sim인 이유는 simulation이라서\n               list(order = c(1, 0, 0), ar = 0.5), # order = c(p, d, q)인데 ARMA는 d가 0인거임, 여기는 AR이니 d, q를 0으로\n               # 뒤에 ar = phi의미\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(2, 0, 0), ar = c(0.5, -0.4)), # sd옵션 추가하면 분산도 변경가능 궁금한 것은 help가서 보기\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\nggplot으로 그리기\n\n\np1 <- ggplot(data.frame(t = 1:length(z), z = as.numeric(z)), aes(t, z)) +\ngeom_line(col = 'steelblue', lwd = 1.2) +\ngeom_hline(yintercept = 0, lty = 2, col = 'grey') +\nggtitle(\"Time series plot : AR(1)\") +\ntheme_bw() +\ntheme(axis.title.y = element_blank())\n\np2 <- ggAcf(z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle(\"SACF\") +\ntheme(axis.title.y = element_blank())\n\np3 <- ggPacf(z, lwd = 1.5) +\ntheme_bw() + ylim(-1, 1) +\nggtitle(\"SPACF\") +\ntheme(axis.title.y = element_blank())\n\ngrid.arrange(p1, p2, p3, nrow = 2,\n             layout_matrix = rbind(c(1, 1),\n                                   c(2, 3)))\n\n\n\n\n\n\n\n\n\n\n\n함수로 생성하기\n\n\\(Z_t = \\epsilon_t - \\theta_1 * \\epsilon_{t-1} + ... + \\theta_q * \\epsilon_{t-q}\\)\n\nsim_ma <- function(n, mu, theta, sigma){\n    q <- length(theta)\n    ep <- rnorm(n + 100, 0, sigma)\n    z <- ep\n    \n    for(k in (q+1) : (n + 100)){\n        z[k] <- mu + ep[k] - sum(ep[(k-1):(k-q)]*theta)\n        }\n    return(z[-(1:100)])\n    }\n\n- 예를들어 MA(1)면\n\nz <- sim_ma(100, 0, theta = 0.9, 1)\n\nts.plot(z)\nacf(z)\npacf(z)\n\n\n\n\n\n\n\n\n\n\n\n해석 : MA의 경우 acf보면 되는데 2번째 것까지 유의하게 나오니 맞다.\n이 역시 패키지로 만들어져 있다.\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(0,0,1), ma = -0.9), # 이거 help가서 패키지 짜여진 식을 보면 위에서 손으로 짠 식과 부호가 반대임 그래서 \"-\"붙임.\n               rand.gen = rnorm)\n\nts.plot(z)\nacf(z, lag.max = 24)\npacf(z, lag.max = 24)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nz <- arima.sim(n = 100,\n               list(order = c(0,0,2), ma = c(0.5, -0.2)),\n               rand.gen = rnorm)\n\nts.plot(z)\nacf(z, lag.max = 20)\npacf(z, lag.max = 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n역시 함수 짜서 해도 된다. 여기서는 패키지 써서\n\n\nz <- arima.sim(n = 10000, list(order = c(1, 0, 1),\n                               ar = -0.5, ma = -0.3),\n               rand.gen = rnorm)\n\nplot.ts(z)\nacf(z, lag.max = 20)\npacf(z, lag.max = 20)\n\n\n\n\n\n\n\n\n\n\n\n해석 : acf, pacf 둘 다 감소하고 있다. -> “ARMA모형이네” 참고로 위의 그림에서 acf로만 보면 MA(5)정도를 사용해야할 것 같고, pacf로만 보면 AR(4)정도 사용해야 할 것 같은데 종합해서 ARMA(1, 1)를 사용해버리면 추정해야될 것이 5개, 4개에서 2개로 줄어들기에 더 이득이라 볼 수 있다."
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-15_vector.html",
    "href": "posts/datascience-for-r/2022-08-15_vector.html",
    "title": "vector",
    "section": "",
    "text": "vector\nlist\n\nlibrary('tidyverse')\n\nstop : 멈추고 메시지 표기(이거는 내가 설정한 거) stopifnot : stop을 사용하면 되지만 에러를 검사해야할 항목이 많을 경우 사용 에러아니면 pass, 에러면 경고문과 함께 stop\n\nlist\n\n리스트는 이름을 지정할 수 있다.\n\n\nx_named <- list(a = 1, b = 2, c = 3)\nx_named\n\n\n    $a\n        1\n    $b\n        2\n    $c\n        3\n\n\n\n\n리스트가 다른 벡터들과 다른 점은 객체들을 혼합하여 포함될 수 있다.\n\n\ny <- list(\"a\", 1L, 1.5, TRUE)\ny\n\n\n    'a'\n    1\n    1.5\n    TRUE\n\n\n\n\n리스트 안에 리스트를 넣을 수도 있다.\n\n\nz <- list(list(1, 2), list(3, 4))\nstr(z)\n\nList of 2\n $ :List of 2\n  ..$ : num 1\n  ..$ : num 2\n $ :List of 2\n  ..$ : num 3\n  ..$ : num 4\n\n\n\n리스트 안의 리스트 구조\n\n\nx1 <- list(c(1, 2), c(3, 4))\nx2 <- list(list(1, 2), list(3, 4))\nx3 <- list(1, list(2, list(3)))\n\n\nx1\nx2\nx3\n\n\n    \n12\n\n    \n34\n\n\n\n\n\n    \n    1\n    2\n\n\n    \n    3\n    4\n\n\n\n\n\n\n    1\n    \n    2\n    \n    3\n\n\n\n\n\n\n\n\n서브셋\n\n\na <- list(a = 1:3, b = \"a string\", c = pi, d = list(-1, -5))\na\n\n\n    $a\n        \n123\n\n    $b\n        'a string'\n    $c\n        3.14159265358979\n    $d\n        \n    -1\n    -5\n\n\n\n\n\n\n[는 부분 리스트를 추출한다. 결과는 항상 리스트이다.\n\n\nstr(a[1:2])\n\nList of 2\n $ a: int [1:3] 1 2 3\n $ b: chr \"a string\"\n\n\n\nstr(a[4])\n\nList of 1\n $ d:List of 2\n  ..$ : num -1\n  ..$ : num -5\n\n\n\n[[는 리스트의 단일 구성요소를 추출한다. 리스트의 계층구조에서 한 레벨을 제거한다.\n\n\nstr(a[[1]])\n\n int [1:3] 1 2 3\n\n\n\n$는 리스트의 명명된 요소를 추출하는 단축문자이다. 이는 따옴표가 필요 없다는 것을 제외하고는 [[와 유사하게 동작한다.\n\n\na$a\n\n\n123\n\n\n\na[[\"a\"]]\n\n\n123\n\n\n\n결국, [는 더 작은 새 리스트를 반환하는 것이고, [[는 리스트 안으로 내려가는 것이다."
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-01-data_handling_a.html",
    "href": "posts/datascience-for-r/2022-08-01-data_handling_a.html",
    "title": "Data handling a",
    "section": "",
    "text": "Data handling a\nsummarize, mutate\n\nlibrary('tidyverse')\nlibrary('nycflights13') #2013년 뉴욕시 출발 항공편 정보 패키지\n\n\nflights %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311517515 2 830 819 11UA1545N14228EWRIAH22714005152013-01-01 05:00:00\n    201311533529 4 850 830 20UA1714N24211LGAIAH22714165292013-01-01 05:00:00\n    201311542540 2 923 850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311544545-110041022-18B6 725N804JBJFKBQN18315765452013-01-01 05:00:00\n    201311554600-6 812 837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4 740 728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n\n\n\n\ndttm는 데이트-타임형(날짜 + 시간) 의미\n\nfilter(flights, month == 1, day == 1) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311517515 2 830 819 11UA1545N14228EWRIAH22714005152013-01-01 05:00:00\n    201311533529 4 850 830 20UA1714N24211LGAIAH22714165292013-01-01 05:00:00\n    201311542540 2 923 850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311544545-110041022-18B6 725N804JBJFKBQN18315765452013-01-01 05:00:00\n    201311554600-6 812 837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4 740 728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n\n\n\n\n\nnear(sqrt(2) ^2, 2)\n\nTRUE\n\n\n\nfilter( flights, month == 11 | month == 12) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    2013111  52359  6352 345  7B6 745N568JBJFKPSE205161723592013-11-01 23:00:00\n    2013111 3522501051232356 87B61816N353JBJFKSYR 36 20922502013-11-01 22:00:00\n    2013111455 500 -5641 651-10US1895N192UWEWRCLT 88 529 5 02013-11-01 05:00:00\n    2013111539 545 -6856 827 29UA1714N38727LGAIAH2291416 5452013-11-01 05:00:00\n    2013111542 545 -3831 855-24AA2243N5CLAAJFKMIA1471089 5452013-11-01 05:00:00\n    2013111549 600-11912 923-11UA 303N595UAJFKSFO3592586 6 02013-11-01 06:00:00\n\n\n\n\n%in% : 이 안에 있는 모든 것 꺼냄\n\nnov_dec <- filter(flights, month %in% c(11,12))\nnov_dec %>% tail\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    20131231NA 855NANA1142NAUA1506NA    EWRJACNA1874 8552013-12-31 08:00:00\n    20131231NA 705NANA 931NAUA1729NA    EWRDENNA1605 7 52013-12-31 07:00:00\n    20131231NA 825NANA1029NAUS1831NA    JFKCLTNA 541 8252013-12-31 08:00:00\n    20131231NA1615NANA1800NAMQ3301N844MQLGARDUNA 43116152013-12-31 16:00:00\n    20131231NA 600NANA 735NAUA 219NA    EWRORDNA 719 6 02013-12-31 06:00:00\n    20131231NA 830NANA1154NAUA 443NA    JFKLAXNA2475 8302013-12-31 08:00:00\n\n\n\n\n\nfilter(flights, !(arr_delay > 120 | dep_delay > 120)) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311517515 2 830 819 11UA1545N14228EWRIAH22714005152013-01-01 05:00:00\n    201311533529 4 850 830 20UA1714N24211LGAIAH22714165292013-01-01 05:00:00\n    201311542540 2 923 850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311544545-110041022-18B6 725N804JBJFKBQN18315765452013-01-01 05:00:00\n    201311554600-6 812 837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4 740 728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n\n\n\n\n\ndf <- tibble(x = c(1, NA, 3))\n\n\ndf\n\n\n\nA tibble: 3 × 1\n\n    x\n    <dbl>\n\n\n     1\n    NA\n     3\n\n\n\n\n\nfilter(df, x >1)\n\n\n\nA tibble: 1 × 1\n\n    x\n    <dbl>\n\n\n    3\n\n\n\n\narrange : desc와 같이 정렬할 때 사용하는 filter\n\narrange(flights, desc(arr_delay)) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    20131 9 641 9001301124215301272HA  51N384HAJFKHNL6404983 9 02013-01-09 09:00:00\n    2013615143219351137160721201127MQ3535N504MQJFKCMH 74 48319352013-06-15 19:00:00\n    2013110112116351126123918101109MQ3695N517MQEWRORD111 71916352013-01-10 16:00:00\n    2013920113918451014145722101007AA 177N338AAJFKSFO354258618452013-09-20 18:00:00\n    2013722 8451600100510441815 989MQ3075N665MQJFKCVG 96 58916 02013-07-22 16:00:00\n    201341011001900 96013422211 931DL2391N959DLJFKTPA139100519 02013-04-10 19:00:00\n\n\n\n\n\ndf <- tibble(x = c(5,2, NA))\narrange(df, x)\n\n\n\nA tibble: 3 × 1\n\n    x\n    <dbl>\n\n\n     2\n     5\n    NA\n\n\n\n\nselect : 관심 있는 열만 보기\n\nselect(flights, year, month, day) %>% head\n\n\n\nA tibble: 6 × 3\n\n    yearmonthday\n    <int><int><int>\n\n\n    201311\n    201311\n    201311\n    201311\n    201311\n    201311\n\n\n\n\n: a ~ b까지\n\nselect(flights, year:arr_delay) %>% head\n\n\n\nA tibble: 6 × 9\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delay\n    <int><int><int><int><int><dbl><int><int><dbl>\n\n\n    201311517515 2 830 819 11\n    201311533529 4 850 830 20\n    201311542540 2 923 850 33\n    201311544545-110041022-18\n    201311554600-6 812 837-25\n    201311554558-4 740 728 12\n\n\n\n\n\nselect(flights, -(year:air_time)) %>% head\n\n\n\nA tibble: 6 × 4\n\n    distancehourminutetime_hour\n    <dbl><dbl><dbl><dttm>\n\n\n    14005152013-01-01 05:00:00\n    14165292013-01-01 05:00:00\n    10895402013-01-01 05:00:00\n    15765452013-01-01 05:00:00\n     7626 02013-01-01 06:00:00\n     7195582013-01-01 05:00:00\n\n\n\n\n- 추가\n\nselect() 안에서 사용할 수 있는 함수들\n- starts_with('abc') : ’abc’로 시작하는 이름에 매칭\n- ends_with(\"xyz\") : ’xyz’로 끝나는 이름에 매칭\n- contains('abc') : ’abc’를 포함한 이름에 매칭\n- num_range('x', 1:3) : x1,x2,x3에 매칭\n\nrename : 변수명 변경\n\nrename(flights, tail_num = tailnum) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttail_numorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311517515 2 830 819 11UA1545N14228EWRIAH22714005152013-01-01 05:00:00\n    201311533529 4 850 830 20UA1714N24211LGAIAH22714165292013-01-01 05:00:00\n    201311542540 2 923 850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311544545-110041022-18B6 725N804JBJFKBQN18315765452013-01-01 05:00:00\n    201311554600-6 812 837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4 740 728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n\n\n\n\neverything: 몇 개의 변수를 데이터프레임 시작 부분으로 옮기고 싶을 때 사용\n\nselect(flights, time_hour, air_time, everything()) %>% head\n\n\n\nA tibble: 6 × 19\n\n    time_hourair_timeyearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestdistancehourminute\n    <dttm><dbl><int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl>\n\n\n    2013-01-01 05:00:00227201311517515 2 830 819 11UA1545N14228EWRIAH1400515\n    2013-01-01 05:00:00227201311533529 4 850 830 20UA1714N24211LGAIAH1416529\n    2013-01-01 05:00:00160201311542540 2 923 850 33AA1141N619AAJFKMIA1089540\n    2013-01-01 05:00:00183201311544545-110041022-18B6 725N804JBJFKBQN1576545\n    2013-01-01 06:00:00116201311554600-6 812 837-25DL 461N668DNLGAATL 7626 0\n    2013-01-01 05:00:00150201311554558-4 740 728 12UA1696N39463EWRORD 719558\n\n\n\n\n\nflights_sml <- select(flights,\n                      year:day,\n                      ends_with('delay'),\n                      distance,\n                      air_time\n                      )\n\nmutate : 새로운 변수 데이터셋 마지막에 추가\n\nmutate(flights_sml,\n       gain = arr_delay - dep_delay,\n       speed = distance / air_time * 60) %>% head\n\n\n\nA tibble: 6 × 9\n\n    yearmonthdaydep_delayarr_delaydistanceair_timegainspeed\n    <int><int><int><dbl><dbl><dbl><dbl><dbl><dbl>\n\n\n    201311 2 111400227  9370.0441\n    201311 4 201416227 16374.2731\n    201311 2 331089160 31408.3750\n    201311-1-181576183-17516.7213\n    201311-6-25 762116-19394.1379\n    201311-4 12 719150 16287.6000\n\n\n\n\ntransmute : mutate에서 새 변수만 남기기\n\ntransmute(flights,\n          gain = arr_delay - dep_delay,\n          hours = air_time / 60,\n          gain_per_hour = gain / hour) %>% head\n\n\n\nA tibble: 6 × 3\n\n    gainhoursgain_per_hour\n    <dbl><dbl><dbl>\n\n\n      93.783333 1.800000\n     163.783333 3.200000\n     312.666667 6.200000\n    -173.050000-3.400000\n    -191.933333-3.166667\n     162.500000 3.200000\n\n\n\n\n%/% : 나누고 정수만 표기\n%% : 나머지\nlag : 한 칸 밀기\nlead : 한 칸 당기기\n\nx <- 1:10\nlag(x)\nlead(x)\n\n\n<NA>123456789\n\n\n\n2345678910<NA>\n\n\ncumsum : 누적 합\ncummean : 누적 평균\n\ncumsum(x)\n\n\n13610152128364555\n\n\n\ncummean(x)\n\n\n11.522.533.544.555.5\n\n\n\n6. summarize로 그룹화 요약\n\nsummarize(flights, delay = mean(dep_delay, na.rm = TRUE))\n\n\n\nA tibble: 1 × 1\n\n    delay\n    <dbl>\n\n\n    12.63907\n\n\n\n\n\nsummarise는 group_by와 함께 써야 유용\n\n\nby_day <- group_by(flights, year, month, day)\n\n\nsummarize(by_day, delay = mean(dep_delay, na.rm = TRUE))\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 365 × 4\n\n    yearmonthdaydelay\n    <int><int><int><dbl>\n\n\n    20131 111.548926\n    20131 213.858824\n    20131 310.987832\n    20131 4 8.951595\n    20131 5 5.732218\n    20131 6 7.148014\n    20131 7 5.417204\n    20131 8 2.553073\n    20131 9 2.276477\n    2013110 2.844995\n    2013111 2.817193\n    2013112 1.596491\n    201311319.873153\n    2013114 2.792657\n    2013115 0.123723\n    201311624.612865\n    2013117 7.648148\n    2013118 6.765864\n    2013119 3.475483\n    2013120 6.783887\n    2013121 7.831858\n    201312212.499435\n    201312310.610360\n    201312419.465423\n    201312521.898534\n    2013126 7.213115\n    2013127 8.377943\n    201312815.138533\n    2013129 2.497149\n    201313028.623441\n    ⋮⋮⋮⋮\n    201312 2 9.021978\n    201312 3 5.975258\n    201312 4 5.366316\n    201312 552.327990\n    201312 616.134509\n    201312 7 4.860327\n    201312 821.515337\n    201312 934.800221\n    2013121026.465494\n    20131211 7.058263\n    20131212 7.527518\n    20131213 5.256995\n    2013121428.361552\n    2013121519.573871\n    2013121611.741127\n    2013121740.705602\n    2013121814.008395\n    2013121916.372165\n    2013122017.266254\n    2013122120.344956\n    2013122229.239865\n    2013122332.254149\n    20131224 6.765957\n    20131225 7.552448\n    2013122614.417204\n    2013122710.937630\n    20131228 7.981550\n    2013122922.309551\n    2013123010.698113\n    20131231 6.996053\n\n\n\n\n\nby_dest <- group_by(flights, dest)\ndelay <- summarize(by_dest,\n                   count = n(),\n                   dist = mean(distance, na.rm = TRUE),\n                   delay = mean(arr_delay, na.rm = TRUE)\n                   )\n\n\ndelay %>% head\n\n\n\nA tibble: 6 × 4\n\n    destcountdistdelay\n    <chr><int><dbl><dbl>\n\n\n    ABQ  2541826.0000 4.381890\n    ACK  265 199.0000 4.852273\n    ALB  439 143.000014.397129\n    ANC    83370.0000-2.500000\n    ATL17215 757.108211.300113\n    AUS 24391514.2530 6.019909\n\n\n\n\n\ndelay <- filter(delay, count > 20, dest != \"HNL\")\ndelay %>% head\n\n\n\nA tibble: 6 × 4\n\n    destcountdistdelay\n    <chr><int><dbl><dbl>\n\n\n    ABQ  2541826.0000 4.381890\n    ACK  265 199.0000 4.852273\n    ALB  439 143.000014.397129\n    ATL17215 757.108211.300113\n    AUS 24391514.2530 6.019909\n    AVL  275 583.5818 8.003831\n\n\n\n\n\nggplot(data = delay, mapping = aes(x = dist, y = delay)) + \ngeom_point(aes(size = count), alpha = 1/3) +\ngeom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'loess' and formula 'y ~ x'\n\n\n\n\n\n\n\ndelays <- flights %>%\ngroup_by(dest) %>%\nsummarize(\n    count = n(),\n    dist = mean(distance, na.rm = TRUE),\n    delay = mean(arr_delay, na.rm = TRUE)\n    ) %>%\nfilter(count > 20, dest != \"HNL\")\n\n\ndelays %>% head\n\n\n\nA tibble: 6 × 4\n\n    destcountdistdelay\n    <chr><int><dbl><dbl>\n\n\n    ABQ  2541826.0000 4.381890\n    ACK  265 199.0000 4.852273\n    ALB  439 143.000014.397129\n    ATL17215 757.108211.300113\n    AUS 24391514.2530 6.019909\n    AVL  275 583.5818 8.003831\n\n\n\n\n\nflights %>% \ngroup_by(year, month, day) %>%\nsummarize(mean = mean(dep_delay, na.rm = TRUE)) %>% head\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 6 × 4\n\n    yearmonthdaymean\n    <int><int><int><dbl>\n\n\n    20131111.548926\n    20131213.858824\n    20131310.987832\n    201314 8.951595\n    201315 5.732218\n    201316 7.148014\n\n\n\n\n\nnot_cancelled <- flights %>%\nfilter(!is.na(dep_delay), !is.na(arr_delay))\nnot_cancelled %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311517515 2 830 819 11UA1545N14228EWRIAH22714005152013-01-01 05:00:00\n    201311533529 4 850 830 20UA1714N24211LGAIAH22714165292013-01-01 05:00:00\n    201311542540 2 923 850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311544545-110041022-18B6 725N804JBJFKBQN18315765452013-01-01 05:00:00\n    201311554600-6 812 837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4 740 728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n\n\n\n\n\nnot_cancelled %>% \ngroup_by(year, month, day) %>%\nsummarize(mean = mean(dep_delay)) %>% head\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 6 × 4\n\n    yearmonthdaymean\n    <int><int><int><dbl>\n\n\n    20131111.435620\n    20131213.677802\n    20131310.907778\n    201314 8.965859\n    201315 5.732218\n    201316 7.145959\n\n\n\n\n\ndelays <- not_cancelled %>%\ngroup_by(tailnum) %>%\nsummarize(\n    delay = mean(arr_delay)\n    )\n\n\ndelays %>% head # tailnum : 비행기 등록번호\n\n\n\nA tibble: 6 × 2\n\n    tailnumdelay\n    <chr><dbl>\n\n\n    D942DN31.500000\n    N0EGMQ 9.982955\n    N1015612.717241\n    N102UW 2.937500\n    N103US-6.934783\n    N104UW 1.804348\n\n\n\n\ngeom_freqpoly : 요약된 수치 값들의 분포를 보여주는(알아서 구간 cut하고 histplot내주는)\n\nggplot(data = delays, mapping = aes(x = delay)) +\ngeom_freqpoly(binwidth = 10)\n\n\n\n\n\n애초에 평균으로 요약된 데이터로 구한 plot으로 특정 한공기 종류는 도착 지연시간 평균이 300분을 넘어가는 것을 볼 수 있다.\n\n\ndelays <- not_cancelled %>%\n    group_by(tailnum) %>%\n    summarize(\n        delay = mean(arr_delay, na.rm=TRUE),\n        n = n()\n        )\n\n\ndelays %>% head # n만 추가\n\n\n\nA tibble: 6 × 3\n\n    tailnumdelayn\n    <chr><dbl><int>\n\n\n    D942DN31.500000  4\n    N0EGMQ 9.982955352\n    N1015612.717241145\n    N102UW 2.937500 48\n    N103US-6.934783 46\n    N104UW 1.804348 46\n\n\n\n\n\nggplot(data = delays, mapping = aes(x = n, y = delay)) +\ngeom_point(alpha = 0.1)\n\n\n\n\n\n해석 : n은 해당 비행기 기종의 운행 횟수를 나타낸 것으로 운행횟수가 많이질수록 평균 지연시간의 변동폭이 적어짐을 알 수 있다.(평균이기에)반대로 평균 운행횟수가 적은 경우 변동폭이 비교적 더 큼.\n\n\nnot_cancelled %>% \ngroup_by(year, month, day) %>%\nsummarize(\n    avg_delay1 = mean(arr_delay),\n    avg_delay2 = mean(arr_delay[arr_delay > 0])\n    ) %>% head\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 6 × 5\n\n    yearmonthdayavg_delay1avg_delay2\n    <int><int><int><dbl><dbl>\n\n\n    20131112.65102332.48156\n    20131212.69288832.02991\n    201313 5.73333327.66087\n    201314-1.93281928.30976\n    201315-1.52580222.55882\n    201316 4.23642924.37270\n\n\n\n\n\nnot_cancelled %>% \ngroup_by(dest) %>% \nsummarize(distance_sd = sd(distance)) %>%\narrange(desc(distance_sd)) %>% head\n\n\n\nA tibble: 6 × 2\n\n    destdistance_sd\n    <chr><dbl>\n\n\n    EGE10.542765\n    SAN10.350094\n    SFO10.216017\n    HNL10.004197\n    SEA 9.977993\n    LAS 9.907786\n\n\n\n\n\nnot_cancelled %>% \ngroup_by(year, month, day) %>%\nsummarize(\n    first = min(dep_time),\n    last = max(dep_time)\n    ) %>% head\n\n`summarise()` has grouped output by 'year', 'month'. You can override using the\n`.groups` argument.\n\n\n\n\nA grouped_df: 6 × 5\n\n    yearmonthdayfirstlast\n    <int><int><int><int><int>\n\n\n    2013115172356\n    201312 422354\n    201313 322349\n    201314 252358\n    201315 142357\n    201316 162355\n\n\n\n\nrange : 범위를 알려주는 함수 최솟값과 최댓값을 표시\n\nnot_cancelled %>%\ngroup_by(year, month, day) %>%\nmutate(r = min_rank(desc(dep_time))) %>%\nfilter(r %in% range(r)) %>% head\n\n\n\nA grouped_df: 6 × 20\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hourr\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm><int>\n\n\n    201311 517 515  2830819 11UA1545N14228EWRIAH2271400 5152013-01-01 05:00:00831\n    20131123562359 -3425437-12B6 727N588JBJFKBQN186157623592013-01-01 23:00:00  1\n    201312  422359 43518442 36B6 707N580JBJFKSJU189159823592013-01-02 23:00:00928\n    20131223542359 -5413437-24B6 727N789JBJFKBQN180157623592013-01-02 23:00:00  1\n    201313  322359 33504442 22B6 707N763JBJFKSJU193159823592013-01-03 23:00:00900\n    20131323492359-10434445-11B6 739N729JBJFKPSE199161723592013-01-03 23:00:00  1\n\n\n\n\nn_distinct : 유일값 개수 카운트 여기서는 각 도착지마다의 항공사의 종류 갯수를 나타냄\n\nnot_cancelled %>%\ngroup_by(dest) %>%\nsummarize(carriers = n_distinct(carrier)) %>%\narrange(desc(carriers)) %>% head\n\n\n\nA tibble: 6 × 2\n\n    destcarriers\n    <chr><int>\n\n\n    ATL7\n    BOS7\n    CLT7\n    ORD7\n    TPA7\n    AUS6\n\n\n\n\n- 이건 각 지역으로 가는 도착 총 항공편 수\n\nnot_cancelled %>%\ncount(dest) %>% head\n\n- 해당 항공기가 비행한 총 마일 수\nwt : weight약자로 count()에서 사용시 가중 합을 의미\n\nnot_cancelled %>%\ncount(tailnum, wt = distance) %>% head\n\n\nsummarize()의 sum과 mean의미\n- sum\n\nnot_cancelled %>%\ngroup_by(year, month, day) %>%\nsummarize(n_early = sum(dep_time < 500)) %>% head\n\n\n여기서 sum(x > 10), mean(y == 0) 같은 거 사용하면 결과 값이 TRUE, FALSE로 나오기에 밑에 결과값처럼 summarize(sum()) 의 결과 값은 TRUE 의 합(개수)을 알려줌.summarize(mean())의 경우 비율을 알려줌.\n\n- mean\n\nnot_cancelled %>%\ngroup_by(year, month, day) %>% \nsummarize(hour_prop = mean(arr_delay > 60)) %>% head\n\n- day\n\ndaily <- group_by(flights, year, month, day)\n(per_day <- summarize(daily, flights = n())) %>% head\n\n\nper_month <- summarize(per_day, flights = sum(flights))\n\n\n위의 경고문 grouping한거에 summarize를 또 씌울 때 나타나는 말이다. 바깥에()를 한번 씌워주면 뒤에서부터 변수 날리면서 통합시켜서 summarize해줌. 여기서는 day 날아감, 그리고 day의 한 단계 위인 해당 month로 통합 한번 더 한다면 month 날리고 그에 해당하는 영역(같은year)까지 통합시킨 결과 보여줌.\n\n- month\n\n(per_month <- summarize(per_day, flights = sum(flights)))\n\n- year\n\n(per_year <- summarize(per_month, flights = sum(flights)))\n\n- 주의 사항\n이러한 점진적 요약할때 sum과 count는 괜찮으나 중앙값의 경우 그룹별 중앙값의 중앙값은 실제 전체 중앙값과 다르다.\nungroup : 그룹화 제거\n\ndaily %>%\nungroup() %>% # date 기반 그룹화 해제\nsummarize(flights = n()) #모든 항공편\n\n\n\n\n7. mutate로 그룹화 요약\n\ngroup_by는 summarize()에서 가장 유용하지만 mutate()와 filter()에서도 가능\n\n\nflights_sml %>% \ngroup_by(year, month, day) %>%\nfilter(rank(desc(arr_delay)) < 10) %>% head\n\n\npopular_dests <- flights %>%\ngroup_by(dest) %>%\nfilter(n() > 365)\npopular_dests %>% head\n\n\npopular_dests %>%\nfilter(arr_delay > 0) %>%\nmutate(prop_delay = arr_delay / sum(arr_delay)) %>%\nselect(year:day, dest, arr_delay, prop_delay) %>% head"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-06_factor.html",
    "href": "posts/datascience-for-r/2022-08-06_factor.html",
    "title": "factor",
    "section": "",
    "text": "factor in ggplot, factor in tibble(fct_record, fct_collapse)\n\nlibrary('tidyverse')\n\n\n\n\n팩터형은 범주형 변수에 사용되는데, 범주형 변수란 가질 수 있는 값이 미리 고정되고 또 알려진 변수를 말한다. 팩터형은 문자형 벡터를 알파벳순이 아닌 순서로 표시하고 싶을 때도 이용할 수 있다. 팩터형이 문자형보다 다루기 쉽기에, 베이스 R의 함수들은 문자형을 자동으로 팩터형으로 변환한다. 다시 말해 팩터형이 사실 도움이 되지 않는 경우에도 나타나는 경우가 많이 있다는 의미다.\n\n- 월을 기록한 변수 예시\n\nx1 <- c(\"Dec\", \"Apr\", \"Jan\", \"Mar\")\n\n\nx1\n\n\n'Dec''Apr''Jan''Mar'\n\n\n- 문자형의 경우 오타를 입력했거나 정렬을 하고자 할 때 유용한 순서로 정렬이 되지 않는다.\n\nsort(x1)\n\n\n'Apr''Dec''Jan''Mar'\n\n\n\n팩터형을 만들기 위해서는 먼저 선례(?)를 만들어 주어야 한다.\n\n\nmonth_levels <- c(\n    \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n    \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"\n    )\n\n\nmonth_levels\n\n\n'Jan''Feb''Mar''Apr''May''Jun''Jul''Aug''Sep''Oct''Nov''Dec'\n\n\n\ny1 <- factor(x1, levels = month_levels)\n\n\ny1\n\n\nDecAprJanMar\n\n\n    \n        Levels:\n    \n    \n    'Jan''Feb''Mar''Apr''May''Jun''Jul''Aug''Sep''Oct''Nov''Dec'\n\n\n\n- 선례를 바탕으로 정렬\n\nsort(y1)\n\n\nJanMarAprDec\n\n\n    \n        Levels:\n    \n    \n    'Jan''Feb''Mar''Apr''May''Jun''Jul''Aug''Sep''Oct''Nov''Dec'\n\n\n\n- 오타가 추가된 예시\n\nx2 <- c(\"Dec\", \"Apr\", \"Jam\", \"Mar\")\n\n\ny2 <- factor(x2, levels = month_levels)\n\n- 레벨 집합(선례)에 포함되지 않는 값은 NA로 변환된다.\n\ny2\n\n\nDecApr<NA>Mar\n\n\n    \n        Levels:\n    \n    \n    'Jan''Feb''Mar''Apr''May''Jun''Jul''Aug''Sep''Oct''Nov''Dec'\n\n\n\n\nparse_factor사용하면 NA가 나올시 warning뜬다.\n\n\ny2 <- parse_factor(x2, levels = month_levels)\n\nWarning message:\n“1 parsing failure.\nrow col           expected actual\n  3  -- value in level set    Jam\n”\n\n\n- levels입력안하면 그냥 알파벳 순서로 나열\n\nfactor(x1)\n\n\nDecAprJanMar\n\n\n    \n        Levels:\n    \n    \n    'Apr''Dec''Jan''Mar'\n\n\n\n\n\n\n- 설문조사 샘플 데이터\n\ngss_cat %>% head\n\n\n\nA tibble: 6 × 9\n\n    yearmaritalageracerincomepartyidreligdenomtvhours\n    <int><fct><int><fct><fct><fct><fct><fct><int>\n\n\n    2000Never married26White$8000 to 9999 Ind,near rep      Protestant        Southern baptist12\n    2000Divorced     48White$8000 to 9999 Not str republicanProtestant        Baptist-dk whichNA\n    2000Widowed      67WhiteNot applicableIndependent       Protestant        No denomination  2\n    2000Never married39WhiteNot applicableInd,near rep      Orthodox-christianNot applicable   4\n    2000Divorced     25WhiteNot applicableNot str democrat  None              Not applicable   1\n    2000Married      25White$20000 - 24999Strong democrat   Protestant        Southern baptistNA\n\n\n\n\n팩터형이 티블로 저장되면 해당하는 레벨들을 쉽게 볼 수 없는데 볼 수 있는 방법1)은 count이다.\n\ngss_cat %>%\ncount(race)\n\n\n\nA tibble: 3 × 2\n\n    racen\n    <fct><int>\n\n\n    Other 1959\n    Black 3129\n    White16395\n\n\n\n\n방법2) 막대 그래프\n\nggplot(gss_cat, aes(race)) + geom_bar()\n\n\n\n\nscale_x_discrete(drop = FALSE) : ggplot에서 값이 없는 레벨을 보이게하기\n\nggplot(gss_cat, aes(race)) +\ngeom_bar() +\nscale_x_discrete(drop = FALSE)\n\n\n\n\n유효하지만 이 데이터 셋에서 나타나지 않는 값을 나타냄\n- 종교에 따른 하루 TV 시청시간의 평균\n\nrelig_summary <- gss_cat %>%\ngroup_by(relig) %>%\nsummarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n    )\n\nggplot(relig_summary, aes(tvhours, relig)) + geom_point()\n\n\n\n\n- tvhours순위로 religion순위 재 정렬\n\nggplot(relig_summary, aes(tvhours, fct_reorder(relig, tvhours))) + geom_point()\n\n\n\n\n- tibble자체를 순서 정렬시키고 그리는 방법\n\nrelig_summary %>%\nmutate(relig = fct_reorder(relig, tvhours)) %>%\nggplot(aes(tvhours, relig)) +\ngeom_point()\n\n\n\n\n- 보고서 소득 레벨에 따라 평균나이가 어떻게 변화하는지 보여주는 plot\n\nrincome_summary <- gss_cat %>%\ngroup_by(rincome) %>%\nsummarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n    )\n\n\nrincome_summary\n\n\n\nA tibble: 16 × 4\n\n    rincomeagetvhoursn\n    <fct><dbl><dbl><int>\n\n\n    No answer     45.450292.904762 183\n    Don't know    45.609023.411290 267\n    Refused       47.610822.481973 975\n    $25000 or more44.212172.2342087363\n    $20000 - 2499941.533652.7847531283\n    $15000 - 1999939.961802.9122451048\n    $10000 - 1499941.113013.0165411168\n    $8000 to 9999 41.082353.148571 340\n    $7000 to 7999 38.244682.645455 188\n    $6000 to 6999 40.299073.174312 215\n    $5000 to 5999 37.810573.163793 227\n    $4000 to 4999 38.875003.145299 226\n    $3000 to 3999 37.821823.312102 276\n    $1000 to 2999 34.544303.004525 395\n    Lt $1000      40.510493.361842 286\n    Not applicable56.106283.7914687043\n\n\n\n\n\nggplot(rincome_summary, aes(age, fct_reorder(rincome, age))) + geom_point()\n\n\n\n\n- 해당없음(Not applicable)을 다른 특별한 레벨들과 함께 앞으로 가져오기\n\nggplot(rincome_summary, aes(age, fct_relevel(rincome, \"Not applicable\"))) +\ngeom_point()\n\n\n\n\n\nby_age <- gss_cat %>%\nfilter(!is.na(age)) %>%\ncount(age, marital) %>%\ngroup_by(age) %>%\nmutate(prop = n / sum(n))\n\n\nby_age %>% head\n\n\n\nA grouped_df: 6 × 4\n\n    agemaritalnprop\n    <int><fct><int><dbl>\n\n\n    18Never married 890.978021978\n    18Married        20.021978022\n    19Never married2340.939759036\n    19Divorced       30.012048193\n    19Widowed        10.004016064\n    19Married       110.044176707\n\n\n\n\n\nggplot(by_age, aes(age, prop, color = marital)) +\ngeom_line(na.rm = TRUE)\n\n\n\n\nfct_reorder2 : 가장 큰 x값과 연관된 y값으로 팩터형을 재정렬한다. 선 색상은 범례와 정렬되므로 이렇게 하면 plot읽기가 쉬워진다.\n\nggplot(by_age, aes(age, prop, color = fct_reorder2(marital, age, prop))) +\ngeom_line() +\nlabs(color = \"marital\")\n\n\n\n\nfct_infreq : 빈도 오름차순으로 레벨 정렬\n\ngss_cat %>%\nmutate(marital = marital %>% fct_infreq() %>% fct_rev()) %>%\nggplot(aes(marital)) +\ngeom_bar()\n\n\n\n\n\n\n\n\ngss_cat %>% count(partyid)\n\n\n\nA tibble: 10 × 2\n\n    partyidn\n    <fct><int>\n\n\n    No answer          154\n    Don't know           1\n    Other party        393\n    Strong republican 2314\n    Not str republican3032\n    Ind,near rep      1791\n    Independent       4119\n    Ind,near dem      2499\n    Not str democrat  3690\n    Strong democrat   3490\n\n\n\n\nfct_recode : 미리 입력한 대로 팩터 값을 바꿔준다(명시적으로 언급하지 않은 것은 그대로 둠)\n\ngss_cat %>%\nmutate(partyid = fct_recode(partyid,\n                            \"Repubican, strong\"     = \"Strong republican\",\n                            \"Repubican, weak\"       = \"Not str republican\",\n                            \"Independent, near rep\" = \"Ind,near rep\",\n                            \"Independent, near dem\" = \"Ind,near dem\",\n                            \"Democrat, weak\"        = \"Not str democrat\",\n                            \"Democrat, strong\"      = \"Strong democrat\"\n                            )) %>%\ncount(partyid)\n\n\n\nA tibble: 10 × 2\n\n    partyidn\n    <fct><int>\n\n\n    No answer             154\n    Don't know              1\n    Other party           393\n    Repubican, strong    2314\n    Repubican, weak      3032\n    Independent, near rep1791\n    Independent          4119\n    Independent, near dem2499\n    Democrat, weak       3690\n    Democrat, strong     3490\n\n\n\n\n\n나머지(No answer)등을 Other로 묶어서 처리해버리기\n\n\ngss_cat %>%\nmutate(partyid = fct_recode(partyid,\n                            \"Repubican, strong\"     = \"Strong republican\",\n                            \"Repubican, weak\"       = \"Not str republican\",\n                            \"Independent, near rep\" = \"Ind,near rep\",\n                            \"Independent, near dem\" = \"Ind,near dem\",\n                            \"Democrat, weak\"        = \"Not str democrat\",\n                            \"Democrat, strong\"      = \"Strong democrat\",\n                            \"Other\"                 = \"No answer\",\n                            \"Other\"                 = \"Don't know\",\n                            \"Other\"                 = \"Other party\"\n                            )) %>%\ncount(partyid)\n\n\n\nA tibble: 8 × 2\n\n    partyidn\n    <fct><int>\n\n\n    Other                 548\n    Repubican, strong    2314\n    Repubican, weak      3032\n    Independent, near rep1791\n    Independent          4119\n    Independent, near dem2499\n    Democrat, weak       3690\n    Democrat, strong     3490\n\n\n\n\n✖︎ 서로 같지 않은 범주들을 함께 묶는다면 잘못된 결과를 도출할 수 있으므로 신중히 사용해야 한다.\nfct_collapse : fct_recode와 비슷한데 다수를 하나로 병합하고자 할 때 더 편함\n\ngss_cat %>%\nmutate(partyid = fct_collapse(partyid,\n                              other = c(\"No answer\", \"Don't know\", \"Other party\"),\n                              rep = c(\"Strong republican\", \"Not str republican\"),\n                              ind = c(\"Ind,near rep\", \"Independent\", \"Ind,near dem\"),\n                              dem = c(\"Not str democrat\", \"Strong democrat\")\n                              )) %>% \ncount(partyid)\n\n\n\nA tibble: 4 × 2\n\n    partyidn\n    <fct><int>\n\n\n    other 548\n    rep  5346\n    ind  8409\n    dem  7180\n\n\n\n\n- 상위 1등과 나머지는 Other로 묶어서 비교하기\n\ngss_cat %>%\nmutate(relig = fct_lump(relig)) %>%\ncount(relig)\n\n\n\nA tibble: 2 × 2\n\n    relign\n    <fct><int>\n\n\n    Protestant10846\n    Other     10637\n\n\n\n\n- 상위 4등까지만 보고 나머지들은 전부 Other로 묶기\n\ngss_cat  %>% mutate(relig = fct_lump(relig, n = 4)) %>%\ncount(relig, sort = TRUE) %>%\nprint(n = Inf)\n\n# A tibble: 5 × 2\n  relig          n\n  <fct>      <int>\n1 Protestant 10846\n2 Catholic    5124\n3 None        3523\n4 Other       1301\n5 Christian    689"
  },
  {
    "objectID": "posts/datascience-for-r/2022-09-14_purr.html",
    "href": "posts/datascience-for-r/2022-09-14_purr.html",
    "title": "purr와 broom",
    "section": "",
    "text": "중첩된 데이터(Nested Data), 리스트-열(중첩, 벡터화 함수, 다중값 요약), broom\n\nlibrary('tidyverse')\nlibrary('modelr')\nlibrary('gapminder') # 기대 수명과 GDP와 같은 통계량을 통해 시간의 경과에 따른 국가의 변천을 요약\n\n\n\n\n많은 양의 모델을 쉽게 작업할 수 있도록 하는 세 가지 아이디어를 알아보면\n\n\n\n간단한 모델을 여러 개 사용하여 복잡한 데이터셋을 잘 이해한다.\n리스트-열(리스트 형식의 열)을 사용하여 임의의 데이터 구조를 데이터 프레임에 저장한다. 예를 들어 리스트-열은 선형 모델을 포함하는 열을 가질 수 있다.\nbroom 패키지를 사용하여 모델을 타이디 데이터로 변환한다. 타이디 데이터가 존재한다면 이전에 배운 기법들을 적용할 수 있으므로 이는 많은 양의 모델을 작업할 수 있는 좋은 기법이다.\n\n\n\n\n\ngapminder %>% head\n\n\n\nA tibble: 6 × 6\n\n    countrycontinentyearlifeExppopgdpPercap\n    <fct><fct><int><dbl><int><dbl>\n\n\n    AfghanistanAsia195228.801 8425333779.4453\n    AfghanistanAsia195730.332 9240934820.8530\n    AfghanistanAsia196231.99710267083853.1007\n    AfghanistanAsia196734.02011537966836.1971\n    AfghanistanAsia197236.08813079460739.9811\n    AfghanistanAsia197738.43814880372786.1134\n\n\n\n\n\ngapminder %>%\nggplot(aes(year, lifeExp, group = country)) +\ngeom_line(alpha = 1/3)\n\n\n\n\n\n전반적으로는 기대 수명이 꾸준히 증가하고 있는 것처럼 보이지만 자세히 살펴보면 이 패턴을 따르지 않는 국가들이 일부 존재하는 것을 알 수 있다. 이 국가들을 보기 쉽게 만들려면, 즉 숨겨진 추세를 확인하기 어렵게 만드는 강한 신호(전반적인 선형 추세)가 존재할 때, 선형 추세 모델을 적합하여 이 요소들을 구분할 것이다. 모델은 시간에 따라 꾸준히 증가하는 추세를 포착하고 잔차는 남아있는 추세를 보여줄 것이다.\n\n\nnz <- filter(gapminder, country == \"New Zealand\")\nnz %>%\nggplot(aes(year, lifeExp)) +\ngeom_line() +\nggtitle(\"Full data = \")\n\n\n\n\n\nnz_mod <- lm(lifeExp ~ year, data = nz)\nnz %>%\nadd_predictions(nz_mod) %>%\nggplot(aes(year, pred)) +\ngeom_line() +\nggtitle(\"Linear trend + \")\n\n\n\n\n\nnz %>%\nadd_residuals(nz_mod) %>%\nggplot(aes(year, resid)) +\ngeom_hline(yintercept = 0, color = \"white\", size = 3) +\ngeom_line() +\nggtitle(\"Remaining pattern\")\n\n\n\n\n\n\n\n\ngroup_by로 묶어놓고 그에 해당하는 나머지 항목들 리스트(같은 데이터 프레임)로 묶어 정리\n\n\nby_country <- gapminder %>%\ngroup_by(country, continent) %>%\nnest()\n\nby_country %>% head\n\n\n\nA grouped_df: 6 × 3\n\n    countrycontinentdata\n    <fct><fct><list>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367\n\n\n\n\n\nby_country$data[[1]]\n\n\n\nA tibble: 12 × 4\n\n    yearlifeExppopgdpPercap\n    <int><dbl><int><dbl>\n\n\n    195228.801 8425333779.4453\n    195730.332 9240934820.8530\n    196231.99710267083853.1007\n    196734.02011537966836.1971\n    197236.08813079460739.9811\n    197738.43814880372786.1134\n    198239.85412881816978.0114\n    198740.82213867957852.3959\n    199241.67416317921649.3414\n    199741.76322227415635.3414\n    200242.12925268405726.7341\n    200743.82831889923974.5803\n\n\n\n\n\n\n\n\n중첩된 데이터프레임에 모델 적합해보기\n\n\ncountry_model <- function(df){\n    lm(lifeExp ~ year, data = df)\n    }\n\n\nmodels <- map(by_country$data, country_model)\n\n\nmodels %>% head\n\n[[1]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n  -507.5343       0.2753  \n\n\n[[2]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n  -594.0725       0.3347  \n\n\n[[3]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n -1067.8590       0.5693  \n\n\n[[4]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n  -376.5048       0.2093  \n\n\n[[5]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n  -389.6063       0.2317  \n\n\n[[6]]\n\nCall:\nlm(formula = lifeExp ~ year, data = df)\n\nCoefficients:\n(Intercept)         year  \n  -376.1163       0.2277  \n\n\n\n\n보기 어려운 형태로 저장되므로 보기 좋게 데이터 프레임 형식으로 저장하기\n\n\nby_country <- by_country %>%\nmutate(model = map(data, country_model))\n\nby_country %>% head\n\n\n\nA grouped_df: 6 × 4\n\n    countrycontinentdatamodel\n    <fct><fct><list><list>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030-594.0725, 0.3346832, -3.999128, -1.622544, 2.24404, 1.970624, 1.767207, 1.333791, 1.150375, 1.056959, -1.035457, -1.339873, -0.312289, -1.213705, -237.0586, 20.01115, 3.248124, 2.926981, 2.675838, 2.194694, 1.963551, 1.822408, -0.3177351, -0.6698783, 0.3099785, -0.6391646, 2, 59.22913, 60.90254, 62.57596, 64.24938, 65.92279, 67.59621, 69.26962, 70.94304, 72.61646, 74.28987, 75.96329, 77.63671, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 55.23, 59.28, 64.82, 66.22, 67.69, 68.93, 70.42, 72, 71.581, 72.95, 75.651, 76.423, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367-1067.859, 0.5692797, -0.2979744, -0.536373, -0.7647716, -0.5071702, -0.2425688, 0.4070326, 0.914634, 2.499235, 1.597837, 0.1594382, -0.8449604, -2.384359, -204.4865, 34.03798, -0.6280719, -0.4013136, -0.1675554, 0.4512029, 0.9279612, 2.481719, 1.549478, 0.08023599, -0.9550057, -2.525247, 2, 43.37497, 46.22137, 49.06777, 51.91417, 54.76057, 57.60697, 60.45337, 63.29976, 66.14616, 68.99256, 71.83896, 74.68536, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231-376.5048, 0.2093399, -2.111654, -1.174353, -0.2200524, 0.7182483, 1.614549, 2.12285, 1.53515, 0.452451, 0.1467517, -0.5839476, -1.590647, -0.9093462, -131.2323, 12.5167, 0.3574398, 1.24968, 2.099921, 2.562161, 1.928402, 0.799642, 0.4478825, -0.3288771, -1.381637, -0.7463962, 2, 32.12665, 33.17335, 34.22005, 35.26675, 36.31345, 37.36015, 38.40685, 39.45355, 40.50025, 41.54695, 42.59365, 43.64035, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 30.015, 31.999, 34, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380-389.6063, 0.2317084, -0.2034359, 0.5520221, 0.1364802, -0.5300618, -0.2576037, -0.0001456876, 0.3023124, -0.0242296, -0.08877156, 0.1596865, 0.06614452, -0.1123974, -239.2323, 13.85415, 0.09303993, -0.5342543, -0.2225486, 0.07415714, 0.4158629, 0.1285686, 0.1032744, 0.3909801, 0.3366858, 0.1973916, 2, 62.68844, 63.84698, 65.00552, 66.16406, 67.3226, 68.48115, 69.63969, 70.79823, 71.95677, 73.11531, 74.27386, 75.4324, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.34, 75.32, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367-376.1163, 0.2277238, 0.7194872, 0.7908683, 0.2522494, -0.7163695, -1.024988, -0.6036072, -0.4922261, -0.05084499, 0.05053613, 0.1819172, 0.5832984, 0.3096795, -258.6399, 13.6159, -0.002715871, -0.9299787, -1.197241, -0.7345042, -0.581767, -0.09902982, 0.04370739, 0.2164446, 0.6591818, 0.426919, 2, 68.40051, 69.53913, 70.67775, 71.81637, 72.95499, 74.09361, 75.23223, 76.37084, 77.50946, 78.64808, 79.7867, 80.92532, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 69.12, 70.33, 70.93, 71.1, 71.93, 73.49, 74.74, 76.32, 77.56, 78.83, 80.37, 81.235, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n\n\n\n\n\n이 방법의 장점은 모든 관련 객체가 함께 저장되므로 필터링하거나 정렬할 때 수동으로 동기화할 필요가 없다.\n\n\nby_country %>%\nfilter(continent == \"Europe\") %>%\nhead\n\n\n\nA grouped_df: 6 × 4\n\n    countrycontinentdatamodel\n    <fct><fct><list><list>\n\n\n    Albania               Europe1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030-594.0725, 0.3346832, -3.999128, -1.622544, 2.24404, 1.970624, 1.767207, 1.333791, 1.150375, 1.056959, -1.035457, -1.339873, -0.312289, -1.213705, -237.0586, 20.01115, 3.248124, 2.926981, 2.675838, 2.194694, 1.963551, 1.822408, -0.3177351, -0.6698783, 0.3099785, -0.6391646, 2, 59.22913, 60.90254, 62.57596, 64.24938, 65.92279, 67.59621, 69.26962, 70.94304, 72.61646, 74.28987, 75.96329, 77.63671, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 55.23, 59.28, 64.82, 66.22, 67.69, 68.93, 70.42, 72, 71.581, 72.95, 75.651, 76.423, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Austria               Europe1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 66.800, 67.480, 69.540, 70.140, 70.630, 72.170, 73.180, 74.940, 76.040, 77.510, 78.980, 79.829, 6927772.000, 6965860.000, 7129864.000, 7376998.000, 7544201.000, 7568430.000, 7574613.000, 7578903.000, 7914969.000, 8069876.000, 8148312.000, 8199783.000, 6137.076, 8842.598, 10750.721, 12834.602, 16661.626, 19749.422, 21597.084, 23687.826, 27042.019, 29095.921, 32417.608, 36126.493-405.9205, 0.2419923, 0.3515385, -0.1784231, 0.6716154, 0.06165385, -0.6583077, -0.3282692, -0.5282308, 0.02180769, -0.08815385, 0.1718846, 0.4319231, 0.07096154, -253.2371, 14.46904, 0.6311732, 0.004321666, -0.7325299, -0.4193814, -0.636233, -0.1030846, -0.2299361, 0.01321234, 0.2563608, -0.1214908, 2, 66.44846, 67.65842, 68.86838, 70.07835, 71.28831, 72.49827, 73.70823, 74.91819, 76.12815, 77.33812, 78.54808, 79.75804, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 66.8, 67.48, 69.54, 70.14, 70.63, 72.17, 73.18, 74.94, 76.04, 77.51, 78.98, 79.829, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Belgium               Europe1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 68.000, 69.240, 70.250, 70.940, 71.440, 72.800, 73.930, 75.350, 76.460, 77.530, 78.320, 79.441, 8730405.000, 8989111.000, 9218400.000, 9556500.000, 9709100.000, 9821800.000, 9856303.000, 9870200.000, 10045622.000, 10199787.000, 10311970.000, 10392226.000, 8343.105, 9714.961, 10991.207, 13149.041, 16672.144, 19117.974, 20979.846, 22525.563, 25575.571, 27561.197, 30485.884, 33692.605-340.2412, 0.2090846, 0.1080769, 0.3026538, 0.2672308, -0.08819231, -0.6336154, -0.3190385, -0.2344615, 0.1401154, 0.2046923, 0.2292692, -0.02615385, 0.04942308, -255.1025, 12.50144, 0.2015463, -0.1355897, -0.6627256, -0.3298616, -0.2269975, 0.1658665, 0.2487306, 0.2915946, 0.05445866, 0.1483227, 2, 67.89192, 68.93735, 69.98277, 71.02819, 72.07362, 73.11904, 74.16446, 75.20988, 76.25531, 77.30073, 78.34615, 79.39158, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 68, 69.24, 70.25, 70.94, 71.44, 72.8, 73.93, 75.35, 76.46, 77.53, 78.32, 79.441, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Bosnia and HerzegovinaEurope1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 53.8200, 58.4500, 61.9300, 64.7900, 67.4500, 69.8600, 70.6900, 71.1400, 72.1780, 73.2440, 74.0900, 74.8520, 2791000.0000, 3076000.0000, 3349000.0000, 3585000.0000, 3819000.0000, 4086000.0000, 4172693.0000, 4338977.0000, 4256013.0000, 3607000.0000, 4165416.0000, 4552198.0000, 973.5332, 1353.9892, 1709.6837, 2172.3524, 2860.1698, 3528.4813, 4126.6132, 4314.1148, 2546.7814, 4766.3559, 6018.9752, 7446.2988-624.6327, 0.3497552, -4.269564, -1.38834, 0.3428834, 1.454107, 2.365331, 3.026555, 2.107779, 0.8090023, 0.09822611, -0.5845501, -1.487326, -2.474103, -234.5468, 20.91232, 1.36364, 2.446497, 3.329354, 3.962211, 3.015068, 1.687925, 0.9487816, 0.2376386, -0.6935044, -1.708647, 2, 58.08956, 59.83834, 61.58712, 63.33589, 65.08467, 66.83345, 68.58222, 70.331, 72.07977, 73.82855, 75.57733, 77.3261, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 53.82, 58.45, 61.93, 64.79, 67.45, 69.86, 70.69, 71.14, 72.178, 73.244, 74.09, 74.852, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Bulgaria              Europe1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 59.600, 66.610, 69.510, 70.420, 70.900, 70.810, 71.080, 71.340, 71.190, 70.320, 72.140, 73.005, 7274900.000, 7651254.000, 8012946.000, 8310226.000, 8576200.000, 8797022.000, 8892098.000, 8971958.000, 8658506.000, 8066057.000, 7661799.000, 7322858.000, 2444.287, 3008.671, 4254.338, 5577.003, 6597.494, 7612.240, 8224.192, 8239.855, 6302.623, 5970.389, 7696.778, 10680.793-218.6473, 0.1456888, -6.137308, 0.1442483, 2.315804, 2.49736, 2.248916, 1.430472, 0.972028, 0.5035839, -0.3748601, -1.973304, -0.8817483, -0.7451923, -241.5994, 8.710924, 3.464353, 3.745675, 3.596997, 2.87832, 2.519642, 2.150964, 1.372286, -0.1263916, 1.064931, 1.301253, 2, 65.73731, 66.46575, 67.1942, 67.92264, 68.65108, 69.37953, 70.10797, 70.83642, 71.56486, 72.2933, 73.02175, 73.75019, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 59.6, 66.61, 69.51, 70.42, 70.9, 70.81, 71.08, 71.34, 71.19, 70.32, 72.14, 73.005, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Croatia               Europe1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 61.210, 64.770, 67.130, 68.500, 69.610, 70.640, 70.460, 71.520, 72.527, 73.680, 74.876, 75.748, 3882229.000, 3991242.000, 4076557.000, 4174366.000, 4225310.000, 4318673.000, 4413368.000, 4484310.000, 4494013.000, 4444595.000, 4481020.000, 4493312.000, 3119.237, 4338.232, 5477.890, 6960.298, 9164.090, 11305.385, 13221.822, 13822.584, 8447.795, 9875.605, 11628.389, 14619.223-376.241, 0.2254594, -2.645782, -0.2130793, 1.019624, 1.262326, 1.245029, 1.147732, -0.1595653, -0.2268625, -0.3471597, -0.3214569, -0.2527541, -0.5080513, -242.6808, 13.48051, 1.555762, 1.823395, 1.831029, 1.758662, 0.4762956, 0.4339291, 0.3385627, 0.3891962, 0.4828297, 0.2524632, 2, 63.85578, 64.98308, 66.11038, 67.23767, 68.36497, 69.49227, 70.61957, 71.74686, 72.87416, 74.00146, 75.12875, 76.25605, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 61.21, 64.77, 67.13, 68.5, 69.61, 70.64, 70.46, 71.52, 72.527, 73.68, 74.876, 75.748, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n\n\n\n\n\nby_country %>%\narrange(continent, country) %>% \nhead\n\n\n\nA grouped_df: 6 × 4\n\n    countrycontinentdatamodel\n    <fct><fct><list><list>\n\n\n    Algeria     Africa1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367-1067.859, 0.5692797, -0.2979744, -0.536373, -0.7647716, -0.5071702, -0.2425688, 0.4070326, 0.914634, 2.499235, 1.597837, 0.1594382, -0.8449604, -2.384359, -204.4865, 34.03798, -0.6280719, -0.4013136, -0.1675554, 0.4512029, 0.9279612, 2.481719, 1.549478, 0.08023599, -0.9550057, -2.525247, 2, 43.37497, 46.22137, 49.06777, 51.91417, 54.76057, 57.60697, 60.45337, 63.29976, 66.14616, 68.99256, 71.83896, 74.68536, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Angola      Africa1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231-376.5048, 0.2093399, -2.111654, -1.174353, -0.2200524, 0.7182483, 1.614549, 2.12285, 1.53515, 0.452451, 0.1467517, -0.5839476, -1.590647, -0.9093462, -131.2323, 12.5167, 0.3574398, 1.24968, 2.099921, 2.562161, 1.928402, 0.799642, 0.4478825, -0.3288771, -1.381637, -0.7463962, 2, 32.12665, 33.17335, 34.22005, 35.26675, 36.31345, 37.36015, 38.40685, 39.45355, 40.50025, 41.54695, 42.59365, 43.64035, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 30.015, 31.999, 34, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Benin       Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 38.2230, 40.3580, 42.6180, 44.8850, 47.0140, 49.1900, 50.9040, 52.3370, 53.9190, 54.7770, 54.4060, 56.7280, 1738315.0000, 1925173.0000, 2151895.0000, 2427334.0000, 2761407.0000, 3168267.0000, 3641603.0000, 4243788.0000, 4981671.0000, 6066080.0000, 7026113.0000, 8078314.0000, 1062.7522, 959.6011, 949.4991, 1035.8314, 1085.7969, 1029.1613, 1277.8976, 1225.8560, 1191.2077, 1232.9753, 1372.8779, 1441.2849-612.834, 0.3342329, -1.365513, -0.9016772, -0.3128415, 0.2829942, 0.7408298, 1.245666, 1.288501, 1.050337, 0.9611725, 0.1480082, -1.894156, -1.243321, -168.9786, 19.98422, 0.08178907, 0.6384955, 1.057202, 1.522908, 1.526615, 1.249321, 1.121028, 0.2687342, -1.812559, -1.200853, 2, 39.58851, 41.25968, 42.93084, 44.60201, 46.27317, 47.94433, 49.6155, 51.28666, 52.95783, 54.62899, 56.30016, 57.97132, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 38.223, 40.358, 42.618, 44.885, 47.014, 49.19, 50.904, 52.337, 53.919, 54.777, 54.406, 56.728, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Botswana    Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 47.6220, 49.6180, 51.5200, 53.2980, 56.0240, 59.3190, 61.4840, 63.6220, 62.7450, 52.5560, 46.6340, 50.7280, 442308.0000, 474639.0000, 512764.0000, 553541.0000, 619351.0000, 781472.0000, 970347.0000, 1151184.0000, 1342614.0000, 1536536.0000, 1630347.0000, 1639131.0000, 851.2411, 918.2325, 983.6540, 1214.7093, 2263.6111, 3214.8578, 4551.1421, 6205.8839, 7954.1116, 8647.1423, 11003.6051, 12569.8518-65.49586, 0.06066853, -5.307115, -3.614458, -2.015801, -0.5411434, 1.881514, 4.873171, 6.734829, 8.569486, 7.389143, -3.103199, -9.328542, -5.537885, -189.1313, 3.627451, -0.4656616, 0.8496905, 3.113043, 5.945395, 7.647747, 9.323099, 7.983451, -2.668197, -9.052845, -5.421493, 2, 52.92912, 53.23246, 53.5358, 53.83914, 54.14249, 54.44583, 54.74917, 55.05251, 55.35586, 55.6592, 55.96254, 56.26588, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 47.622, 49.618, 51.52, 53.298, 56.024, 59.319, 61.484, 63.622, 62.745, 52.556, 46.634, 50.728, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Burkina FasoAfrica1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 3.197500e+01, 3.490600e+01, 3.781400e+01, 4.069700e+01, 4.359100e+01, 4.613700e+01, 4.812200e+01, 4.955700e+01, 5.026000e+01, 5.032400e+01, 5.065000e+01, 5.229500e+01, 4.469979e+06, 4.713416e+06, 4.919632e+06, 5.127935e+06, 5.433886e+06, 5.889574e+06, 6.634596e+06, 7.586551e+06, 8.878303e+06, 1.035284e+07, 1.225121e+07, 1.432620e+07, 5.432552e+02, 6.171835e+02, 7.225120e+02, 7.948266e+02, 8.547360e+02, 7.433870e+02, 8.071986e+02, 9.120631e+02, 9.317528e+02, 9.462950e+02, 1.037645e+03, 1.217033e+03-675.7942, 0.3639748, -2.709692, -1.598566, -0.5104406, 0.5526853, 1.626811, 2.352937, 2.518063, 2.133189, 1.016315, -0.7395594, -2.233434, -2.408308, -154.8246, 21.76253, 0.2442503, 1.242254, 2.251257, 2.91226, 3.012263, 2.562267, 1.38027, -0.4407268, -1.999723, -2.23972, 2, 34.68469, 36.50457, 38.32444, 40.14431, 41.96419, 43.78406, 45.60394, 47.42381, 49.24369, 51.06356, 52.88343, 54.70331, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 31.975, 34.906, 37.814, 40.697, 43.591, 46.137, 48.122, 49.557, 50.26, 50.324, 50.65, 52.295, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n    Burundi     Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 39.0310, 40.5330, 42.0450, 43.5480, 44.0570, 45.9100, 47.4710, 48.2110, 44.7360, 45.3260, 47.3600, 49.5800, 2445618.0000, 2667518.0000, 2961915.0000, 3330989.0000, 3529983.0000, 3834415.0000, 4580410.0000, 5126023.0000, 5809236.0000, 6121610.0000, 7021078.0000, 8390505.0000, 339.2965, 379.5646, 355.2032, 412.9775, 464.0995, 556.1033, 559.6032, 621.8188, 631.6999, 463.1151, 446.4035, 430.0707-260.2914, 0.1541343, -1.547641, -0.8163124, -0.07498368, 0.657345, 0.3956737, 1.478002, 2.268331, 2.23766, -2.008012, -2.188683, -0.9253543, 0.5239744, -155.2518, 9.215889, 0.3416532, 1.043139, 0.750624, 1.802109, 2.561595, 2.50008, -1.776435, -1.987949, -0.7554638, 0.6630216, 2, 40.57864, 41.34931, 42.11998, 42.89066, 43.66133, 44.432, 45.20267, 45.97334, 46.74401, 47.51468, 48.28535, 49.05603, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 39.031, 40.533, 42.045, 43.548, 44.057, 45.91, 47.471, 48.211, 44.736, 45.326, 47.36, 49.58, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007\n\n\n\n\n\n데이터프레임의 리스트와 모델의 리스트가 분리된 객체인 경우, 하나의 벡터를 재정렬하거나 하위 집합으로 만들 때마다 동기화하기 위해 다른 모든 것을 재정렬하거나 하위 집합으로 만들어야 한다. 만약 이 부분을 놓치게 된다면 코드는 계속 작동하지만 잘못된 결과를 제공할 것이다.\n\n\n\n\n\nby_country <- by_country %>%\nmutate(\n    resids = map2(data, model, add_residuals)\n    )\nby_country %>% head\n\n\n\nA grouped_df: 6 × 5\n\n    countrycontinentdatamodelresids\n    <fct><fct><list><list><list>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02, -1.106295e+00, -9.519382e-01, -6.635816e-01, -1.722494e-02, 6.741317e-01, 1.647488e+00, 1.686845e+00, 1.278202e+00, 7.535583e-01, -5.340851e-01, -1.544728e+00, -1.222372e+00\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030-594.0725, 0.3346832, -3.999128, -1.622544, 2.24404, 1.970624, 1.767207, 1.333791, 1.150375, 1.056959, -1.035457, -1.339873, -0.312289, -1.213705, -237.0586, 20.01115, 3.248124, 2.926981, 2.675838, 2.194694, 1.963551, 1.822408, -0.3177351, -0.6698783, 0.3099785, -0.6391646, 2, 59.22913, 60.90254, 62.57596, 64.24938, 65.92279, 67.59621, 69.26962, 70.94304, 72.61646, 74.28987, 75.96329, 77.63671, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 55.23, 59.28, 64.82, 66.22, 67.69, 68.93, 70.42, 72, 71.581, 72.95, 75.651, 76.423, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 5.523000e+01, 5.928000e+01, 6.482000e+01, 6.622000e+01, 6.769000e+01, 6.893000e+01, 7.042000e+01, 7.200000e+01, 7.158100e+01, 7.295000e+01, 7.565100e+01, 7.642300e+01, 1.282697e+06, 1.476505e+06, 1.728137e+06, 1.984060e+06, 2.263554e+06, 2.509048e+06, 2.780097e+06, 3.075321e+06, 3.326498e+06, 3.428038e+06, 3.508512e+06, 3.600523e+06, 1.601056e+03, 1.942284e+03, 2.312889e+03, 2.760197e+03, 3.313422e+03, 3.533004e+03, 3.630881e+03, 3.738933e+03, 2.497438e+03, 3.193055e+03, 4.604212e+03, 5.937030e+03, -3.999128e+00, -1.622544e+00, 2.244040e+00, 1.970624e+00, 1.767207e+00, 1.333791e+00, 1.150375e+00, 1.056959e+00, -1.035457e+00, -1.339873e+00, -3.122890e-01, -1.213705e+00\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367-1067.859, 0.5692797, -0.2979744, -0.536373, -0.7647716, -0.5071702, -0.2425688, 0.4070326, 0.914634, 2.499235, 1.597837, 0.1594382, -0.8449604, -2.384359, -204.4865, 34.03798, -0.6280719, -0.4013136, -0.1675554, 0.4512029, 0.9279612, 2.481719, 1.549478, 0.08023599, -0.9550057, -2.525247, 2, 43.37497, 46.22137, 49.06777, 51.91417, 54.76057, 57.60697, 60.45337, 63.29976, 66.14616, 68.99256, 71.83896, 74.68536, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.307700e+01, 4.568500e+01, 4.830300e+01, 5.140700e+01, 5.451800e+01, 5.801400e+01, 6.136800e+01, 6.579900e+01, 6.774400e+01, 6.915200e+01, 7.099400e+01, 7.230100e+01, 9.279525e+06, 1.027086e+07, 1.100095e+07, 1.276050e+07, 1.476079e+07, 1.715280e+07, 2.003375e+07, 2.325496e+07, 2.629837e+07, 2.907202e+07, 3.128714e+07, 3.333322e+07, 2.449008e+03, 3.013976e+03, 2.550817e+03, 3.246992e+03, 4.182664e+03, 4.910417e+03, 5.745160e+03, 5.681359e+03, 5.023217e+03, 4.797295e+03, 5.288040e+03, 6.223367e+03, -2.979744e-01, -5.363730e-01, -7.647716e-01, -5.071702e-01, -2.425688e-01, 4.070326e-01, 9.146340e-01, 2.499235e+00, 1.597837e+00, 1.594382e-01, -8.449604e-01, -2.384359e+00\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231-376.5048, 0.2093399, -2.111654, -1.174353, -0.2200524, 0.7182483, 1.614549, 2.12285, 1.53515, 0.452451, 0.1467517, -0.5839476, -1.590647, -0.9093462, -131.2323, 12.5167, 0.3574398, 1.24968, 2.099921, 2.562161, 1.928402, 0.799642, 0.4478825, -0.3288771, -1.381637, -0.7463962, 2, 32.12665, 33.17335, 34.22005, 35.26675, 36.31345, 37.36015, 38.40685, 39.45355, 40.50025, 41.54695, 42.59365, 43.64035, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 30.015, 31.999, 34, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 3.001500e+01, 3.199900e+01, 3.400000e+01, 3.598500e+01, 3.792800e+01, 3.948300e+01, 3.994200e+01, 3.990600e+01, 4.064700e+01, 4.096300e+01, 4.100300e+01, 4.273100e+01, 4.232095e+06, 4.561361e+06, 4.826015e+06, 5.247469e+06, 5.894858e+06, 6.162675e+06, 7.016384e+06, 7.874230e+06, 8.735988e+06, 9.875024e+06, 1.086611e+07, 1.242048e+07, 3.520610e+03, 3.827940e+03, 4.269277e+03, 5.522776e+03, 5.473288e+03, 3.008647e+03, 2.756954e+03, 2.430208e+03, 2.627846e+03, 2.277141e+03, 2.773287e+03, 4.797231e+03, -2.111654e+00, -1.174353e+00, -2.200524e-01, 7.182483e-01, 1.614549e+00, 2.122850e+00, 1.535150e+00, 4.524510e-01, 1.467517e-01, -5.839476e-01, -1.590647e+00, -9.093462e-01\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380-389.6063, 0.2317084, -0.2034359, 0.5520221, 0.1364802, -0.5300618, -0.2576037, -0.0001456876, 0.3023124, -0.0242296, -0.08877156, 0.1596865, 0.06614452, -0.1123974, -239.2323, 13.85415, 0.09303993, -0.5342543, -0.2225486, 0.07415714, 0.4158629, 0.1285686, 0.1032744, 0.3909801, 0.3366858, 0.1973916, 2, 62.68844, 63.84698, 65.00552, 66.16406, 67.3226, 68.48115, 69.63969, 70.79823, 71.95677, 73.11531, 74.27386, 75.4324, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.34, 75.32, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.248500e+01, 6.439900e+01, 6.514200e+01, 6.563400e+01, 6.706500e+01, 6.848100e+01, 6.994200e+01, 7.077400e+01, 7.186800e+01, 7.327500e+01, 7.434000e+01, 7.532000e+01, 1.787696e+07, 1.961054e+07, 2.128378e+07, 2.293422e+07, 2.477980e+07, 2.698383e+07, 2.934137e+07, 3.162092e+07, 3.395895e+07, 3.620346e+07, 3.833112e+07, 4.030193e+07, 5.911315e+03, 6.856856e+03, 7.133166e+03, 8.052953e+03, 9.443039e+03, 1.007903e+04, 8.997897e+03, 9.139671e+03, 9.308419e+03, 1.096728e+04, 8.797641e+03, 1.277938e+04, -2.034359e-01, 5.520221e-01, 1.364802e-01, -5.300618e-01, -2.576037e-01, -1.456876e-04, 3.023124e-01, -2.422960e-02, -8.877156e-02, 1.596865e-01, 6.614452e-02, -1.123974e-01\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367-376.1163, 0.2277238, 0.7194872, 0.7908683, 0.2522494, -0.7163695, -1.024988, -0.6036072, -0.4922261, -0.05084499, 0.05053613, 0.1819172, 0.5832984, 0.3096795, -258.6399, 13.6159, -0.002715871, -0.9299787, -1.197241, -0.7345042, -0.581767, -0.09902982, 0.04370739, 0.2164446, 0.6591818, 0.426919, 2, 68.40051, 69.53913, 70.67775, 71.81637, 72.95499, 74.09361, 75.23223, 76.37084, 77.50946, 78.64808, 79.7867, 80.92532, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 69.12, 70.33, 70.93, 71.1, 71.93, 73.49, 74.74, 76.32, 77.56, 78.83, 80.37, 81.235, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.912000e+01, 7.033000e+01, 7.093000e+01, 7.110000e+01, 7.193000e+01, 7.349000e+01, 7.474000e+01, 7.632000e+01, 7.756000e+01, 7.883000e+01, 8.037000e+01, 8.123500e+01, 8.691212e+06, 9.712569e+06, 1.079497e+07, 1.187226e+07, 1.317700e+07, 1.407410e+07, 1.518420e+07, 1.625725e+07, 1.748198e+07, 1.856524e+07, 1.954679e+07, 2.043418e+07, 1.003960e+04, 1.094965e+04, 1.221723e+04, 1.452612e+04, 1.678863e+04, 1.833420e+04, 1.947701e+04, 2.188889e+04, 2.342477e+04, 2.699794e+04, 3.068775e+04, 3.443537e+04, 7.194872e-01, 7.908683e-01, 2.522494e-01, -7.163695e-01, -1.024988e+00, -6.036072e-01, -4.922261e-01, -5.084499e-02, 5.053613e-02, 1.819172e-01, 5.832984e-01, 3.096795e-01\n\n\n\n\n\n데이터프레임 리스트를 플롯으로 나타내기\n\n\nresids <- unnest(by_country, resids)\nresids %>% head\n\n\n\nA grouped_df: 6 × 9\n\n    countrycontinentdatamodelyearlifeExppopgdpPercapresid\n    <fct><fct><list><list><int><dbl><int><dbl><dbl>\n\n\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007195228.801 8425333779.4453-1.10629487\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007195730.332 9240934820.8530-0.95193823\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007196231.99710267083853.1007-0.66358159\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007196734.02011537966836.1971-0.01722494\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007197236.08813079460739.9811 0.67413170\n    AfghanistanAsia1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 2007197738.43814880372786.1134 1.64748834\n\n\n\n\n\n보통의 열은 중첩된 열의 행으로 한 번씩 반복되지만 이제는 일반적인 데이터프레임을 가지고 있으므로 잔차를 플롯으로 나타낼 수 있다.\n\n\nresids %>%\nggplot(aes(year, resid)) +\ngeom_line(aes(group = country), alpha = 1/3) +\ngeom_smooth(se = FALSE)\n\n`geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = \"cs\")'\n\n\n\n\n\n\n\n플롯을 대륙으로 면분할하면 더 잘 나타난다.\n\n\nresids %>%\nggplot(aes(year, resid, group = country)) +\ngeom_line(alpha = 1/3) +\nfacet_wrap(~continent)\n\n\n\n\n\n플롯을 보면 가벼운 패턴은 포착하지 못한 것처럼 보인다. 또한, 아프리카 대륙의 플롯에서는 매우 큰 잔차값을 일부 볼 수 있으며, 이는 그 값에 대해 모델이 잘 맞지 않는다는 흥미로운 점을 발견할 수 있다.\n\n\n\n\n모델의 잔차를 탐색하는 대신, 모델의 성능에 대한 일반적인 측정값을 살펴볼 수 있다. broom패키지는 모델을 많은 타이디 데이터로 전환하는 일반적인 함수들을 제공한다.  broom::glance() : 모델의 성능 메트릭을 추출하기 위해 사용 이 함수를 모델에 적용하면 한 줄로 이루어진 데이터프레임이 생성된다.\n\nbroom::glance(nz_mod)\n\n\n\nA tibble: 1 × 12\n\n    r.squaredadj.r.squaredsigmastatisticp.valuedflogLikAICBICdeviancedf.residualnobs\n    <dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><int><int>\n\n\n    0.95358460.94894310.8043472205.44595.407324e-081-13.3206432.6412834.0966.4697431012\n\n\n\n\n\nmutate()와 unnest()를 사용하여 국가별로 하나의 행이 존재하는 데이터프레임을 만들 수 있다.\n\n\nby_country %>%\nmutate(glance = map(model, broom::glance)) %>%\nunnest(glance) %>% head\n\n\n\nA grouped_df: 6 × 17\n\n    countrycontinentdatamodelresidsr.squaredadj.r.squaredsigmastatisticp.valuedflogLikAICBICdeviancedf.residualnobs\n    <fct><fct><list><list><list><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><int><int>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02, -1.106295e+00, -9.519382e-01, -6.635816e-01, -1.722494e-02, 6.741317e-01, 1.647488e+00, 1.686845e+00, 1.278202e+00, 7.535583e-01, -5.340851e-01, -1.544728e+00, -1.222372e+000.94771230.94248351.2227880 181.249419.835213e-081-18.34693542.69387044.14859014.95210451012\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030-594.0725, 0.3346832, -3.999128, -1.622544, 2.24404, 1.970624, 1.767207, 1.333791, 1.150375, 1.056959, -1.035457, -1.339873, -0.312289, -1.213705, -237.0586, 20.01115, 3.248124, 2.926981, 2.675838, 2.194694, 1.963551, 1.822408, -0.3177351, -0.6698783, 0.3099785, -0.6391646, 2, 59.22913, 60.90254, 62.57596, 64.24938, 65.92279, 67.59621, 69.26962, 70.94304, 72.61646, 74.28987, 75.96329, 77.63671, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 55.23, 59.28, 64.82, 66.22, 67.69, 68.93, 70.42, 72, 71.581, 72.95, 75.651, 76.423, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 5.523000e+01, 5.928000e+01, 6.482000e+01, 6.622000e+01, 6.769000e+01, 6.893000e+01, 7.042000e+01, 7.200000e+01, 7.158100e+01, 7.295000e+01, 7.565100e+01, 7.642300e+01, 1.282697e+06, 1.476505e+06, 1.728137e+06, 1.984060e+06, 2.263554e+06, 2.509048e+06, 2.780097e+06, 3.075321e+06, 3.326498e+06, 3.428038e+06, 3.508512e+06, 3.600523e+06, 1.601056e+03, 1.942284e+03, 2.312889e+03, 2.760197e+03, 3.313422e+03, 3.533004e+03, 3.630881e+03, 3.738933e+03, 2.497438e+03, 3.193055e+03, 4.604212e+03, 5.937030e+03, -3.999128e+00, -1.622544e+00, 2.244040e+00, 1.970624e+00, 1.767207e+00, 1.333791e+00, 1.150375e+00, 1.056959e+00, -1.035457e+00, -1.339873e+00, -3.122890e-01, -1.213705e+000.91057780.90163551.9830615 101.829011.462763e-061-24.14903654.29807155.75279139.32533021012\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367-1067.859, 0.5692797, -0.2979744, -0.536373, -0.7647716, -0.5071702, -0.2425688, 0.4070326, 0.914634, 2.499235, 1.597837, 0.1594382, -0.8449604, -2.384359, -204.4865, 34.03798, -0.6280719, -0.4013136, -0.1675554, 0.4512029, 0.9279612, 2.481719, 1.549478, 0.08023599, -0.9550057, -2.525247, 2, 43.37497, 46.22137, 49.06777, 51.91417, 54.76057, 57.60697, 60.45337, 63.29976, 66.14616, 68.99256, 71.83896, 74.68536, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.307700e+01, 4.568500e+01, 4.830300e+01, 5.140700e+01, 5.451800e+01, 5.801400e+01, 6.136800e+01, 6.579900e+01, 6.774400e+01, 6.915200e+01, 7.099400e+01, 7.230100e+01, 9.279525e+06, 1.027086e+07, 1.100095e+07, 1.276050e+07, 1.476079e+07, 1.715280e+07, 2.003375e+07, 2.325496e+07, 2.629837e+07, 2.907202e+07, 3.128714e+07, 3.333322e+07, 2.449008e+03, 3.013976e+03, 2.550817e+03, 3.246992e+03, 4.182664e+03, 4.910417e+03, 5.745160e+03, 5.681359e+03, 5.023217e+03, 4.797295e+03, 5.288040e+03, 6.223367e+03, -2.979744e-01, -5.363730e-01, -7.647716e-01, -5.071702e-01, -2.425688e-01, 4.070326e-01, 9.146340e-01, 2.499235e+00, 1.597837e+00, 1.594382e-01, -8.449604e-01, -2.384359e+000.98511720.98362891.3230064 661.917091.808143e-101-19.29221444.58442746.03914717.50345891012\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231-376.5048, 0.2093399, -2.111654, -1.174353, -0.2200524, 0.7182483, 1.614549, 2.12285, 1.53515, 0.452451, 0.1467517, -0.5839476, -1.590647, -0.9093462, -131.2323, 12.5167, 0.3574398, 1.24968, 2.099921, 2.562161, 1.928402, 0.799642, 0.4478825, -0.3288771, -1.381637, -0.7463962, 2, 32.12665, 33.17335, 34.22005, 35.26675, 36.31345, 37.36015, 38.40685, 39.45355, 40.50025, 41.54695, 42.59365, 43.64035, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 30.015, 31.999, 34, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 3.001500e+01, 3.199900e+01, 3.400000e+01, 3.598500e+01, 3.792800e+01, 3.948300e+01, 3.994200e+01, 3.990600e+01, 4.064700e+01, 4.096300e+01, 4.100300e+01, 4.273100e+01, 4.232095e+06, 4.561361e+06, 4.826015e+06, 5.247469e+06, 5.894858e+06, 6.162675e+06, 7.016384e+06, 7.874230e+06, 8.735988e+06, 9.875024e+06, 1.086611e+07, 1.242048e+07, 3.520610e+03, 3.827940e+03, 4.269277e+03, 5.522776e+03, 5.473288e+03, 3.008647e+03, 2.756954e+03, 2.430208e+03, 2.627846e+03, 2.277141e+03, 2.773287e+03, 4.797231e+03, -2.111654e+00, -1.174353e+00, -2.200524e-01, 7.182483e-01, 1.614549e+00, 2.122850e+00, 1.535150e+00, 4.524510e-01, 1.467517e-01, -5.839476e-01, -1.590647e+00, -9.093462e-010.88781460.87659611.4070091  79.138184.593498e-061-20.03092846.06185747.51657719.79674711012\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380-389.6063, 0.2317084, -0.2034359, 0.5520221, 0.1364802, -0.5300618, -0.2576037, -0.0001456876, 0.3023124, -0.0242296, -0.08877156, 0.1596865, 0.06614452, -0.1123974, -239.2323, 13.85415, 0.09303993, -0.5342543, -0.2225486, 0.07415714, 0.4158629, 0.1285686, 0.1032744, 0.3909801, 0.3366858, 0.1973916, 2, 62.68844, 63.84698, 65.00552, 66.16406, 67.3226, 68.48115, 69.63969, 70.79823, 71.95677, 73.11531, 74.27386, 75.4324, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.34, 75.32, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.248500e+01, 6.439900e+01, 6.514200e+01, 6.563400e+01, 6.706500e+01, 6.848100e+01, 6.994200e+01, 7.077400e+01, 7.186800e+01, 7.327500e+01, 7.434000e+01, 7.532000e+01, 1.787696e+07, 1.961054e+07, 2.128378e+07, 2.293422e+07, 2.477980e+07, 2.698383e+07, 2.934137e+07, 3.162092e+07, 3.395895e+07, 3.620346e+07, 3.833112e+07, 4.030193e+07, 5.911315e+03, 6.856856e+03, 7.133166e+03, 8.052953e+03, 9.443039e+03, 1.007903e+04, 8.997897e+03, 9.139671e+03, 9.308419e+03, 1.096728e+04, 8.797641e+03, 1.277938e+04, -2.034359e-01, 5.520221e-01, 1.364802e-01, -5.300618e-01, -2.576037e-01, -1.456876e-04, 3.023124e-01, -2.422960e-02, -8.877156e-02, 1.596865e-01, 6.614452e-02, -1.123974e-010.99556810.99512490.29230722246.366354.215567e-131 -1.173933 8.347866 9.802586 0.85443491012\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367-376.1163, 0.2277238, 0.7194872, 0.7908683, 0.2522494, -0.7163695, -1.024988, -0.6036072, -0.4922261, -0.05084499, 0.05053613, 0.1819172, 0.5832984, 0.3096795, -258.6399, 13.6159, -0.002715871, -0.9299787, -1.197241, -0.7345042, -0.581767, -0.09902982, 0.04370739, 0.2164446, 0.6591818, 0.426919, 2, 68.40051, 69.53913, 70.67775, 71.81637, 72.95499, 74.09361, 75.23223, 76.37084, 77.50946, 78.64808, 79.7867, 80.92532, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 69.12, 70.33, 70.93, 71.1, 71.93, 73.49, 74.74, 76.32, 77.56, 78.83, 80.37, 81.235, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.912000e+01, 7.033000e+01, 7.093000e+01, 7.110000e+01, 7.193000e+01, 7.349000e+01, 7.474000e+01, 7.632000e+01, 7.756000e+01, 7.883000e+01, 8.037000e+01, 8.123500e+01, 8.691212e+06, 9.712569e+06, 1.079497e+07, 1.187226e+07, 1.317700e+07, 1.407410e+07, 1.518420e+07, 1.625725e+07, 1.748198e+07, 1.856524e+07, 1.954679e+07, 2.043418e+07, 1.003960e+04, 1.094965e+04, 1.221723e+04, 1.452612e+04, 1.678863e+04, 1.833420e+04, 1.947701e+04, 2.188889e+04, 2.342477e+04, 2.699794e+04, 3.068775e+04, 3.443537e+04, 7.194872e-01, 7.908683e-01, 2.522494e-01, -7.163695e-01, -1.024988e+00, -6.036072e-01, -4.922261e-01, -5.084499e-02, 5.053613e-02, 1.819172e-01, 5.832984e-01, 3.096795e-010.97964770.97761250.6206086 481.345868.667222e-101-10.20867726.41735327.872073 3.85155011012\n\n\n\n\n\n그렇지만 여전히 모든 리스트-열을 포함하고 있으므로 이는 우리가 원하는 결과물이 아니다. 이것은 unnest()를 단일 행의 데이터프레임에 적용했을 때의 기본 동작이다. 이 열을 숨기기 위해서는 .drop = TRUE를 사용하면 된다.\n\n\nglance <- by_country %>%\nmutate(glance = map(model, broom::glance)) %>%\nunnest(glance, .drop = TRUE)\nglance %>% head\n\nWarning message:\n“The `.drop` argument of `unnest()` is deprecated as of tidyr 1.0.0.\nAll list-columns are now preserved.”\n\n\n\n\nA grouped_df: 6 × 17\n\n    countrycontinentdatamodelresidsr.squaredadj.r.squaredsigmastatisticp.valuedflogLikAICBICdeviancedf.residualnobs\n    <fct><fct><list><list><list><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><int><int>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02-507.5343, 0.2753287, -1.106295, -0.9519382, -0.6635816, -0.01722494, 0.6741317, 1.647488, 1.686845, 1.278202, 0.7535583, -0.5340851, -1.544728, -1.222372, -129.8305, 16.46226, -0.3108827, 0.2892301, 0.934343, 1.861456, 1.854569, 1.399681, 0.8287943, -0.5050929, -1.56198, -1.285867, 2, 29.90729, 31.28394, 32.66058, 34.03722, 35.41387, 36.79051, 38.16716, 39.5438, 40.92044, 42.29709, 43.67373, 45.05037, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 28.801, 30.332, 31.997, 34.02, 36.088, 38.438, 39.854, 40.822, 41.674, 41.763, 42.129, 43.828, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02, -1.106295e+00, -9.519382e-01, -6.635816e-01, -1.722494e-02, 6.741317e-01, 1.647488e+00, 1.686845e+00, 1.278202e+00, 7.535583e-01, -5.340851e-01, -1.544728e+00, -1.222372e+000.94771230.94248351.2227880 181.249419.835213e-081-18.34693542.69387044.14859014.95210451012\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030-594.0725, 0.3346832, -3.999128, -1.622544, 2.24404, 1.970624, 1.767207, 1.333791, 1.150375, 1.056959, -1.035457, -1.339873, -0.312289, -1.213705, -237.0586, 20.01115, 3.248124, 2.926981, 2.675838, 2.194694, 1.963551, 1.822408, -0.3177351, -0.6698783, 0.3099785, -0.6391646, 2, 59.22913, 60.90254, 62.57596, 64.24938, 65.92279, 67.59621, 69.26962, 70.94304, 72.61646, 74.28987, 75.96329, 77.63671, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 55.23, 59.28, 64.82, 66.22, 67.69, 68.93, 70.42, 72, 71.581, 72.95, 75.651, 76.423, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 5.523000e+01, 5.928000e+01, 6.482000e+01, 6.622000e+01, 6.769000e+01, 6.893000e+01, 7.042000e+01, 7.200000e+01, 7.158100e+01, 7.295000e+01, 7.565100e+01, 7.642300e+01, 1.282697e+06, 1.476505e+06, 1.728137e+06, 1.984060e+06, 2.263554e+06, 2.509048e+06, 2.780097e+06, 3.075321e+06, 3.326498e+06, 3.428038e+06, 3.508512e+06, 3.600523e+06, 1.601056e+03, 1.942284e+03, 2.312889e+03, 2.760197e+03, 3.313422e+03, 3.533004e+03, 3.630881e+03, 3.738933e+03, 2.497438e+03, 3.193055e+03, 4.604212e+03, 5.937030e+03, -3.999128e+00, -1.622544e+00, 2.244040e+00, 1.970624e+00, 1.767207e+00, 1.333791e+00, 1.150375e+00, 1.056959e+00, -1.035457e+00, -1.339873e+00, -3.122890e-01, -1.213705e+000.91057780.90163551.9830615 101.829011.462763e-061-24.14903654.29807155.75279139.32533021012\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367-1067.859, 0.5692797, -0.2979744, -0.536373, -0.7647716, -0.5071702, -0.2425688, 0.4070326, 0.914634, 2.499235, 1.597837, 0.1594382, -0.8449604, -2.384359, -204.4865, 34.03798, -0.6280719, -0.4013136, -0.1675554, 0.4512029, 0.9279612, 2.481719, 1.549478, 0.08023599, -0.9550057, -2.525247, 2, 43.37497, 46.22137, 49.06777, 51.91417, 54.76057, 57.60697, 60.45337, 63.29976, 66.14616, 68.99256, 71.83896, 74.68536, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.307700e+01, 4.568500e+01, 4.830300e+01, 5.140700e+01, 5.451800e+01, 5.801400e+01, 6.136800e+01, 6.579900e+01, 6.774400e+01, 6.915200e+01, 7.099400e+01, 7.230100e+01, 9.279525e+06, 1.027086e+07, 1.100095e+07, 1.276050e+07, 1.476079e+07, 1.715280e+07, 2.003375e+07, 2.325496e+07, 2.629837e+07, 2.907202e+07, 3.128714e+07, 3.333322e+07, 2.449008e+03, 3.013976e+03, 2.550817e+03, 3.246992e+03, 4.182664e+03, 4.910417e+03, 5.745160e+03, 5.681359e+03, 5.023217e+03, 4.797295e+03, 5.288040e+03, 6.223367e+03, -2.979744e-01, -5.363730e-01, -7.647716e-01, -5.071702e-01, -2.425688e-01, 4.070326e-01, 9.146340e-01, 2.499235e+00, 1.597837e+00, 1.594382e-01, -8.449604e-01, -2.384359e+000.98511720.98362891.3230064 661.917091.808143e-101-19.29221444.58442746.03914717.50345891012\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231-376.5048, 0.2093399, -2.111654, -1.174353, -0.2200524, 0.7182483, 1.614549, 2.12285, 1.53515, 0.452451, 0.1467517, -0.5839476, -1.590647, -0.9093462, -131.2323, 12.5167, 0.3574398, 1.24968, 2.099921, 2.562161, 1.928402, 0.799642, 0.4478825, -0.3288771, -1.381637, -0.7463962, 2, 32.12665, 33.17335, 34.22005, 35.26675, 36.31345, 37.36015, 38.40685, 39.45355, 40.50025, 41.54695, 42.59365, 43.64035, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 30.015, 31.999, 34, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 3.001500e+01, 3.199900e+01, 3.400000e+01, 3.598500e+01, 3.792800e+01, 3.948300e+01, 3.994200e+01, 3.990600e+01, 4.064700e+01, 4.096300e+01, 4.100300e+01, 4.273100e+01, 4.232095e+06, 4.561361e+06, 4.826015e+06, 5.247469e+06, 5.894858e+06, 6.162675e+06, 7.016384e+06, 7.874230e+06, 8.735988e+06, 9.875024e+06, 1.086611e+07, 1.242048e+07, 3.520610e+03, 3.827940e+03, 4.269277e+03, 5.522776e+03, 5.473288e+03, 3.008647e+03, 2.756954e+03, 2.430208e+03, 2.627846e+03, 2.277141e+03, 2.773287e+03, 4.797231e+03, -2.111654e+00, -1.174353e+00, -2.200524e-01, 7.182483e-01, 1.614549e+00, 2.122850e+00, 1.535150e+00, 4.524510e-01, 1.467517e-01, -5.839476e-01, -1.590647e+00, -9.093462e-010.88781460.87659611.4070091  79.138184.593498e-061-20.03092846.06185747.51657719.79674711012\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380-389.6063, 0.2317084, -0.2034359, 0.5520221, 0.1364802, -0.5300618, -0.2576037, -0.0001456876, 0.3023124, -0.0242296, -0.08877156, 0.1596865, 0.06614452, -0.1123974, -239.2323, 13.85415, 0.09303993, -0.5342543, -0.2225486, 0.07415714, 0.4158629, 0.1285686, 0.1032744, 0.3909801, 0.3366858, 0.1973916, 2, 62.68844, 63.84698, 65.00552, 66.16406, 67.3226, 68.48115, 69.63969, 70.79823, 71.95677, 73.11531, 74.27386, 75.4324, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.34, 75.32, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.248500e+01, 6.439900e+01, 6.514200e+01, 6.563400e+01, 6.706500e+01, 6.848100e+01, 6.994200e+01, 7.077400e+01, 7.186800e+01, 7.327500e+01, 7.434000e+01, 7.532000e+01, 1.787696e+07, 1.961054e+07, 2.128378e+07, 2.293422e+07, 2.477980e+07, 2.698383e+07, 2.934137e+07, 3.162092e+07, 3.395895e+07, 3.620346e+07, 3.833112e+07, 4.030193e+07, 5.911315e+03, 6.856856e+03, 7.133166e+03, 8.052953e+03, 9.443039e+03, 1.007903e+04, 8.997897e+03, 9.139671e+03, 9.308419e+03, 1.096728e+04, 8.797641e+03, 1.277938e+04, -2.034359e-01, 5.520221e-01, 1.364802e-01, -5.300618e-01, -2.576037e-01, -1.456876e-04, 3.023124e-01, -2.422960e-02, -8.877156e-02, 1.596865e-01, 6.614452e-02, -1.123974e-010.99556810.99512490.29230722246.366354.215567e-131 -1.173933 8.347866 9.802586 0.85443491012\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367-376.1163, 0.2277238, 0.7194872, 0.7908683, 0.2522494, -0.7163695, -1.024988, -0.6036072, -0.4922261, -0.05084499, 0.05053613, 0.1819172, 0.5832984, 0.3096795, -258.6399, 13.6159, -0.002715871, -0.9299787, -1.197241, -0.7345042, -0.581767, -0.09902982, 0.04370739, 0.2164446, 0.6591818, 0.426919, 2, 68.40051, 69.53913, 70.67775, 71.81637, 72.95499, 74.09361, 75.23223, 76.37084, 77.50946, 78.64808, 79.7867, 80.92532, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 69.12, 70.33, 70.93, 71.1, 71.93, 73.49, 74.74, 76.32, 77.56, 78.83, 80.37, 81.235, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 6.912000e+01, 7.033000e+01, 7.093000e+01, 7.110000e+01, 7.193000e+01, 7.349000e+01, 7.474000e+01, 7.632000e+01, 7.756000e+01, 7.883000e+01, 8.037000e+01, 8.123500e+01, 8.691212e+06, 9.712569e+06, 1.079497e+07, 1.187226e+07, 1.317700e+07, 1.407410e+07, 1.518420e+07, 1.625725e+07, 1.748198e+07, 1.856524e+07, 1.954679e+07, 2.043418e+07, 1.003960e+04, 1.094965e+04, 1.221723e+04, 1.452612e+04, 1.678863e+04, 1.833420e+04, 1.947701e+04, 2.188889e+04, 2.342477e+04, 2.699794e+04, 3.068775e+04, 3.443537e+04, 7.194872e-01, 7.908683e-01, 2.522494e-01, -7.163695e-01, -1.024988e+00, -6.036072e-01, -4.922261e-01, -5.084499e-02, 5.053613e-02, 1.819172e-01, 5.832984e-01, 3.096795e-010.97964770.97761250.6206086 481.345868.667222e-101-10.20867726.41735327.872073 3.85155011012\n\n\n\n\n\n유용한 정보가 많이 포함되었지만 인쇄되지 않은 변수에 주목해본다. 이 데이터프레임을 사용하면 잘 맞지 않는 모델을 찾을 수 있다.\n\n\nglance %>%\narrange(r.squared) %>% \nhead\n\n\n\nA grouped_df: 6 × 17\n\n    countrycontinentdatamodelresidsr.squaredadj.r.squaredsigmastatisticp.valuedflogLikAICBICdeviancedf.residualnobs\n    <fct><fct><list><list><list><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><int><int>\n\n\n    Rwanda   Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 40.0000, 41.5000, 43.0000, 44.1000, 44.6000, 45.0000, 46.2180, 44.0200, 23.5990, 36.0870, 43.4130, 46.2420, 2534927.0000, 2822082.0000, 3051242.0000, 3451079.0000, 3992121.0000, 4657072.0000, 5507565.0000, 6349365.0000, 7290203.0000, 7212583.0000, 7852401.0000, 8860588.0000, 493.3239, 540.2894, 597.4731, 510.9637, 590.5807, 670.0806, 881.5706, 847.9912, 737.0686, 589.9445, 785.6538, 863.0885132.205, -0.04583147, -2.741949, -1.012791, 0.716366, 2.045523, 2.774681, 3.403838, 4.850995, 2.882153, -17.30969, -4.592533, 2.962625, 6.020782, -143.6964, -2.740323, 1.389955, 2.692936, 3.395916, 3.998897, 5.419878, 3.424859, -16.79316, -4.10218, 3.426801, 6.458782, 2, 42.74195, 42.51279, 42.28363, 42.05448, 41.82532, 41.59616, 41.367, 41.13785, 40.90869, 40.67953, 40.45038, 40.22122, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 40, 41.5, 43, 44.1, 44.6, 45, 46.218, 44.02, 23.599, 36.087, 43.413, 46.242, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.000000e+01, 4.150000e+01, 4.300000e+01, 4.410000e+01, 4.460000e+01, 4.500000e+01, 4.621800e+01, 4.402000e+01, 2.359900e+01, 3.608700e+01, 4.341300e+01, 4.624200e+01, 2.534927e+06, 2.822082e+06, 3.051242e+06, 3.451079e+06, 3.992121e+06, 4.657072e+06, 5.507565e+06, 6.349365e+06, 7.290203e+06, 7.212583e+06, 7.852401e+06, 8.860588e+06, 4.933239e+02, 5.402894e+02, 5.974731e+02, 5.109637e+02, 5.905807e+02, 6.700806e+02, 8.815706e+02, 8.479912e+02, 7.370686e+02, 5.899445e+02, 7.856538e+02, 8.630885e+02, -2.741949e+00, -1.012791e+00, 7.163660e-01, 2.045523e+00, 2.774681e+00, 3.403838e+00, 4.850995e+00, 2.882153e+00, -1.730969e+01, -4.592533e+00, 2.962625e+00, 6.020782e+000.01715964-0.0811244016.5582690.17459230.68489271-38.5020583.0041184.45883430.10901012\n    Botswana Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 47.6220, 49.6180, 51.5200, 53.2980, 56.0240, 59.3190, 61.4840, 63.6220, 62.7450, 52.5560, 46.6340, 50.7280, 442308.0000, 474639.0000, 512764.0000, 553541.0000, 619351.0000, 781472.0000, 970347.0000, 1151184.0000, 1342614.0000, 1536536.0000, 1630347.0000, 1639131.0000, 851.2411, 918.2325, 983.6540, 1214.7093, 2263.6111, 3214.8578, 4551.1421, 6205.8839, 7954.1116, 8647.1423, 11003.6051, 12569.8518-65.49586, 0.06066853, -5.307115, -3.614458, -2.015801, -0.5411434, 1.881514, 4.873171, 6.734829, 8.569486, 7.389143, -3.103199, -9.328542, -5.537885, -189.1313, 3.627451, -0.4656616, 0.8496905, 3.113043, 5.945395, 7.647747, 9.323099, 7.983451, -2.668197, -9.052845, -5.421493, 2, 52.92912, 53.23246, 53.5358, 53.83914, 54.14249, 54.44583, 54.74917, 55.05251, 55.35586, 55.6592, 55.96254, 56.26588, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 47.622, 49.618, 51.52, 53.298, 56.024, 59.319, 61.484, 63.622, 62.745, 52.556, 46.634, 50.728, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.762200e+01, 4.961800e+01, 5.152000e+01, 5.329800e+01, 5.602400e+01, 5.931900e+01, 6.148400e+01, 6.362200e+01, 6.274500e+01, 5.255600e+01, 4.663400e+01, 5.072800e+01, 4.423080e+05, 4.746390e+05, 5.127640e+05, 5.535410e+05, 6.193510e+05, 7.814720e+05, 9.703470e+05, 1.151184e+06, 1.342614e+06, 1.536536e+06, 1.630347e+06, 1.639131e+06, 8.512411e+02, 9.182325e+02, 9.836540e+02, 1.214709e+03, 2.263611e+03, 3.214858e+03, 4.551142e+03, 6.205884e+03, 7.954112e+03, 8.647142e+03, 1.100361e+04, 1.256985e+04, -5.307115e+00, -3.614458e+00, -2.015801e+00, -5.411434e-01, 1.881514e+00, 4.873171e+00, 6.734829e+00, 8.569486e+00, 7.389143e+00, -3.103199e+00, -9.328542e+00, -5.537885e+000.03402340-0.0625742596.1121770.35221770.56604141-37.6567381.3134682.76818373.58711012\n    Zimbabwe Africa1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.845100e+01, 5.046900e+01, 5.235800e+01, 5.399500e+01, 5.563500e+01, 5.767400e+01, 6.036300e+01, 6.235100e+01, 6.037700e+01, 4.680900e+01, 3.998900e+01, 4.348700e+01, 3.080907e+06, 3.646340e+06, 4.277736e+06, 4.995432e+06, 5.861135e+06, 6.642107e+06, 7.636524e+06, 9.216418e+06, 1.070434e+07, 1.140495e+07, 1.192656e+07, 1.231114e+07, 4.068841e+02, 5.187643e+02, 5.272722e+02, 5.697951e+02, 7.993622e+02, 6.855877e+02, 7.888550e+02, 7.061573e+02, 6.934208e+02, 7.924500e+02, 6.720386e+02, 4.697093e+02236.7982, -0.09302098, -6.770244, -4.287139, -1.933034, 0.1690711, 2.274176, 4.778281, 7.932386, 10.38549, 8.876596, -4.2263, -10.58119, -6.61809, -182.4306, -5.561846, -0.003763574, 1.916383, 3.839529, 6.161675, 9.133821, 11.40497, 9.714114, -3.57074, -10.10759, -6.326448, 2, 55.22124, 54.75614, 54.29103, 53.82593, 53.36082, 52.89572, 52.43061, 51.96551, 51.5004, 51.0353, 50.57019, 50.10509, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 48.451, 50.469, 52.358, 53.995, 55.635, 57.674, 60.363, 62.351, 60.377, 46.809, 39.989, 43.487, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.845100e+01, 5.046900e+01, 5.235800e+01, 5.399500e+01, 5.563500e+01, 5.767400e+01, 6.036300e+01, 6.235100e+01, 6.037700e+01, 4.680900e+01, 3.998900e+01, 4.348700e+01, 3.080907e+06, 3.646340e+06, 4.277736e+06, 4.995432e+06, 5.861135e+06, 6.642107e+06, 7.636524e+06, 9.216418e+06, 1.070434e+07, 1.140495e+07, 1.192656e+07, 1.231114e+07, 4.068841e+02, 5.187643e+02, 5.272722e+02, 5.697951e+02, 7.993622e+02, 6.855877e+02, 7.888550e+02, 7.061573e+02, 6.934208e+02, 7.924500e+02, 6.720386e+02, 4.697093e+02, -6.770244e+00, -4.287139e+00, -1.933034e+00, 1.690711e-01, 2.274176e+00, 4.778281e+00, 7.932386e+00, 1.038549e+01, 8.876596e+00, -4.226300e+00, -1.058119e+01, -6.618090e+000.05623196-0.0381448427.2054310.59582400.45802901-39.6313585.2627186.71743519.18231012\n    Zambia   Africa1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 42.038, 44.077, 46.023, 47.768, 50.107, 51.386, 51.821, 50.821, 46.100, 40.238, 39.193, 42.384, 2672000.000, 3016000.000, 3421000.000, 3900000.000, 4506497.000, 5216550.000, 6100407.000, 7272406.000, 8381163.000, 9417789.000, 10595811.000, 11746035.000, 1147.389, 1311.957, 1452.726, 1777.077, 1773.498, 1588.688, 1408.679, 1213.315, 1210.885, 1071.354, 1071.614, 1271.212165.608, -0.06042517, -5.620026, -3.2789, -1.030774, 1.016352, 3.657478, 5.238604, 5.97573, 5.277855, 0.8589814, -4.700893, -5.443767, -1.950641, -159.336, -3.6129, 0.5290378, 2.4435, 4.951963, 6.400425, 7.004887, 6.17435, 1.622812, -4.069725, -4.945263, -1.584801, 2, 47.65803, 47.3559, 47.05377, 46.75165, 46.44952, 46.1474, 45.84527, 45.54314, 45.24102, 44.93889, 44.63677, 44.33464, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 42.038, 44.077, 46.023, 47.768, 50.107, 51.386, 51.821, 50.821, 46.1, 40.238, 39.193, 42.384, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.203800e+01, 4.407700e+01, 4.602300e+01, 4.776800e+01, 5.010700e+01, 5.138600e+01, 5.182100e+01, 5.082100e+01, 4.610000e+01, 4.023800e+01, 3.919300e+01, 4.238400e+01, 2.672000e+06, 3.016000e+06, 3.421000e+06, 3.900000e+06, 4.506497e+06, 5.216550e+06, 6.100407e+06, 7.272406e+06, 8.381163e+06, 9.417789e+06, 1.059581e+07, 1.174604e+07, 1.147389e+03, 1.311957e+03, 1.452726e+03, 1.777077e+03, 1.773498e+03, 1.588688e+03, 1.408679e+03, 1.213315e+03, 1.210885e+03, 1.071354e+03, 1.071614e+03, 1.271212e+03, -5.620026e+00, -3.278900e+00, -1.030774e+00, 1.016352e+00, 3.657478e+00, 5.238604e+00, 5.975730e+00, 5.277855e+00, 8.589814e-01, -4.700893e+00, -5.443767e+00, -1.950641e+000.05983644-0.0341799184.5287130.63644710.44353181-34.0585974.1171775.57189205.09241012\n    SwazilandAfrica1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 41.407, 43.424, 44.992, 46.633, 49.552, 52.537, 55.561, 57.678, 58.474, 54.289, 43.869, 39.613, 290243.000, 326741.000, 370006.000, 420690.000, 480105.000, 551425.000, 649901.000, 779348.000, 962344.000, 1054486.000, 1130269.000, 1133066.000, 1148.377, 1244.708, 1856.182, 2613.102, 3364.837, 3781.411, 3895.384, 3984.840, 3553.022, 3876.768, 4128.117, 4513.481-139.1982, 0.09507483, -4.980859, -3.439233, -2.346607, -1.180981, 1.262645, 3.77227, 6.320896, 7.962522, 8.283148, 3.622774, -7.2726, -12.00397, -169.7494, 5.684648, -0.8847665, 0.1282624, 2.419291, 4.77632, 7.172349, 8.661378, 8.829407, 4.016435, -7.031536, -11.91551, 2, 46.38786, 46.86323, 47.33861, 47.81398, 48.28936, 48.76473, 49.2401, 49.71548, 50.19085, 50.66623, 51.1416, 51.61697, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 41.407, 43.424, 44.992, 46.633, 49.552, 52.537, 55.561, 57.678, 58.474, 54.289, 43.869, 39.613, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.140700e+01, 4.342400e+01, 4.499200e+01, 4.663300e+01, 4.955200e+01, 5.253700e+01, 5.556100e+01, 5.767800e+01, 5.847400e+01, 5.428900e+01, 4.386900e+01, 3.961300e+01, 2.902430e+05, 3.267410e+05, 3.700060e+05, 4.206900e+05, 4.801050e+05, 5.514250e+05, 6.499010e+05, 7.793480e+05, 9.623440e+05, 1.054486e+06, 1.130269e+06, 1.133066e+06, 1.148377e+03, 1.244708e+03, 1.856182e+03, 2.613102e+03, 3.364837e+03, 3.781411e+03, 3.895384e+03, 3.984840e+03, 3.553022e+03, 3.876768e+03, 4.128117e+03, 4.513481e+03, -4.980859e+00, -3.439233e+00, -2.346607e+00, -1.180981e+00, 1.262645e+00, 3.772270e+00, 6.320896e+00, 7.962522e+00, 8.283148e+00, 3.622774e+00, -7.272600e+00, -1.200397e+010.06821087-0.0249680466.6440910.73204190.41225301-38.6580783.3161484.77086441.43951012\n    Lesotho  Africa1952.0000, 1957.0000, 1962.0000, 1967.0000, 1972.0000, 1977.0000, 1982.0000, 1987.0000, 1992.0000, 1997.0000, 2002.0000, 2007.0000, 42.1380, 45.0470, 47.7470, 48.4920, 49.7670, 52.2080, 55.0780, 57.1800, 59.6850, 55.5580, 44.5930, 42.5920, 748747.0000, 813338.0000, 893143.0000, 996380.0000, 1116779.0000, 1251524.0000, 1411807.0000, 1599200.0000, 1803195.0000, 1982823.0000, 2046772.0000, 2012649.0000, 298.8462, 335.9971, 411.8006, 498.6390, 496.5816, 745.3695, 797.2631, 773.9932, 977.4863, 1186.1480, 1275.1846, 1569.3314-139.1653, 0.09556573, -5.241026, -2.809854, -0.587683, -0.3205117, 0.4766597, 2.439831, 4.832002, 6.456174, 8.483345, 3.878516, -7.564312, -10.04314, -173.2296, 5.714, 0.8300106, 0.9897477, 1.679485, 3.535222, 5.819959, 7.336696, 9.256433, 4.54417, -7.006093, -9.592356, 2, 47.37903, 47.85685, 48.33468, 48.81251, 49.29034, 49.76817, 50.246, 50.72383, 51.20166, 51.67948, 52.15731, 52.63514, 0, 1, -3.464102, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, 0.2886751, -6857.189, 59.7913, 0.1896554, 0.1060312, 0.02240704, -0.06121716, -0.1448414, -0.2284656, -0.3120898, -0.395714, -0.4793382, -0.5629624, 1.288675, 1.27328, 1, 2, 1e-07, 2, 10, lm(formula = lifeExp ~ year, data = df), lifeExp ~ year, 42.138, 45.047, 47.747, 48.492, 49.767, 52.208, 55.078, 57.18, 59.685, 55.558, 44.593, 42.592, 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002, 20071.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 4.213800e+01, 4.504700e+01, 4.774700e+01, 4.849200e+01, 4.976700e+01, 5.220800e+01, 5.507800e+01, 5.718000e+01, 5.968500e+01, 5.555800e+01, 4.459300e+01, 4.259200e+01, 7.487470e+05, 8.133380e+05, 8.931430e+05, 9.963800e+05, 1.116779e+06, 1.251524e+06, 1.411807e+06, 1.599200e+06, 1.803195e+06, 1.982823e+06, 2.046772e+06, 2.012649e+06, 2.988462e+02, 3.359971e+02, 4.118006e+02, 4.986390e+02, 4.965816e+02, 7.453695e+02, 7.972631e+02, 7.739932e+02, 9.774863e+02, 1.186148e+03, 1.275185e+03, 1.569331e+03, -5.241026e+00, -2.809854e+00, -5.876830e-01, -3.205117e-01, 4.766597e-01, 2.439831e+00, 4.832002e+00, 6.456174e+00, 8.483345e+00, 3.878516e+00, -7.564312e+00, -1.004314e+010.08485635-0.0066580115.9339340.92724630.35828641-37.3015880.6031682.05788352.11571012\n\n\n\n\n가장 좋지 않은 모델은 아프리카 대륙에서 나타난다. 이는 플롯으로 다시 확인해보면 상대적으로 적은 수의 관측값과 이산형 변수가 존재핳기 때문에 geom_jitter()함수가 효과적이다.\n\nglance %>%\nggplot(aes(continent, r.squared)) +\ngeom_jitter(width = 0.5)\n\n\n\n\n\n\\(R^2\\)값이 작은 국가를 제거한 데이터를 플롯으로 나타내면\n\n\nbad_fit <- filter(glance, r.squared < 0.25)\n\ngapminder %>%\nsemi_join(bad_fit, by = \"country\") %>%\nggplot(aes(year, lifeExp, color = country)) +\ngeom_line()\n\n\n\n\n\n다른 배경지식을 사용하면 여기에는 HIV/AIDS 전염병과 르완다 집단 학살의 비극이라는 두 가지 주요 효과가 있다는 것을 알 수 있다.\n\n\n\n\n\n\n데이터프레임은 같은 길이의 벡터로 명명된 리스트로 이루어져 있으며, 이는 리스트-열이 데이터프레임의 정의에 내재되어 있다는 것이다. 리스트는 벡터이므로 리스트를 데이터프레임의 열로 사용하는 것은 타당한 방법이다. 그러나 베이스 R에서는 리스트-열을 쉽게 만들 수 없으며 data.frame()은 리스트를 열의 리스트로 처리한다.\n\n\ndata.frame(x = list(1:3, 3:5))\n\n\n\nA data.frame: 3 × 2\n\n    x.1.3x.3.5\n    <int><int>\n\n\n    13\n    24\n    35\n\n\n\n\nI()를 사용하면 data.frame()에서 이를 막을 수는 있지만, 다음과 같이 제대로 출력되지 않는다.\n\ndata.frame(\n    x = I(list(1:3, 3:5)),\n    y = c(\"1, 2\", \"3, 4, 5\")\n    )\n\n\n\nA data.frame: 2 × 2\n\n    xy\n    <I<list>><chr>\n\n\n    1, 2, 31, 2   \n    3, 4, 53, 4, 5\n\n\n\n\n\ntibble()은 입렵값을 수정하지 않고도 더 나은 출력 방법을 제공하여 이 문제를 해결할 수 있다.\n\n\ntibble(\n    x = list(1:3, 3:5),\n    y = c(\"1, 2\", \"3, 4, 5\")\n    )\n\n\n\nA tibble: 2 × 2\n\n    xy\n    <list><chr>\n\n\n    1, 2, 31, 2   \n    3, 4, 53, 4, 5\n\n\n\n\n\ntribble()은 필요한 리스트를 자동으로 생성할 수 있는 더 간단한 방법이다.\n\n\ntribble(\n    ~x, ~y,\n    1:3, \"1, 2\",\n    3:5, \"3, 4, 5\"\n    )\n\n\n\nA tibble: 2 × 2\n\n    xy\n    <list><chr>\n\n\n    1, 2, 31, 2   \n    3, 4, 53, 4, 5\n\n\n\n\n\n리스트-열은 중급 데이터 구조로 가장 유용하다. 대부분의 R함수가 원자 벡터 또는 데이터프레임에서 동작하기 때문에 리스트-열로 직접 작업하기는 어렵다. 데이터프레임에서 연관된 항목을 유지하는 장점을 누리려면 약간의 번거로움이 따를 수 밖에 없다. 일반적으로 리스트-열 파이프 라인에는 효과적인 측면이 세 가지이다.\n\n\n\nnest(), summarize() + list() 또는 mutate() + map 함수 중 하나를 사용하여 리스트-열을 생성한다.\n기존의 리스트-열을 map(), map2() 또는 pmap()으로 변형하여 다른 중간 리스트-열을 만든다. 예를 들어 이전 사례에서 데이터프레임의 리스트-열을 변형하여 모델의 리스트-열을 생성하였다.\n리스트-열을 데이터프레임 또는 원자 벡터로 다시 단순화한다.\n\n\n\n\n\nnest() 함수는 중첩된 데이터프레임(즉, 데이터프레임의 리스트-열로 이루어진 데이터프레임)을 생성한다. 중첩된 데이터프레임의 각 행은 메타 관측값을 나타낸다. 다른 열은 관측값을 정의하는 변수(예 : 국가와 대륙)를 제공하고 데이터프레임의 리스트-열은 메타 관측값을 구성하는 개별 관측값을 제공한다. nest()를 사용하는 두 가지 방법이 있는데 앞서서는 그룹화된 데이터프레임에 사용하는 방법이였고 그룹화된 데이터프레임에 적용할 때 nest()는 그룹화된 열은 그대로 유지하고 그 외의 모든 항목은 리스트-열로 묶는다.\n\n\ngapminder %>%\ngroup_by(country, continent) %>%\nnest() %>% head\n\n\n\nA grouped_df: 6 × 3\n\n    countrycontinentdata\n    <fct><fct><list>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367\n\n\n\n\n\n그룹화되지 않은 데이터프레임에서도 중첩하고자 하는 열을 지정하면 사용할 수 있다.\n\n\ngapminder %>%\nnest(year:gdpPercap) %>%\nhead\n\nWarning message:\n“All elements of `...` must be named.\nDid you want `data = year:gdpPercap`?”\n\n\n\n\nA tibble: 6 × 3\n\n    countrycontinentdata\n    <fct><fct><list>\n\n\n    AfghanistanAsia    1.952000e+03, 1.957000e+03, 1.962000e+03, 1.967000e+03, 1.972000e+03, 1.977000e+03, 1.982000e+03, 1.987000e+03, 1.992000e+03, 1.997000e+03, 2.002000e+03, 2.007000e+03, 2.880100e+01, 3.033200e+01, 3.199700e+01, 3.402000e+01, 3.608800e+01, 3.843800e+01, 3.985400e+01, 4.082200e+01, 4.167400e+01, 4.176300e+01, 4.212900e+01, 4.382800e+01, 8.425333e+06, 9.240934e+06, 1.026708e+07, 1.153797e+07, 1.307946e+07, 1.488037e+07, 1.288182e+07, 1.386796e+07, 1.631792e+07, 2.222742e+07, 2.526840e+07, 3.188992e+07, 7.794453e+02, 8.208530e+02, 8.531007e+02, 8.361971e+02, 7.399811e+02, 7.861134e+02, 9.780114e+02, 8.523959e+02, 6.493414e+02, 6.353414e+02, 7.267341e+02, 9.745803e+02\n    Albania    Europe  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 55.230, 59.280, 64.820, 66.220, 67.690, 68.930, 70.420, 72.000, 71.581, 72.950, 75.651, 76.423, 1282697.000, 1476505.000, 1728137.000, 1984060.000, 2263554.000, 2509048.000, 2780097.000, 3075321.000, 3326498.000, 3428038.000, 3508512.000, 3600523.000, 1601.056, 1942.284, 2312.889, 2760.197, 3313.422, 3533.004, 3630.881, 3738.933, 2497.438, 3193.055, 4604.212, 5937.030\n    Algeria    Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 43.077, 45.685, 48.303, 51.407, 54.518, 58.014, 61.368, 65.799, 67.744, 69.152, 70.994, 72.301, 9279525.000, 10270856.000, 11000948.000, 12760499.000, 14760787.000, 17152804.000, 20033753.000, 23254956.000, 26298373.000, 29072015.000, 31287142.000, 33333216.000, 2449.008, 3013.976, 2550.817, 3246.992, 4182.664, 4910.417, 5745.160, 5681.359, 5023.217, 4797.295, 5288.040, 6223.367\n    Angola     Africa  1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 30.015, 31.999, 34.000, 35.985, 37.928, 39.483, 39.942, 39.906, 40.647, 40.963, 41.003, 42.731, 4232095.000, 4561361.000, 4826015.000, 5247469.000, 5894858.000, 6162675.000, 7016384.000, 7874230.000, 8735988.000, 9875024.000, 10866106.000, 12420476.000, 3520.610, 3827.940, 4269.277, 5522.776, 5473.288, 3008.647, 2756.954, 2430.208, 2627.846, 2277.141, 2773.287, 4797.231\n    Argentina  Americas1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 62.485, 64.399, 65.142, 65.634, 67.065, 68.481, 69.942, 70.774, 71.868, 73.275, 74.340, 75.320, 17876956.000, 19610538.000, 21283783.000, 22934225.000, 24779799.000, 26983828.000, 29341374.000, 31620918.000, 33958947.000, 36203463.000, 38331121.000, 40301927.000, 5911.315, 6856.856, 7133.166, 8052.953, 9443.039, 10079.027, 8997.897, 9139.671, 9308.419, 10967.282, 8797.641, 12779.380\n    Australia  Oceania 1952.000, 1957.000, 1962.000, 1967.000, 1972.000, 1977.000, 1982.000, 1987.000, 1992.000, 1997.000, 2002.000, 2007.000, 69.120, 70.330, 70.930, 71.100, 71.930, 73.490, 74.740, 76.320, 77.560, 78.830, 80.370, 81.235, 8691212.000, 9712569.000, 10794968.000, 11872264.000, 13177000.000, 14074100.000, 15184200.000, 16257249.000, 17481977.000, 18565243.000, 19546792.000, 20434176.000, 10039.596, 10949.650, 12217.227, 14526.125, 16788.629, 18334.198, 19477.009, 21888.889, 23424.767, 26997.937, 30687.755, 34435.367\n\n\n\n\n\n\n\n\n몇가지 유용한 함수는 원자 벡터를 입력하여 리스트를 반환한다. 예를 들어 stringr::str_split(). mutate 함수 안에서 이를 사용하면 리스트-열을 얻을 수 있다.\n\n\ndf <- tribble(\n    ~x1,\n    \"a,b,c\",\n    \"d,e,f,g\"\n    )\ndf\n\n\n\nA tibble: 2 × 1\n\n    x1\n    <chr>\n\n\n    a,b,c  \n    d,e,f,g\n\n\n\n\n\ndf %>%\nmutate(x2 = stringr::str_split(x1, \",\"))\n\n\n\nA tibble: 2 × 2\n\n    x1x2\n    <chr><list>\n\n\n    a,b,c  a, b, c\n    d,e,f,gd, e, f, g\n\n\n\n\nunnest() 함수는 벡터 리스트 다루는 방법을 알고 있다.\n\ndf %>%\nmutate(x2 = stringr::str_split(x1, \",\")) %>%\nunnest()\n\nWarning message:\n“`cols` is now required when using unnest().\nPlease use `cols = c(x2)`”\n\n\n\n\nA tibble: 7 × 2\n\n    x1x2\n    <chr><chr>\n\n\n    a,b,c  a\n    a,b,c  b\n    a,b,c  c\n    d,e,f,gd\n    d,e,f,ge\n    d,e,f,gf\n    d,e,f,gg\n\n\n\n\n\n이 패턴을 많이 사용하는 경우에는 공통 패턴을 포함하는 tidyr:separate_row()를 반드시 확인한다. 이 패턴의 또 다른 예제는 purr의 map(), map2(), pmap() 함수를 사용하는 것이다.\n\n\nsim <- tribble(\n    ~f, ~params,\n    \"runif\", list(min = -1, max = -1),\n    \"rnorm\", list(sd = 5),\n    \"rpois\", list(lambda = 10)\n    )\nsim\n\n\n\nA tibble: 3 × 2\n\n    fparams\n    <chr><list>\n\n\n    runif-1, -1\n    rnorm5\n    rpois10\n\n\n\n\n\nsim %>%\nmutate(sims = invoke_map(f, params, n = 10))\n\n\n\nA tibble: 3 × 3\n\n    fparamssims\n    <chr><list><list>\n\n\n    runif-1, -1-1, -1, -1, -1, -1, -1, -1, -1, -1, -1\n    rnorm50.8244597185, 7.4269963753, -0.2802207175, 2.1495297875, -0.0002438665, 6.1046357552, 6.5391574008, -8.5557067705, -2.5508686388, 2.3913567687\n    rpois109, 14, 9, 14, 8, 8, 10, 14, 9, 16\n\n\n\n\n\nsim은 더블형과 정수형 벡터 둘 다 포함하므로 기술적으로 똑같지 않다. 그러나 정수형과 더블형 벡터 모두 수치형 벡터이므로 많은 문제가 발생하지 않는다.\n\n\n\n\nsummarize()의 한 가지 제약은 단일 값을 반환하는 요약 함수로만 동작한다는 것이다. 즉, 임의 길이의 벡터를 반환하는 quantile()과 같은 함수와 함께 사용할 수 없다는 것을 의미한다.\n\nmtcars %>%\ngroup_by(cyl) %>%\nsummarize(q = quantile(mpg))\n\n`summarise()` has grouped output by 'cyl'. You can override using the `.groups`\nargument.\n\n\n\n\nA grouped_df: 15 × 2\n\n    cylq\n    <dbl><dbl>\n\n\n    421.40\n    422.80\n    426.00\n    430.40\n    433.90\n    617.80\n    618.65\n    619.70\n    621.00\n    621.40\n    810.40\n    814.40\n    815.20\n    816.25\n    819.20\n\n\n\n\n\n결과를 리스트로 넣기 각각의 요약은 길이가 1인 리스트(벡터)이므로 summarize()함수의 규칙을 따른다.\n\n\nmtcars %>% \ngroup_by(cyl) %>%\nsummarize(q = list(quantile(mpg)))\n\n\n\nA tibble: 3 × 2\n\n    cylq\n    <dbl><list>\n\n\n    421.4, 22.8, 26.0, 30.4, 33.9\n    617.80, 18.65, 19.70, 21.00, 21.40\n    810.40, 14.40, 15.20, 16.25, 19.20\n\n\n\n\n\nunnest()를 사용하여 유용한 결과를 얻기 위해서는 확률값을 포착해야 한다.\n\n\nprobs <- c(0.01, 0.25, 0.5, 0.75, 0.99)\nmtcars %>%\ngroup_by(cyl) %>%\nsummarize(p = list(probs), q = list(quantile(mpg, probs))) %>%\nunnest()\n\nWarning message:\n“`cols` is now required when using unnest().\nPlease use `cols = c(p, q)`”\n\n\n\n\nA tibble: 15 × 3\n\n    cylpq\n    <dbl><dbl><dbl>\n\n\n    40.0121.410\n    40.2522.800\n    40.5026.000\n    40.7530.400\n    40.9933.750\n    60.0117.818\n    60.2518.650\n    60.5019.700\n    60.7521.000\n    60.9921.376\n    80.0110.400\n    80.2514.400\n    80.5015.200\n    80.7516.250\n    80.9919.135\n\n\n\n\n\n\n\n\n리스트-열이 있는 데이터프레임은 다음의 일반적인 문제에 대한 해결책을 제공한다. 리스트의 내용과 요소, 둘 다 반복하고자 할 때는 어떻게 할 것인가? 모든 것을 하나의 객체로 묶으려고 하는 대신 데이터프레임을 만드는 것이 더 쉽다. 하나의 열은 요소를 포함할 수 있고, 다른 하나의 열은 리스트를 포함할 수 있다. 리스트에서 이러한 데이터프레임을 만드는 쉬운 방법은 tibble::enframe()을 사용하는 것이다.\n\n\nx <- list(\n    a=1:5,\n    b=3:4,\n    c=5:6)\n\ndf <- enframe(x)\ndf\n\n\n\nA tibble: 3 × 2\n\n    namevalue\n    <chr><list>\n\n\n    a1, 2, 3, 4, 5\n    b3, 4\n    c5, 6\n\n\n\n\n\n이 구조의 장점은 간단한 방법으로 일반화한다는 것이다. 메타 데이터에 문자형 벡터가 있는 경우 이름(name)에는 유용하지만 다른 유형의 데이터 또는 여러 벡터가 있는 경우 유용하지 않다.\n\n\ndf %>%\nmutate(\n    smry = map2_chr(\n        name,\n        value,\n        ~ stringr::str_c(.x, \": \", .y[1])\n        )\n    )\n\n\n\nA tibble: 3 × 3\n\n    namevaluesmry\n    <chr><list><chr>\n\n\n    a1, 2, 3, 4, 5a: 1\n    b3, 4b: 3\n    c5, 6c: 5\n\n\n\n\n\n\n\n\n데이터 처리 및 시각화 기술을 적용하기 위해서는 리스트-열을 일반 열(원자 벡터) 또는 열의 집합으로 다시 단순화해야 한다. 더 간단한 구조로 축소하기 위해 사용할 기법은 요소당 하나의 값을 사용하는지 또는 여러 값을 사용하는지에 따라 달라진다.\n\n\n단일 값을 원하는 경우 map_lgl(), map_int(), map_dbl(), map_chr()에 mutate()를 사용하여 원자 벡터를 생성한다. 많은 값을 원하는 경우 unnest()를 사용하여 리스트-열을 일반 열로 다시 변환하고 필요한 만큼 행을 반복한다.\n\n\n\n\n리스트 열을 원자 벡터로 줄일 수 있다면 리스트 열은 일반 열이 될 것이다. 예를 들어 타입과 길이를 가진 객체는 항상 요약할 수 있으므로 다음 코드는 리스트 열의 종류에 관계없이 작동할 것이다.\n\n\ndf <- tribble(\n    ~x,\n    letters[1:5],\n    1:3,\n    runif(5)\n    )\ndf\n\n\n\nA tibble: 3 × 1\n\n    x\n    <list>\n\n\n    a, b, c, d, e\n    1, 2, 3\n    0.5219118, 0.7152954, 0.5081047, 0.6517999, 0.3156121\n\n\n\n\n\ndf %>% mutate(\n    type = map_chr(x, typeof),\n    length = map_int(x, length)\n    )\n\n\n\nA tibble: 3 × 3\n\n    xtypelength\n    <list><chr><int>\n\n\n    a, b, c, d, echaracter5\n    1, 2, 3integer  3\n    0.5219118, 0.7152954, 0.5081047, 0.6517999, 0.3156121double   5\n\n\n\n\n\n이는 기본 tbl print 방법에서 얻은 것과 같은 기본 정보지만, 여기에서는 필터링 용도로 사용할 수 있다.  다차원적인 리스트에 대해서 작동하지 않는 부분을 필터링하고자 할 때 유용한 기법이다. map_*()단축어를 기억하자. 예를 들어 map_chr(x, \"apple\")를 사용하여 x의 각 요소에 대해 apple에 저장된 문자열을 추출할 수 있다. 이는 중첩된 리스트를 일반 열로 분리할 때 유용하다. 리스트의 요소가 누락된 경우 (NULL을 반환한느 대신) 사용할 값을 제공하는 .null인수를 사용한다.\n\n\ndf <- tribble(\n    ~x,\n    list(a=1, b=2),\n    list(a=2, c=4)\n    )\ndf\n\n\n\nA tibble: 2 × 1\n\n    x\n    <list>\n\n\n    1, 2\n    2, 4\n\n\n\n\n\ndf %>% mutate(\n    a = map_dbl(x, \"a\"),\n    b = map_dbl(x, \"b\", .null = NA_real_)\n    )\n\n\n\nA tibble: 2 × 3\n\n    xab\n    <list><dbl><dbl>\n\n\n    1, 21 2\n    2, 42NA\n\n\n\n\n\n\n\n\nunnest()는 리스트-열의 각 요소를 한 줄씩 일반 열로 반복하며 동작한다. 예를 들어 다음의 아주 간단한 예제에서는 (y의 첫번째 요소 길이가 4이므로) 첫 번째 행은 4번 반복하고 두 번째 행은 한 번만 반복한다.\n\n\ntibble(x = 1:2, y = list(1:4, 1)) %>% unnest(y)\n\n\n\nA tibble: 5 × 2\n\n    xy\n    <int><dbl>\n\n\n    11\n    12\n    13\n    14\n    21\n\n\n\n\n\n즉, 이는 다른 수의 요소가 포함된 두 개의 열을 동시에 중첩 해제할 수 없다는 것을 의미한다.\n\n\ndf1 <- tribble(\n    ~x, ~y, ~z,\n    1, c(\"a\", \"b\"), 1:2,\n    2, \"c\", 3\n    )\ndf1\n\n\n\nA tibble: 2 × 3\n\n    xyz\n    <dbl><list><list>\n\n\n    1a, b1, 2\n    2c3\n\n\n\n\n\ndf1 %>% unnest(y, z)\n\nWarning message:\n“unnest() has a new interface. See ?unnest for details.\nTry `df %>% unnest(c(y, z))`, with `mutate()` if needed”\n\n\n\n\nA tibble: 3 × 3\n\n    xyz\n    <dbl><chr><dbl>\n\n\n    1a1\n    1b2\n    2c3\n\n\n\n\n\ndf2 <- tribble(\n    ~x, ~y, ~z,\n    1, \"a\", 1:2,\n    2, c(\"b\",\"c\"), 3\n    )\ndf2\n\n\n\nA tibble: 2 × 3\n\n    xyz\n    <dbl><list><list>\n\n\n    1a1, 2\n    2b, c3\n\n\n\n\n\ndf2 %>% unnest(y, z)\n\nWarning message:\n“unnest() has a new interface. See ?unnest for details.\nTry `df %>% unnest(c(y, z))`, with `mutate()` if needed”\n\n\n\n\nA tibble: 4 × 3\n\n    xyz\n    <dbl><chr><dbl>\n\n\n    1a1\n    1a2\n    2b3\n    2c3\n\n\n\n\n\n데이터프레임의 리스트-열을 중첩 해제할 때도 같은 원칙이 적용된다. 각 행의 모든 데이터프레임이 같은 개수의 행을 가지고 있다면 여러 개의 리스트-열을 중첩 해제할 수 있다.\n\n\n\n\n\n\nbroom 패키지는 모델을 타이디 데이터프레임으로 변환할 수 있는 세 가지의 일반적인 도구를 제공한다.\n\n\nbroom::glance(model)은 각 모델에 대한 행을 반환한다. 각 열에는 모델 요약(모델 성능 척도 또는 복잡성 또는 둘의 조합)이 표시된다. broom::tidy(model)은 모델의 각 계수에 대한 행을 반환한다. 각 열의 추정값 또는 변동성에 대한 정보를 제공한다. broom::augment(model, data)는 data의 각 행에 잔차와 같은 영향 통계량을 추가하여 반환한다."
  },
  {
    "objectID": "posts/datascience-for-r/2022-09-01_반복문.html",
    "href": "posts/datascience-for-r/2022-09-01_반복문.html",
    "title": "반복문",
    "section": "",
    "text": "apply(lapply, sapply), map(map2, pmap, invoke_map), reduce\n\nlibrary('tidyverse')\nlibrary('data.table')\n\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\n\n\nmedian(df$a)\n\n0.362010450965252\n\n\n\noutput <- vector(\"double\", ncol(df))\nfor(i in seq_along(df)){\n    output[[1]] <- median(df[[i]])\n    }\noutput\n\n\n-0.113482282023113000\n\n\n\ny <- vector(\"double\", 0)\nseq_along(y)\n\n\n\n\n\n1:length(y)\n\n\n10\n\n\nseq_along : 간격 1로 고정된 seq 예를들어, seq_along(1:10) = 1,2,3….10으로 출력\nrange : 입력값들 중에서 최소값과 최대값 출력\n- for문 사용해서 데이터프레임 변경 예시\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\ndf_ori <- copy(df)\nrescale01 <- function(x){\n    rng <- range(x, na.rm = TRUE)\n    (x - rng[1]) / (rng[2] - rng[1])\n    }\n\n\ndf_ori\n\n\n\nA tibble: 10 × 4\n\n    abcd\n    <dbl><dbl><dbl><dbl>\n\n\n     0.101961343-0.71086623-0.25512630 0.5539966\n    -0.316890930-1.53110514-0.46776683 0.4088169\n     0.475460867 0.69184710-0.52080481-1.1331320\n     0.633766246-0.34604681-0.25575415 0.2928074\n    -0.001845828-0.25148523 0.91689638 0.1911644\n     0.455532073-1.04661644 0.40009228 0.6358231\n     0.043596138 1.04180720 1.33016238 1.3531848\n     0.348391867 0.97740881 0.06871437-2.3191413\n     0.582021699-0.04129945 0.54256432 0.8905353\n     0.074872799 0.48993701 0.04458287 0.9957713\n\n\n\n\n\ndf$a <- rescale01(df$a)\ndf$b <- rescale01(df$b)\ndf$c <- rescale01(df$c)\ndf$d <- rescale01(df$d)\n\n\n변경해주는 것도 for문 사용해서 변경하기\n\n\nfor (i in seq_along(4)){\n    df[[i]] <- rescale01(df[[i]])\n    }\n\n\ndf\n\n\n\nA tibble: 10 × 4\n\n    abcd\n    <dbl><dbl><dbl><dbl>\n\n\n    0.44059230.31879780.14353500.7823755\n    0.00000000.00000000.02865420.7428420\n    0.83347800.86398290.00000000.3229586\n    1.00000000.46059020.14319580.7112518\n    0.33139720.49734300.77672970.6835737\n    0.81251480.18830360.49752210.8046574\n    0.37919781.00000001.00000001.0000000\n    0.69981360.97497060.31849250.0000000\n    0.94556970.57903480.57449380.8740173\n    0.41209780.78550760.30545530.9026738\n\n\n\n\n\n\n\n벡터를 점진적으로 늘려가는 방법으로 해결한다면?\n\nrnorm(n, mean, sd) : 정규분포 난수 만들기 double : 소수점 얼마얼마 숫자(정수도 가능) length : vector 개수 세기\n\nmeans <- c(0, 1, 2)\n\noutput <- double()\nfor (i in seq_along(means)){\n    n <- sample(100, 1) # 1~100중 1개 선택\n    output <- c(output, rnorm(n, means[[i]]))\n    }\nstr(output)\n\n num [1:110] -0.7369 0.0787 -2.256 -0.6757 0.1158 ...\n\n\n\nout <- vector(\"list\", length(means))\nfor(i in seq_along(means)){\n    n <- sample(100,1)\n    out[[i]] <- rnorm(n, means[[i]])\n    }\nstr(out)\n\nList of 3\n $ : num [1:75] 0.4274 0.0549 -0.223 1.2001 0.123 ...\n $ : num [1:98] 1.6386 1.0974 1.1385 0.0381 -0.5397 ...\n $ : num [1:75] 2.529 3.133 0.915 2.794 1.578 ...\n\n\nunlist : 벡터의 리스트를 단일 벡터로 플랫하게 만들기\n\nstr(unlist(out))\n\n num [1:248] 0.4274 0.0549 -0.223 1.2001 0.123 ...\n\n\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\n\n\nmap_dbl(df, mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\nmap : 함수를 적용시켜 리스트로 출력해주는 함수 map(x,f) 형태\n\n\n리스트로 출력해준다고 했는데 뒤에 접미사 다른 거 붙이면 다른 형태로도 출력가능 map() : 리스트 map_lgl() : 논리형 벡터 map_int() : 정수형 벡터 map_dbl() : 더블형 벡터 map_chr() : 문자형 벡터\n\n\n- 예시\n\nmap_dbl(df, mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\n\nmap_dbl(df, median)\n\na-0.542239777185805b-0.855557504853792c0.838733172985942d-0.323875457122516\n\n\n\nmap_dbl(df, sd)\n\na1.07926902284635b1.22672862747107c0.615238020380514d1.23052848204296\n\n\n\n파이프 연산자 역시 사용가능\n\n\ndf %>% map_dbl(mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\n\n맵 함수는 또한 이름을 유지한다.\n\n\nz <- list(x = 1:3, y = 4:5)\nmap_int(z, length)\n\nx3y2\n\n\n- 데이터 셋 각 그룹에 선형 모형을 적합하기 - 여기에서 .은 현재 리스트 요소를 가르키는 역할이다.\n\nmodels <- mtcars %>% \nsplit(.$cyl) %>%\nmap(~lm(mpg ~ wt, data = .))\n\n\nmodels\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\n\n- 같은 방식으로 .을 사용하여 \\(R^2\\) 출력\n\nmodels %>%\nmap(summary) %>%\nmap_dbl(~.$r.squared)\n\n40.5086325963231460.46451015055054880.422965536496111\n\n\n\n아예 이름을 불러 호출하여 추출하는 방법\n\n\nmodels %>%\nmap(summary) %>%\nmap_dbl(\"r.squared\")\n\n40.5086325963231460.46451015055054880.422965536496111\n\n\n\n정수형을 사용하여 위치로 요소를 선택할 수도 있다.\n\n\nx <- list(list(1,2,3), list(4,5,6), list(7,8,9))\nx %>%\nmap_dbl(2)\n\n\n258\n\n\n\n\n\n\napply : 행렬의 행 또는 열 방향으로 특정 함수를 적용한다. ex) apply(array, 방향, 함수) 이때, 방향은 1=행, 2=열 대신 위에 나온 것처럼 apply는 array밖에 입력 안된다.  lapply : 똑같은데 입력으로 vector 또는 list를 받아 list를 반환한다. 데이터 프레임도 적용가능하다.(데이터 프레임은 list 기반이기에)  sapply : lapply에서 list 대신 행렬 or 벡터로 반환한다. 등등\n\n- 예시\n\nx1 <- list(\n    c(0.27, 0.37, 0.57, 0.91, 0.20),\n    c(0.90, 0.94, 0.66, 0.63, 0.06),\n    c(0.21, 0.18, 0.69, 0.38, 0.77)\n    )\nx2 <- list(\n    c(0.50, 0.72, 0.99, 0.38, 0.78),\n    c(0.93, 0.21, 0.65, 0.13, 0.27),\n    c(0.39, 0.01, 0.38, 0.87, 0.34)\n    )\n\n\nthreshold <- function(x, cutoff = 0.9) x[x > cutoff] # 여기서 cutoff는 그냥 명명한 거. 뜻 없음\nx1 %>% sapply(threshold) %>% str()\n\nList of 3\n $ : num 0.91\n $ : num 0.94\n $ : num(0) \n\n\n\nx2 %>% sapply(threshold) %>% str()\n\nList of 3\n $ : num 0.99\n $ : num 0.93\n $ : num(0) \n\n\n\n\n\nsafely : 계산상에 오류가 있는지 확인해준다. 오류가 없으면 error에 NULL로 표기\n\nsafe_log <- safely(log)\nstr(safe_log(10))\n\nList of 2\n $ result: num 2.3\n $ error : NULL\n\n\n\nstr(safe_log(\"a\"))\n\nList of 2\n $ result: NULL\n $ error :List of 2\n  ..$ message: chr \"수학함수에 숫자가 아닌 인자가 전달되었습니다\"\n  ..$ call   : language .Primitive(\"log\")(x, base)\n  ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\n\n\n\n\n\n\nmu <- list(5, 10, -3)\nsigma <- list(1, 5, 10)\nmu %>%\nmap(rnorm, n = 5) %>%\nstr()\n\nList of 3\n $ : num [1:5] 5 4.84 5.25 4.08 3.68\n $ : num [1:5] 10.25 9.78 10.39 10.78 12.78\n $ : num [1:5] -1.15 -2.11 -2.37 -2.99 -2.69\n\n\n\n아래는 다음의 과정을 거쳐 작동된다.\n\n\n\n\nmu\nsigma\nmap2(mu, sigma, rnorm, n = 10)\n\n\n\n\n5\n1\nrnorm(5, 1, n = 10)\n\n\n10\n5\nrnorm(10, 5, n = 10)\n\n\n-3\n10\nrnorm(-3, 10, n = 10)\n\n\n\n\nmap2(mu, sigma, rnorm, n = 10)\n\n\n    \n4.349467887707474.824739556540025.116070093806054.438424173656614.311806245932135.001691148385446.025764457163115.006236997835643.415325280626594.56435385331102\n\n    \n9.389706217853512.429470779734310.779377578046614.17528995582757.6176367057342318.057691977141812.66881272755925.519712814552037.0422019215429312.8668843514661\n\n    \n-12.12632850681018.10375813436303-2.77099269255498-8.017821324584639.23333321085482-2.762977006435372.10853033340745-16.3415111650991-8.0945480461034-6.86634956802985\n\n\n\n\n\n\n\n\nmap3, map4등등 계속 숫자를 올릴 수 없으므로 그 이상은 pmap을 사용한다. pmap : map인데 인수를 리스트로 받을 수 있음.\n\n- 예시\n\nn <- list(1, 3, 5)\nargs1 <- list(n, mu, sigma)\nargs1 %>%\npmap(rnorm) %>%\nstr()\n\nList of 3\n $ : num 4.53\n $ : num [1:3] 1.13 9.61 3.6\n $ : num [1:5] -9.5 -9.63 -29.9 -11.2 -7.71\n\n\npmap의 작동 구조는 다음과 같다.\n\n\n\n\nargs1\n\npmap(args1)\n\n\n\n\n1\n5\n1\nrnorm(1, 5, 1)\n\n\n3\n10\n5\nrnorm(3, 10, 5)\n\n\n5\n-3\n10\nrnorm(5, -3, 10)\n\n\n\n\n아예 명령시킬 것을 명명시켜 리스트형태로 넣어서 사용도 가능하다. 위의 방법이 위치에 맞는 함수나 인수들을 받아들이는 거라면 이거는 이름 붙인 것을 꺼내는 방식이라 오류가 더 적다.\n\n\nargs2 <- list(mean = mu, sd = sigma, n = n)\nargs2 %>%\npmap(rnorm) %>%\nstr()\n\nList of 3\n $ : num 4.31\n $ : num [1:3] 4.01 15.02 20.1\n $ : num [1:5] -2.02 -14.74 17.28 -7.93 -4.06\n\n\n\nmu, sigma, n 모두 인수의 길이가 같기 때문에 데이터프레임으로 저장하고 사용하는 것도 가능하다. 코드가 복잡하다면 이 방법이 더 유용하다.\n\n\nparams <- tribble(\n    ~mean, ~sd, ~n,\n    5 ,  1, 1,\n    10,  5, 3,\n    -3, 10, 5\n    )\nparams\n\n\n\nA tibble: 3 × 3\n\n    meansdn\n    <dbl><dbl><dbl>\n\n\n     5 11\n    10 53\n    -3105\n\n\n\n\n\nparams %>%\npmap(rnorm)\n\n\n    6.15037626545721\n    \n9.8922797604828519.631019470154110.6521306803585\n\n    \n-16.7748421066845.89682521421044-3.8973650519893612.9090332777723-2.7446162856276\n\n\n\n\n\nf <- c(\"runif\", \"rnorm\", \"rpois\")\nparam <- list(\n    list(min = -1, max = 1),\n    list(sd = 5),\n    list(lambda = 10)\n    )\n\n\nf\n\n\n'runif''rnorm''rpois'\n\n\n\nparam\n\n\n    \n    $min\n        -1\n    $max\n        1\n\n\n    $sd = 5\n    $lambda = 10\n\n\n\n\ninvoke_map(f, param, n = 5) %>% str()\n\nList of 3\n $ : num [1:5] -0.408 0.918 0.437 0.206 0.574\n $ : num [1:5] -1.99 -3.46 -1.99 -4.26 -2.59\n $ : int [1:5] 5 7 6 8 14\n\n\n\n\n\n\npmap에서 한 술 더 떠서 이름이 지정된 리스트를 불러서 그 이름에 해당하는 함수 적용까지 가능하다.\n\ninvoke_map의 작동구조는 다음과 같다.\n\n\n\nf\nparams\ninvoke_map(f, params, n = 5)\n\n\n\n\n“runif”\n-1,1\nrunif(min = -1, max = 1, n = 1)\n\n\n“rnorm”\n5\nrnorm(sd = 5, n = 5)\n\n\n“rpois”\n10\nrpois(lambda = 10, n = 5)\n\n\n\n- 자료를 tribble에 빠르게 넣고 빠르게 적용하기\n\nsim <- tribble(\n    ~f, ~params,\n    \"runif\", list(min = -1, max = 1),\n    \"rnorm\", list(sd = 5),\n    \"rpois\", list(lambda = 10)\n    )\nsim\n\n\n\nA tibble: 3 × 2\n\n    fparams\n    <chr><list>\n\n\n    runif-1, 1\n    rnorm5\n    rpois10\n\n\n\n\n\nsim %>%\nmutate(sim = invoke_map(f, params, n = 10))\n\n\n\nA tibble: 3 × 3\n\n    fparamssim\n    <chr><list><list>\n\n\n    runif-1, 10.07894134, -0.86898545, -0.15951936, 0.78716288, -0.83887923, 0.91604573, -0.71653860, -0.20937246, 0.73207933, -0.55086865\n    rnorm54.6303684, 1.4773254, -6.1243872, -0.3974409, -0.3804220, -1.6938584, 4.8958890, 5.0882558, -8.4444484, 7.0620562\n    rpois1016, 13, 14, 13, 13, 7, 11, 6, 7, 10\n\n\n\n\nsome : 일부 요소가 참인지 알려줌. every : 모든 요소가 참인지 알려줌.\n\nx <- list(1:5, letters, list(10))\nx\n\n\n    \n12345\n\n    \n'a''b''c''d''e''f''g''h''i''j''k''l''m''n''o''p''q''r''s''t''u''v''w''x''y''z'\n\n    \n    10\n\n\n\n\n\n\nx %>%\nsome(is.character)\n\nTRUE\n\n\n\nx %>% \nevery(is_vector)\n\nTRUE\n\n\ndetect : 논리서술이 참인 첫 번째 요소를 찾아준다. detect_index : 논리서술이 참인 첫 번째 요소의 해당 위치를 반환하다. head_while : 벡터의 시작에서부터 논리서술자가 참인 요소들을 반환한다. tail_while : 벡터의 끝에서부터 논리서술자가 참인 요소들을 반환한다.\n\nx <- sample(10)\nx\n\n\n91045761283\n\n\n\nx %>%\ndetect(~ . > 5)\n\n9\n\n\n\nx %>%\ndetect_index(~ . > 5) \n\n1\n\n\n\nx %>%\nhead_while(~ . > 5)\n\n\n910\n\n\n\nx %>%\ntail_while(~ . > 5)\n\n\n\n\n\n\n\n\n\n데이터프레임 리스트가 있을 때, 리스트의 요소를 “조인”해서 하나의 데이터프레임으로 만들어준다.\n\n\ndfs <- list(\n    age = tibble(name = \"John\", age = 30),\n    sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n    trt = tibble(name = \"Mary\", treatment = \"A\")\n    )\n\n\ndfs\n\n\n\n    $age\n        \nA tibble: 1 × 2\n\n    nameage\n    <chr><dbl>\n\n\n    John30\n\n\n\n    $sex\n        \nA tibble: 2 × 2\n\n    namesex\n    <chr><chr>\n\n\n    JohnM\n    MaryF\n\n\n\n    $trt\n        \nA tibble: 1 × 2\n\n    nametreatment\n    <chr><chr>\n\n\n    MaryA\n\n\n\n\n\n\n\ndfs %>% reduce(full_join)\n\nJoining, by = \"name\"\nJoining, by = \"name\"\n\n\n\n\nA tibble: 2 × 4\n\n    nameagesextreatment\n    <chr><dbl><chr><chr>\n\n\n    John30MNA\n    MaryNAFA \n\n\n\n\n\n벡터의 리스트가 있을 때, 교집합을 구하는 방법\n\n\nvs <- list(\n    c(1, 3, 5, 6, 10),\n    c(1, 2, 3, 7, 8, 10),\n    c(1, 2, 3, 4, 8, 9, 10)\n    )\nvs\n\n\n    \n135610\n\n    \n1237810\n\n    \n12348910\n\n\n\n\n\nvs %>% reduce(intersect)\n\n\n1310"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-02-data_handling_b.html",
    "href": "posts/datascience-for-r/2022-08-02-data_handling_b.html",
    "title": "Data handling b",
    "section": "",
    "text": "시각화, 결측값, 공변동, 패턴과 모델\n\nlibrary('tidyverse')\n\n\n모든 연속형 변수를 두 번 이상 측정하면 다른 값이 나온다. 이 때 변수의 측정값이 변하는 경향을 변동(variation)이라고 말한다. 범주형 변수 역시 서로 다른 피실험자 또는 다른 시간을 측정하는 경우 다를 수 있다. 결국 각각의 측정값은 서로 다른 약간의 오차를 포함하는데 이 때 모든 변수들은 고유한 변동 패턴을 가지고 있고 이러한 패턴을 이해하는 가장 좋은 방법은 변수들 값의 분포를 시각화 하는 것이다.\n\n\n\n- 범주형 변수\n\nggplot(data = diamonds) + \ngeom_bar(mapping = aes(x = cut))\n\n\n\n\n\ndiamonds %>% count(cut)\n\n\n\nA tibble: 5 × 2\n\n    cutn\n    <ord><int>\n\n\n    Fair      1610\n    Good      4906\n    Very Good12082\n    Premium  13791\n    Ideal    21551\n\n\n\n\n- 연속형 변수\n\nggplot(data = diamonds) +\ngeom_histogram(mapping = aes(x= carat), binwidth = 0.5)\n\n\n\n\n\ndiamonds %>%\ncount(cut_width(carat, 0.5))\n\n\n\nA tibble: 11 × 2\n\n    cut_width(carat, 0.5)n\n    <fct><int>\n\n\n    [-0.25,0.25]  785\n    (0.25,0.75] 29498\n    (0.75,1.25] 15977\n    (1.25,1.75]  5313\n    (1.75,2.25]  2002\n    (2.25,2.75]   322\n    (2.75,3.25]    32\n    (3.25,3.75]     5\n    (3.75,4.25]     4\n    (4.25,4.75]     1\n    (4.75,5.25]     1\n\n\n\n\n\nsmaller <- diamonds %>%\nfilter(carat < 3)\n\nggplot(data = smaller, mapping = aes(x = carat)) +\ngeom_histogram(binwidth = 0.1)\n\n\n\n\ngeom_freqpoly : 같은 플롯에서 여러개의 히스토그램을 겹처서 그리기\n\nggplot(data = smaller, mapping = aes(x = carat, color = cut)) +\ngeom_freqpoly(binwidth = 0.1)\n\n\n\n\n\nggplot(data = smaller, mapping = aes(x = carat)) +\ngeom_histogram(binwidth = 0.01)\n\n\n\n\n\n위의 그래프는 일부 캐럿의 다이아몬드가 많은 의문을 자아낸다.일반적이라면 정규분포 혹은 고르게 분포할 것으로 예상해 볼 수 있겠다.\n\n\nfaithful %>% head #Yellowstone 분출간격 자료\n\n\n\nA data.frame: 6 × 2\n\n    eruptionswaiting\n    <dbl><dbl>\n\n\n    13.60079\n    21.80054\n    33.33374\n    42.28362\n    54.53385\n    62.88355\n\n\n\n\n\nggplot(data = faithful, mapping = aes(x = eruptions)) + \ngeom_histogram(binwidth = 0.25)\n\n\n\n\n\nggplot(diamonds) +\ngeom_histogram(mapping = aes(x = y), binwidth = 0.5)\n\n\n\n\n\n이런 특정한 구간에 관측값이 쏠려 있는 경우 이상값을 알아내기 어려움.그래서 보고 싶은 구간을 확대해서 본다.\n\ncoord_cartesian : x축 or y축의 지정한 특정 범위를 확대해서 보여줌.\n\nggplot(diamonds) +\ngeom_histogram(mapping = aes(x = y), binwidth = 0.5) +\ncoord_cartesian(ylim = c(0, 50))\n\n\n\n\n\n원본 y축이 0~ 12,000 범위였는데 0 ~ 50 구간으로 확대해서 본 모습 보이지 않던 이상치들이 보이기 시작함.\n\n- 위의 그래프에서 보인 두개의 이상값 추출하기 위해 범위를 특정해서 필터링해보기\n\nunusual <- diamonds %>%\nfilter(y < 3 | y > 20) %>%\nselect(price, x, y, z) %>%\narrange(y)\n\n\nunusual\n\n\n\nA tibble: 9 × 4\n\n    pricexyz\n    <int><dbl><dbl><dbl>\n\n\n     51390.00 0.00.00\n     63810.00 0.00.00\n    128000.00 0.00.00\n    156860.00 0.00.00\n    180340.00 0.00.00\n     21300.00 0.00.00\n     21300.00 0.00.00\n     20755.1531.85.12\n    122108.0958.98.06\n\n\n\n\n\n\n\n이상값 처리법 두가지 1) 이상값이 포함된 행 전체를 지운다. 2) 이상값을 결측값으로 변경한다.\n\n\n지우기(다른 측정값은 유용할 수도 있으므로 권장되지 않음)\n\n\ndiamonds2 <- diamonds %>%\nfilter(between(y, 3, 20))\n\n\ndiamonds2 %>% head\n\n\n\nA tibble: 6 × 10\n\n    caratcutcolorclaritydepthtablepricexyz\n    <dbl><ord><ord><ord><dbl><dbl><int><dbl><dbl><dbl>\n\n\n    0.23Ideal    ESI2 61.5553263.953.982.43\n    0.21Premium  ESI1 59.8613263.893.842.31\n    0.23Good     EVS1 56.9653274.054.072.31\n    0.29Premium  IVS2 62.4583344.204.232.63\n    0.31Good     JSI2 63.3583354.344.352.75\n    0.24Very GoodJVVS262.8573363.943.962.48\n\n\n\n\n\n이상값 -> 결측값\n\n\ndiamonds2 <- diamonds %>%\nmutate(y = ifelse(y < 3 | y > 20, NA, y))\ndiamonds2 %>% head\n\n\n\nA tibble: 6 × 10\n\n    caratcutcolorclaritydepthtablepricexyz\n    <dbl><ord><ord><ord><dbl><dbl><int><dbl><dbl><dbl>\n\n\n    0.23Ideal    ESI2 61.5553263.953.982.43\n    0.21Premium  ESI1 59.8613263.893.842.31\n    0.23Good     EVS1 56.9653274.054.072.31\n    0.29Premium  IVS2 62.4583344.204.232.63\n    0.31Good     JSI2 63.3583354.344.352.75\n    0.24Very GoodJVVS262.8573363.943.962.48\n\n\n\n\n\nggplot(data = diamonds2, mapping = aes(x = x, y = y)) +\ngeom_point()\n\nWarning message:\n“Removed 9 rows containing missing values (geom_point).”\n\n\n\n\n\n\nlibrary('nycflights13') #13년도 뉴욕항공편 데이터\n\n여기서\nnycflights13::flights$dep_time\n값이 NA인 값은 해당 항공편 운항이 취소된 것을 의미\n- 취소된 비행기의 예정 출발 시각과 취소되지 않은 비행기의 출발 시각 비교해보기\n\nnycflights13::flights %>%\nmutate(\n    cancelled = is.na(dep_time),\n    sched_hour = sched_dep_time %/% 100,\n    sched_min = sched_dep_time %% 100,\n    sched_dep_time = sched_hour + sched_min / 60\n    ) %>%\nggplot(mapping = aes(sched_dep_time)) +\ngeom_freqpoly(\n    mapping = aes(color = cancelled),\n    binwidth = 1/4\n    )\n\n\n\n\n\n그래프는 제대로 그려졌으나 취소된 항공편이 취소되지 않은 항공편에 비해 현저히 적기 때문에 이 플랏은 유용하지 않음. TRUE가 FALSE와 비슷한 수준(count)이라면 유의미한 비교가 가능할듯.(시계열 자료 느낌)\n\n\n\n\n변동이 변수 내의 움직임을 설명한다면 공변동(covariation)은 변수들 간의 움직임을 설명한다. 즉, 공변동은 둘 이상의 변숫값이 연관되어 동시에 변하는 경향\n\n공변동을 시각화 방법은 변수의 유형에 따라 달라진다.\n\n- 기존의 방식의 문제는 빈도수가 차이날 때 변수들의 움직임이 잘 보이지 않는다는 것이다.\n\nggplot(data = diamonds, mapping = aes(x = price)) +\ngeom_freqpoly(mapping = aes(color = cut), binwidth = 500)\n\n\n\n\n\nggplot(diamonds) +\ngeom_bar(mapping = aes(x = cut))\n\n\n\n\n\n\n..density.. : 전체적인 빈도수가 다르기에 큰 그래프에 작은 그래프들이 묻혀 모든 그래프들의 추이를 비교하기에는 어려움.(특히 빈도가 작아서 잘 안보이는 것들) density를 사용하면 그래프 아래 넓이를 1로 고정시켜주기에 각각의 추이 자체만을 비교할 때 도움이 된다. 이런식으로 안쓰고 geom_density() 형태로도 사용가능\n\nggplot(\n    data = diamonds,\n    mapping = aes(x = price, y = ..density..)\n    ) +\ngeom_freqpoly(mapping = aes(color = cut), binwidth = 500)\n\n\n\n\n\n범주형 변수로 구분된 연속형 변수의 분포를 나타내는 또 다른 방법은 boxplot\n\n\n\n\n\nggplot(data = diamonds, mapping = aes(x = cut, y= price)) +\ngeom_boxplot()\n\n\n\n\n\n박스 플롯은 분포에 대해 더 적은 정보를 확인할 수 있지만, 간단하므로 쉽게 비교할 수 있다. 위의 플롯에서 얻을 수 있는 정보는 ’더 좋은 품질의 다이아몬드가 평균적으로는 더 저렴하다’는 직관에 반하는 사실이다.\n\n\n\n\n\ncut의 경우 fair ~ ideal까지 순서에 따라 나열된 것을 비교해 분석해 보았다. 하지만, 대부분의 범주형 변수에는 이러한 고유한 순서가 없기에 순서를 변경하여 더 유용한 정보를 제공하도록 표현할 수 있다. 이 때, reorder사용\n\nreorder : 순서 재 정렬\n- mpg데이터 셋의 class 변수의 hwy를 순서 없이 그냥 나열한 plot\n\nggplot(data = mpg, mapping = aes(x = class, y= hwy)) +\ngeom_boxplot()\n\n\n\n\n- 추세를 더 쉽게 파악하기 위해 hwy 변수의 중간값을 기준으로 class변수의 순서를 변경\n\nggplot(data = mpg) +\ngeom_boxplot(\n    mapping = aes(\n        x = reorder(class, hwy, FUN = median),\n        y = hwy\n        )\n    )\n\n\n\n\n- 변수의 이름이 길다면 coord_flip으로 축 변경\n\nggplot(data = mpg) +\ngeom_boxplot(\n    mapping = aes(\n        x = reorder(class, hwy, FUN = median),\n        y = hwy\n        )\n    ) +\ncoord_flip()\n\n\n\n\n\n\ngeom_count : 각 조합에 대한 관측값 수 count\n\nggplot(data = diamonds) +\ngeom_count(mapping = aes(x = cut, y= color))\n\n\n\n\ncount : n()과 역할 같음, 다만 더 간단하다\n\ndiamonds %>%\ncount(color, cut) %>% head\n\n\n\nA tibble: 6 × 3\n\n    colorcutn\n    <ord><ord><int>\n\n\n    DFair      163\n    DGood      662\n    DVery Good1513\n    DPremium  1603\n    DIdeal    2834\n    EFair      224\n\n\n\n\n- geom_tile()함수와 fill심미성으로 시각화\n\n심미성 : 점의 크기, 모양, 색깔 같이 객체를 다르게 표현하는 속성\n\n\ndiamonds %>%\ncount(color, cut) %>%\nggplot(mapping = aes(x = color, y = cut)) +\ngeom_tile(mapping = aes(fill = n))\n\n\n\n\n\n\n\n- geom_point사용\n\nggplot(data = diamonds) +\ngeom_point(mapping = aes(x = carat, y = price))\n\n\n\n\n- 겹칠 때 잘 안보이므로 alpha사용\n\nggplot(data = diamonds) +\ngeom_point(\n    mapping = aes(x = carat, y= price),\n    alpha = 0.01\n    )\n\n\n\n\n\n매우 큰 데이터셋에서는 투명도의 효과가 미비할 수도 있다.  이 때는 bin을 사용한다. 이전에 사용한 geom_histogram, geom_freqpoly은 1차원의 빈이다. geom_bin2d, geom_hex 는 2차원의 빈 이들은 좌표 평면을 2D 빈으로 나눈 후, 각 빈에 몇 개의 점이 해당하는지 나타내기 위해 색상 채우기를 사용 이 때, geom_bin2d는 직사각형 빈을 만들고, geom_hex는 육각형 빈을 만든다.\n\n\nlibrary('hexbin')\n\nERROR: Error in library(\"hexbin\"): ‘hexbin’이라고 불리는 패키지가 없습니다\n\n\n\nggplot(data = smaller) +\ngeom_bin2d(mapping = aes(x = carat, y = price))\n\n\nggplot(data = smaller) +\ngeom_hex(mapping = aes(x = carat, y = price))\n\n- (앞에 나옴) 연속 변수를 그룹화하여 범주형 변수처럼 만들기\n\nggplot(data = smaller, mapping = aes(x = carat, y= price)) +\ngeom_boxplot(mapping = aes(group = cut_width(carat, 0.1)))\n\n\n이것의 문제는 관측값의 개수는 무시하고 보여주기에 빈도에 대한 정보는 없음 다음은 관측값 수까지 반영한 방법이다. varwidth = TRUE : 이제 박스 플롯의 너비는 점의 개수와 비례한다 유사한 방법으로 cut_number : 각 빈에 대략 같은 수의 점을 표시\n\n- cut_number이용\n\nggplot(data = smaller, mapping = aes(x = carat, y = price)) +\ngeom_boxplot(mapping = aes(group = cut_number(carat, 20)))\n\n\n\n\n\n\n데이터의 패턴은 상관관계에 대한 단서를 제공한다. 두 변수 사이에 규칙적인 관계가 존재하면 데이터의 패턴으로 나타난다. 패턴을 발견하게 되면 스스로에게 질문해본다. > 이 패턴은 우연의 일치(즉, 랜덤한 가능성) 때문인가? 패턴이 내포하는 상관관계를 어떻게 설명할 수 있는가? 패턴이 내포하는 상관관계는 얼마나 강한가? 다른 변수가 그 상관관계에 영향을 줄 수 있는가? 데이터의 개별 하위집단을 살펴보면 상관관계가 변경되는가?\n\n- Old Faithful 분출 시간과 분출 사이의 시간 사이의 산점도는 분출 사이의 대기 시간이 길수록 분출 시간도 길어지는 패턴을 보인다.\n\nggplot(data = faithful) +\ngeom_point(mapping = aes(x = eruptions, y = waiting))\n\n\n변동이 불확실성이 만드는 현상으로 생각한다면 공변동은 불확실성을 감소시키는 현상이다. 두 개의 변수가 함께 변동하면 한 변수의 값을 사용하여 다른 변수의 값을 잘 예측할 수 있다. 인과관계(특별한 경우)로 인해 공변동이 생기는 경우, 한 변수의 값을 다른 변수의 값을 통제하는 데 사용할 수 있다. 모델은 데이터에서 패턴을 추출하는 도구이다. 다이아몬드 데이터에서 컷팅과 캐럿, 캐럿과 가격은 밀접하게 관려노디어 있으므로 컷팅과 가격의 상관관계를 이해하기 어렵다. 모델을 활용하여 가격과 캐럿 간의 매우 강력한 상관관계를 제거하면 남아있는 중요한 세부요소들을 탐색할 수 있다.\n\n- 다음은 carat으로 price를 예측하는 모델을 적합시킨 다음, 잔차(예측값과 실제값의 차이)를 계산한다.  캐럿의 효과가 제거되면 잔차는 다이아몬드의 가격에 대한 관점을 제공하기에\n\nlibrary('modelr')\n\n\nmod <- lm(log(price) ~ log(carat), data = diamonds)\n\ndiamonds2 <- diamonds %>%\nadd_residuals(mod) %>%\nmutate(resid = exp(resid))\n\nggplot(data = diamonds2) +\ngeom_point(mapping = aes(x = carat, y = resid))\n\n\nggplot(data = diamonds2) +\ngeom_boxplot(mapping = aes(x = cut, y = resid))"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-17_반복문.html",
    "href": "posts/datascience-for-r/2022-08-17_반복문.html",
    "title": "반복문",
    "section": "",
    "text": "apply(lapply, sapply), map(map2, pmap, invoke_map), reduce\n\nlibrary('tidyverse')\nlibrary('data.table')\n\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\n\n\nmedian(df$a)\n\n0.362010450965252\n\n\n\noutput <- vector(\"double\", ncol(df))\nfor(i in seq_along(df)){\n    output[[1]] <- median(df[[i]])\n    }\noutput\n\n\n-0.113482282023113000\n\n\n\ny <- vector(\"double\", 0)\nseq_along(y)\n\n\n\n\n\n1:length(y)\n\n\n10\n\n\nseq_along : 간격 1로 고정된 seq 예를들어, seq_along(1:10) = 1,2,3….10으로 출력\nrange : 입력값들 중에서 최소값과 최대값 출력\n- for문 사용해서 데이터프레임 변경 예시\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\ndf_ori <- copy(df)\nrescale01 <- function(x){\n    rng <- range(x, na.rm = TRUE)\n    (x - rng[1]) / (rng[2] - rng[1])\n    }\n\n\ndf_ori\n\n\n\nA tibble: 10 × 4\n\n    abcd\n    <dbl><dbl><dbl><dbl>\n\n\n     0.101961343-0.71086623-0.25512630 0.5539966\n    -0.316890930-1.53110514-0.46776683 0.4088169\n     0.475460867 0.69184710-0.52080481-1.1331320\n     0.633766246-0.34604681-0.25575415 0.2928074\n    -0.001845828-0.25148523 0.91689638 0.1911644\n     0.455532073-1.04661644 0.40009228 0.6358231\n     0.043596138 1.04180720 1.33016238 1.3531848\n     0.348391867 0.97740881 0.06871437-2.3191413\n     0.582021699-0.04129945 0.54256432 0.8905353\n     0.074872799 0.48993701 0.04458287 0.9957713\n\n\n\n\n\ndf$a <- rescale01(df$a)\ndf$b <- rescale01(df$b)\ndf$c <- rescale01(df$c)\ndf$d <- rescale01(df$d)\n\n\n변경해주는 것도 for문 사용해서 변경하기\n\n\nfor (i in seq_along(4)){\n    df[[i]] <- rescale01(df[[i]])\n    }\n\n\ndf\n\n\n\nA tibble: 10 × 4\n\n    abcd\n    <dbl><dbl><dbl><dbl>\n\n\n    0.44059230.31879780.14353500.7823755\n    0.00000000.00000000.02865420.7428420\n    0.83347800.86398290.00000000.3229586\n    1.00000000.46059020.14319580.7112518\n    0.33139720.49734300.77672970.6835737\n    0.81251480.18830360.49752210.8046574\n    0.37919781.00000001.00000001.0000000\n    0.69981360.97497060.31849250.0000000\n    0.94556970.57903480.57449380.8740173\n    0.41209780.78550760.30545530.9026738\n\n\n\n\n\n\n\n벡터를 점진적으로 늘려가는 방법으로 해결한다면?\n\nrnorm(n, mean, sd) : 정규분포 난수 만들기 double : 소수점 얼마얼마 숫자(정수도 가능) length : vector 개수 세기\n\nmeans <- c(0, 1, 2)\n\noutput <- double()\nfor (i in seq_along(means)){\n    n <- sample(100, 1) # 1~100중 1개 선택\n    output <- c(output, rnorm(n, means[[i]]))\n    }\nstr(output)\n\n num [1:110] -0.7369 0.0787 -2.256 -0.6757 0.1158 ...\n\n\n\nout <- vector(\"list\", length(means))\nfor(i in seq_along(means)){\n    n <- sample(100,1)\n    out[[i]] <- rnorm(n, means[[i]])\n    }\nstr(out)\n\nList of 3\n $ : num [1:75] 0.4274 0.0549 -0.223 1.2001 0.123 ...\n $ : num [1:98] 1.6386 1.0974 1.1385 0.0381 -0.5397 ...\n $ : num [1:75] 2.529 3.133 0.915 2.794 1.578 ...\n\n\nunlist : 벡터의 리스트를 단일 벡터로 플랫하게 만들기\n\nstr(unlist(out))\n\n num [1:248] 0.4274 0.0549 -0.223 1.2001 0.123 ...\n\n\n\ndf <- tibble(\n    a = rnorm(10),\n    b = rnorm(10),\n    c = rnorm(10),\n    d = rnorm(10)\n    )\n\n\nmap_dbl(df, mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\nmap : 함수를 적용시켜 리스트로 출력해주는 함수 map(x,f) 형태\n\n\n리스트로 출력해준다고 했는데 뒤에 접미사 다른 거 붙이면 다른 형태로도 출력가능 map() : 리스트 map_lgl() : 논리형 벡터 map_int() : 정수형 벡터 map_dbl() : 더블형 벡터 map_chr() : 문자형 벡터\n\n\n- 예시\n\nmap_dbl(df, mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\n\nmap_dbl(df, median)\n\na-0.542239777185805b-0.855557504853792c0.838733172985942d-0.323875457122516\n\n\n\nmap_dbl(df, sd)\n\na1.07926902284635b1.22672862747107c0.615238020380514d1.23052848204296\n\n\n\n파이프 연산자 역시 사용가능\n\n\ndf %>% map_dbl(mean)\n\na-0.362048185177478b-0.716840170078306c0.639352852031247d0.0124627667485991\n\n\n\n맵 함수는 또한 이름을 유지한다.\n\n\nz <- list(x = 1:3, y = 4:5)\nmap_int(z, length)\n\nx3y2\n\n\n- 데이터 셋 각 그룹에 선형 모형을 적합하기 - 여기에서 .은 현재 리스트 요소를 가르키는 역할이다.\n\nmodels <- mtcars %>% \nsplit(.$cyl) %>%\nmap(~lm(mpg ~ wt, data = .))\n\n\nmodels\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\n\n- 같은 방식으로 .을 사용하여 \\(R^2\\) 출력\n\nmodels %>%\nmap(summary) %>%\nmap_dbl(~.$r.squared)\n\n40.5086325963231460.46451015055054880.422965536496111\n\n\n\n아예 이름을 불러 호출하여 추출하는 방법\n\n\nmodels %>%\nmap(summary) %>%\nmap_dbl(\"r.squared\")\n\n40.5086325963231460.46451015055054880.422965536496111\n\n\n\n정수형을 사용하여 위치로 요소를 선택할 수도 있다.\n\n\nx <- list(list(1,2,3), list(4,5,6), list(7,8,9))\nx %>%\nmap_dbl(2)\n\n\n258\n\n\n\n\n\n\napply : 행렬의 행 또는 열 방향으로 특정 함수를 적용한다. ex) apply(array, 방향, 함수) 이때, 방향은 1=행, 2=열 대신 위에 나온 것처럼 apply는 array밖에 입력 안된다.  lapply : 똑같은데 입력으로 vector 또는 list를 받아 list를 반환한다. 데이터 프레임도 적용가능하다.(데이터 프레임은 list 기반이기에)  sapply : lapply에서 list 대신 행렬 or 벡터로 반환한다. 등등\n\n- 예시\n\nx1 <- list(\n    c(0.27, 0.37, 0.57, 0.91, 0.20),\n    c(0.90, 0.94, 0.66, 0.63, 0.06),\n    c(0.21, 0.18, 0.69, 0.38, 0.77)\n    )\nx2 <- list(\n    c(0.50, 0.72, 0.99, 0.38, 0.78),\n    c(0.93, 0.21, 0.65, 0.13, 0.27),\n    c(0.39, 0.01, 0.38, 0.87, 0.34)\n    )\n\n\nthreshold <- function(x, cutoff = 0.9) x[x > cutoff] # 여기서 cutoff는 그냥 명명한 거. 뜻 없음\nx1 %>% sapply(threshold) %>% str()\n\nList of 3\n $ : num 0.91\n $ : num 0.94\n $ : num(0) \n\n\n\nx2 %>% sapply(threshold) %>% str()\n\nList of 3\n $ : num 0.99\n $ : num 0.93\n $ : num(0) \n\n\n\n\n\nsafely : 계산상에 오류가 있는지 확인해준다. 오류가 없으면 error에 NULL로 표기\n\nsafe_log <- safely(log)\nstr(safe_log(10))\n\nList of 2\n $ result: num 2.3\n $ error : NULL\n\n\n\nstr(safe_log(\"a\"))\n\nList of 2\n $ result: NULL\n $ error :List of 2\n  ..$ message: chr \"수학함수에 숫자가 아닌 인자가 전달되었습니다\"\n  ..$ call   : language .Primitive(\"log\")(x, base)\n  ..- attr(*, \"class\")= chr [1:3] \"simpleError\" \"error\" \"condition\"\n\n\n\n\n\n\n\n\nmu <- list(5, 10, -3)\nsigma <- list(1, 5, 10)\nmu %>%\nmap(rnorm, n = 5) %>%\nstr()\n\nList of 3\n $ : num [1:5] 5 4.84 5.25 4.08 3.68\n $ : num [1:5] 10.25 9.78 10.39 10.78 12.78\n $ : num [1:5] -1.15 -2.11 -2.37 -2.99 -2.69\n\n\n\n아래는 다음의 과정을 거쳐 작동된다.\n\n\n\n\nmu\nsigma\nmap2(mu, sigma, rnorm, n = 10)\n\n\n\n\n5\n1\nrnorm(5, 1, n = 10)\n\n\n10\n5\nrnorm(10, 5, n = 10)\n\n\n-3\n10\nrnorm(-3, 10, n = 10)\n\n\n\n\nmap2(mu, sigma, rnorm, n = 10)\n\n\n    \n4.349467887707474.824739556540025.116070093806054.438424173656614.311806245932135.001691148385446.025764457163115.006236997835643.415325280626594.56435385331102\n\n    \n9.389706217853512.429470779734310.779377578046614.17528995582757.6176367057342318.057691977141812.66881272755925.519712814552037.0422019215429312.8668843514661\n\n    \n-12.12632850681018.10375813436303-2.77099269255498-8.017821324584639.23333321085482-2.762977006435372.10853033340745-16.3415111650991-8.0945480461034-6.86634956802985\n\n\n\n\n\n\n\n\nmap3, map4등등 계속 숫자를 올릴 수 없으므로 그 이상은 pmap을 사용한다. pmap : map인데 인수를 리스트로 받을 수 있음.\n\n- 예시\n\nn <- list(1, 3, 5)\nargs1 <- list(n, mu, sigma)\nargs1 %>%\npmap(rnorm) %>%\nstr()\n\nList of 3\n $ : num 4.53\n $ : num [1:3] 1.13 9.61 3.6\n $ : num [1:5] -9.5 -9.63 -29.9 -11.2 -7.71\n\n\npmap의 작동 구조는 다음과 같다.\n\n\n\n\nargs1\n\npmap(args1)\n\n\n\n\n1\n5\n1\nrnorm(1, 5, 1)\n\n\n3\n10\n5\nrnorm(3, 10, 5)\n\n\n5\n-3\n10\nrnorm(5, -3, 10)\n\n\n\n\n아예 명령시킬 것을 명명시켜 리스트형태로 넣어서 사용도 가능하다. 위의 방법이 위치에 맞는 함수나 인수들을 받아들이는 거라면 이거는 이름 붙인 것을 꺼내는 방식이라 오류가 더 적다.\n\n\nargs2 <- list(mean = mu, sd = sigma, n = n)\nargs2 %>%\npmap(rnorm) %>%\nstr()\n\nList of 3\n $ : num 4.31\n $ : num [1:3] 4.01 15.02 20.1\n $ : num [1:5] -2.02 -14.74 17.28 -7.93 -4.06\n\n\n\nmu, sigma, n 모두 인수의 길이가 같기 때문에 데이터프레임으로 저장하고 사용하는 것도 가능하다. 코드가 복잡하다면 이 방법이 더 유용하다.\n\n\nparams <- tribble(\n    ~mean, ~sd, ~n,\n    5 ,  1, 1,\n    10,  5, 3,\n    -3, 10, 5\n    )\nparams\n\n\n\nA tibble: 3 × 3\n\n    meansdn\n    <dbl><dbl><dbl>\n\n\n     5 11\n    10 53\n    -3105\n\n\n\n\n\nparams %>%\npmap(rnorm)\n\n\n    6.15037626545721\n    \n9.8922797604828519.631019470154110.6521306803585\n\n    \n-16.7748421066845.89682521421044-3.8973650519893612.9090332777723-2.7446162856276\n\n\n\n\n\nf <- c(\"runif\", \"rnorm\", \"rpois\")\nparam <- list(\n    list(min = -1, max = 1),\n    list(sd = 5),\n    list(lambda = 10)\n    )\n\n\nf\n\n\n'runif''rnorm''rpois'\n\n\n\nparam\n\n\n    \n    $min\n        -1\n    $max\n        1\n\n\n    $sd = 5\n    $lambda = 10\n\n\n\n\ninvoke_map(f, param, n = 5) %>% str()\n\nList of 3\n $ : num [1:5] -0.408 0.918 0.437 0.206 0.574\n $ : num [1:5] -1.99 -3.46 -1.99 -4.26 -2.59\n $ : int [1:5] 5 7 6 8 14\n\n\n\n\n\n\npmap에서 한 술 더 떠서 이름이 지정된 리스트를 불러서 그 이름에 해당하는 함수 적용까지 가능하다.\n\ninvoke_map의 작동구조는 다음과 같다.\n\n\n\nf\nparams\ninvoke_map(f, params, n = 5)\n\n\n\n\n“runif”\n-1,1\nrunif(min = -1, max = 1, n = 1)\n\n\n“rnorm”\n5\nrnorm(sd = 5, n = 5)\n\n\n“rpois”\n10\nrpois(lambda = 10, n = 5)\n\n\n\n- 자료를 tribble에 빠르게 넣고 빠르게 적용하기\n\nsim <- tribble(\n    ~f, ~params,\n    \"runif\", list(min = -1, max = 1),\n    \"rnorm\", list(sd = 5),\n    \"rpois\", list(lambda = 10)\n    )\nsim\n\n\n\nA tibble: 3 × 2\n\n    fparams\n    <chr><list>\n\n\n    runif-1, 1\n    rnorm5\n    rpois10\n\n\n\n\n\nsim %>%\nmutate(sim = invoke_map(f, params, n = 10))\n\n\n\nA tibble: 3 × 3\n\n    fparamssim\n    <chr><list><list>\n\n\n    runif-1, 10.07894134, -0.86898545, -0.15951936, 0.78716288, -0.83887923, 0.91604573, -0.71653860, -0.20937246, 0.73207933, -0.55086865\n    rnorm54.6303684, 1.4773254, -6.1243872, -0.3974409, -0.3804220, -1.6938584, 4.8958890, 5.0882558, -8.4444484, 7.0620562\n    rpois1016, 13, 14, 13, 13, 7, 11, 6, 7, 10\n\n\n\n\nsome : 일부 요소가 참인지 알려줌. every : 모든 요소가 참인지 알려줌.\n\nx <- list(1:5, letters, list(10))\nx\n\n\n    \n12345\n\n    \n'a''b''c''d''e''f''g''h''i''j''k''l''m''n''o''p''q''r''s''t''u''v''w''x''y''z'\n\n    \n    10\n\n\n\n\n\n\nx %>%\nsome(is.character)\n\nTRUE\n\n\n\nx %>% \nevery(is_vector)\n\nTRUE\n\n\ndetect : 논리서술이 참인 첫 번째 요소를 찾아준다. detect_index : 논리서술이 참인 첫 번째 요소의 해당 위치를 반환하다. head_while : 벡터의 시작에서부터 논리서술자가 참인 요소들을 반환한다. tail_while : 벡터의 끝에서부터 논리서술자가 참인 요소들을 반환한다.\n\nx <- sample(10)\nx\n\n\n91045761283\n\n\n\nx %>%\ndetect(~ . > 5)\n\n9\n\n\n\nx %>%\ndetect_index(~ . > 5) \n\n1\n\n\n\nx %>%\nhead_while(~ . > 5)\n\n\n910\n\n\n\nx %>%\ntail_while(~ . > 5)\n\n\n\n\n\n\n\n\n\n데이터프레임 리스트가 있을 때, 리스트의 요소를 “조인”해서 하나의 데이터프레임으로 만들어준다.\n\n\ndfs <- list(\n    age = tibble(name = \"John\", age = 30),\n    sex = tibble(name = c(\"John\", \"Mary\"), sex = c(\"M\", \"F\")),\n    trt = tibble(name = \"Mary\", treatment = \"A\")\n    )\n\n\ndfs\n\n\n\n    $age\n        \nA tibble: 1 × 2\n\n    nameage\n    <chr><dbl>\n\n\n    John30\n\n\n\n    $sex\n        \nA tibble: 2 × 2\n\n    namesex\n    <chr><chr>\n\n\n    JohnM\n    MaryF\n\n\n\n    $trt\n        \nA tibble: 1 × 2\n\n    nametreatment\n    <chr><chr>\n\n\n    MaryA\n\n\n\n\n\n\n\ndfs %>% reduce(full_join)\n\nJoining, by = \"name\"\nJoining, by = \"name\"\n\n\n\n\nA tibble: 2 × 4\n\n    nameagesextreatment\n    <chr><dbl><chr><chr>\n\n\n    John30MNA\n    MaryNAFA \n\n\n\n\n\n벡터의 리스트가 있을 때, 교집합을 구하는 방법\n\n\nvs <- list(\n    c(1, 3, 5, 6, 10),\n    c(1, 2, 3, 7, 8, 10),\n    c(1, 2, 3, 4, 8, 9, 10)\n    )\nvs\n\n\n    \n135610\n\n    \n1237810\n\n    \n12348910\n\n\n\n\n\nvs %>% reduce(intersect)\n\n\n1310"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-18_tibble.html",
    "href": "posts/datascience-for-r/2022-08-18_tibble.html",
    "title": "tibble, parsing",
    "section": "",
    "text": "tibble(tribble), parsing\n\nlibrary('tidyverse')\n\n- 데이터프레임을 티블로 변형하기\n\nas_tibble(iris) %>% head\n\n\n\nA tibble: 6 × 5\n\n    Sepal.LengthSepal.WidthPetal.LengthPetal.WidthSpecies\n    <dbl><dbl><dbl><dbl><fct>\n\n\n    5.13.51.40.2setosa\n    4.93.01.40.2setosa\n    4.73.21.30.2setosa\n    4.63.11.50.2setosa\n    5.03.61.40.2setosa\n    5.43.91.70.4setosa\n\n\n\n\n\ntibble(\n    x = 1:5,\n    y = 1,\n    z = x^2 + y\n    )\n\n\n\nA tibble: 5 × 3\n\n    xyz\n    <int><dbl><dbl>\n\n\n    11 2\n    21 5\n    3110\n    4117\n    5126\n\n\n\n\n\ntibble과 데이터프레임의 차이점 1) 입력 유형을 절대로 변경하지 않는다 ex) 문자열 > factor 2) 변수의 이름을 바꾸거나 행 이름을 생성하지 않는다 3) 티블은 R변수명으로 유효하지 않은 이름도 열 이름으로 가질 수 있다 ex) 공백다만, 이런 변수들을 참조하려면 역따옴표(`)로 감싸야한다고 하는데 안써도 되는데?\n\n\ntb <- tibble(\n    `apple` = \"근본\",\n    ' ' = \"스페이스\",\n    '1000' = \"숫자\")\n\n\ntb\n\n\n\nA tibble: 1 × 3\n\n    apple 1000\n    <chr><chr><chr>\n\n\n    근본스페이스숫자\n\n\n\n\n\n\n\n티블을 만드는 또 다른 방법(적은 양의 데이터를 빠르게 읽기 쉬운형태로 만드는) 열 헤더는 공식으로 정의(~로 시작), 입력은 쉼표로 구분)\n\n\ntribble(\n    ~x, ~y, ~z,\n    \"c\" ,  3, 4.0,\n    \"a\", 2, 3.6,\n    \"b\", 1, 8.5\n    )\n\n\n\nA tibble: 3 × 3\n\n    xyz\n    <chr><dbl><dbl>\n\n\n    c34.0\n    a23.6\n    b18.5\n\n\n\n\n\ntibble(\n    a = lubridate::now() + runif(1e3) * 86400,\n    b = lubridate::today() + runif(1e3) * 30,\n    c = 1:1e3,\n    d = runif(1e3),\n    e = sample(letters, 1e3, replace = TRUE)\n    ) %>% head\n\n\n\nA tibble: 6 × 5\n\n    abcde\n    <dttm><date><int><dbl><chr>\n\n\n    2022-11-19 17:08:052022-12-1610.94539166z\n    2022-11-19 03:54:572022-11-2420.71200584o\n    2022-11-19 20:30:162022-12-1630.04094422y\n    2022-11-19 07:42:122022-11-2740.54030697e\n    2022-11-19 02:46:382022-12-1450.38184878j\n    2022-11-19 09:17:172022-12-0160.83675883a\n\n\n\n\n\n참고) 1e3 = 1000이다\n\nrunif : 평균=0, 표준편차=1의 무작위 난수 추출\nprint(n=) : 보여주는 행의수 제어 width = Inf : 열 모두 보이기\n\nnycflights13::flights %>%\nprint(n = 10, width = Inf)\n\n# A tibble: 336,776 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n   arr_delay carrier flight tailnum origin dest  air_time distance  hour minute\n       <dbl> <chr>    <int> <chr>   <chr>  <chr>    <dbl>    <dbl> <dbl>  <dbl>\n 1        11 UA        1545 N14228  EWR    IAH        227     1400     5     15\n 2        20 UA        1714 N24211  LGA    IAH        227     1416     5     29\n 3        33 AA        1141 N619AA  JFK    MIA        160     1089     5     40\n 4       -18 B6         725 N804JB  JFK    BQN        183     1576     5     45\n 5       -25 DL         461 N668DN  LGA    ATL        116      762     6      0\n 6        12 UA        1696 N39463  EWR    ORD        150      719     5     58\n 7        19 B6         507 N516JB  EWR    FLL        158     1065     6      0\n 8       -14 EV        5708 N829AS  LGA    IAD         53      229     6      0\n 9        -8 B6          79 N593JB  JFK    MCO        140      944     6      0\n10         8 AA         301 N3ALAA  LGA    ORD        138      733     6      0\n   time_hour          \n   <dttm>             \n 1 2013-01-01 05:00:00\n 2 2013-01-01 05:00:00\n 3 2013-01-01 05:00:00\n 4 2013-01-01 05:00:00\n 5 2013-01-01 06:00:00\n 6 2013-01-01 05:00:00\n 7 2013-01-01 06:00:00\n 8 2013-01-01 06:00:00\n 9 2013-01-01 06:00:00\n10 2013-01-01 06:00:00\n# … with 336,766 more rows\n\n\n\n\n\n\ndf <- tibble(\n    x = runif(5),\n    y = rnorm(5)\n    )\ndf\n\n\n\nA tibble: 5 × 2\n\n    xy\n    <dbl><dbl>\n\n\n    0.8825180-0.48401982\n    0.3718944 0.49982998\n    0.5794829-1.31736327\n    0.2130048-0.03729576\n    0.4266255-0.72504338\n\n\n\n\n\ndf$x\n\n\n0.8825179932173340.3718944157008080.5794829186052080.2130048032850030.426625467604026\n\n\n\ndf[[\"x\"]]\n\n\n0.8825179932173340.3718944157008080.5794829186052080.2130048032850030.426625467604026\n\n\n\ndf[[1]]\n\n\n0.8825179932173340.3718944157008080.5794829186052080.2130048032850030.426625467604026\n\n\n- pipe에서의 서브셋 . 찍어줘야한다\n\ndf %>% .$x\n\n\n0.8825179932173340.3718944157008080.5794829186052080.2130048032850030.426625467604026\n\n\n\ndf %>% .[[\"x\"]]\n\n\n0.8825179932173340.3718944157008080.5794829186052080.2130048032850030.426625467604026\n\n\n- 일부 오래된 함수의 경우 tibble에서 동작하지 않기에 이 경우 dataframe으로 변환후 사용한다\n\nclass(as.data.frame(tb))\n\n'data.frame'\n\n\n\n\n\n\noption만 넣음\n\nskip = n : 첫 n줄 건너 뛰기 comment = # : #으로 시작하는 모든 줄 무시 col_names = FALSE : 첫 행을 헤드로 취급하지 않고 x1 ~ xn으로 이름 붙임(데이터에 열 이름 없을 때 사용)\n\n\n\n\n(뜻)parse -> 분석하다\n\nparse_무언가() : 문자형 벡터를 입력으로 하여 논리형, 정수형 또는 날짜형과 같은 좀 더 특수화된 벡터를 반환\n- parsing 실패 > 실패하면 경고문과 함께 NA로 표기 > 이 경우 problems()사용하면 문제점 알려줌\n\nx <- parse_integer(c(\"123\",\"345\",\"abc\",\"123.45\"))\n\nWarning message:\n“2 parsing failures.\nrow col               expected actual\n  3  -- no trailing characters abc   \n  4  -- no trailing characters 123.45\n”\n\n\n\nx\n\n\n123345<NA><NA>\n\n\n\nproblems(x)\n\n\n\nA tibble: 2 × 4\n\n    rowcolexpectedactual\n    <int><int><chr><chr>\n\n\n    3NAno trailing charactersabc   \n    4NAno trailing characters123.45\n\n\n\n\nparse 종류 >parse_logical : 논리형 parse_integer : 정수형 parse_double : 엄격한 수치형(★★★) parse_number : 유연한 수치형(★★) -> 각자 다른 방식의 숫자 표현을 써버리기에 parse_character : 문자형 -> 단순하지만 문자 인코딩에서 중요 parse_factor : 팩터형(R이 미리 정해지고 알려진 값으로 범주형 변수를 나타내기 위해 사용하는 데이터 구조) parse_datetime : 날짜/시각(★★★★) -> 날짜를 쓰는 방법은 다양하기에 이들이 제일 복잡 parse_date : 날짜/시각(★★★★) parse_time : 날짜/시각(★★★★)\n\n\n\n숫자 파싱이 문제가 되는 3가지 1) 소수점 구별기호 ex) . or , 2) 단위 ex) $ % 3) 간혹 읽기 편하라고 ’ ’ 사용\n\n- 첫 번째 문제 해결 지역에 따라 파싱 옵션을 지정하는 객체인 locale사용 변경이 필요할 경우 새로운 locale을 생성하고 decimal_mark인수를 설정하여 기본값인 .을 다른 값으로 재정의\n\nparse_double(\"1.23\")\n\n1.23\n\n\n- 변경 예시\n\nparse_double(\"1,23\", locale = locale(decimal_mark = \",\"))\n\n1.23\n\n\n-두 번째 문제 해결 parse_number는 숫자 앞뒤의 비수치 문자(non-numeric character)를 모두 무시 통화 및 백분율에 특히 유용하고 텍스트에 포함된 숫자를 추출하는 데도 효과적\n\nparse_number(\"$100\")\n\n100\n\n\n\nparse_number(\"20%\")\n\n20\n\n\n- 비수치 문자 무시 예\n\nparse_number(\"It cost $123.45\")\n\n123.45\n\n\n- 미국식 처리법\n\nparse_number(\"$123,456,789\")\n\n123456789\n\n\n- 유럽식 처리법\n\nparse_number(\n    \"123.456.789\",\n    locale = locale(grouping_mark = \".\"))\n\n123456789\n\n\n- factor형 처리 R은 팩터형을 사용하기에, 가질 수 있는 값을 미리 알고 있는 범주형 변수를 나타낸다\n\nfruit <- c(\"apple\", \"banana\")\nparse_factor(c(\"apple\", \"banana\", \"bananana\"), levels = fruit)\n\nWarning message:\n“1 parsing failure.\nrow col           expected   actual\n  3  -- value in level set bananana\n”\n\n\n\napplebanana<NA>\n\n\n    \n        Levels:\n    \n    \n    'apple''banana'\n\n\n\n\n\n\n\nparse_datetime(\"2010-10-01T2010\")\n\n[1] \"2010-10-01 20:10:00 UTC\"\n\n\n\nparse_datetime(\"20101010\")\n\n[1] \"2010-10-10 UTC\"\n\n\n\nparse_date(\"2010-10-01\")\n\n2010-10-01\n\n\n\nlibrary('hms')# 시간 데이터 다루는 패키지\n\n\nparse_time(\"20:10:01\")\n\n20:10:01\n\n\n\nparse_time(\"01:10 am\")\n\n01:10:00\n\n\n\n위의 예시들로 주어진 데이터를 처리하지 못한다면 나만의 format을 만들어 사용가능  연 %Y(4 자리) %y(2 자리, 00-69 -> 2000-2069, 70-99 -> 1970-1999)  월 %m(2 자리) %b(“jan”과 같이 축약된 명칭) %B(전체 명칭, “January”)  일 %d(2 자리) %e(선택적 선행 공백)  시간 %H(0-23 시간 형식) %I(0-12, %p와 함께 사용해야 함) %p(a.m/p.m표시) %M(분) %S(정수 초) %OS(실수 초)  숫자가 아닌 문자 %.(숫자가 아닌 문자 하나를 건너뛴다) %*(숫자가 아닌 문자 모두를 건너뛴다)\n\n- 시간 데이터 처리 예시\n\nparse_date(\"01/02/15\", \"%m/%d/%y\")\n\n2015-01-02\n\n\n\nparse_date(\"01/02/15\", \"%d/%m/%y\")\n\n2015-02-01\n\n\n\nparse_date(\"01/02/15\", \"%y/%m/%d\")\n\n2001-02-15"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-19_tidydata.html",
    "href": "posts/datascience-for-r/2022-08-19_tidydata.html",
    "title": "tidy data",
    "section": "",
    "text": "pivot_longer, separate, unite, 결측값\n\nlibrary('tidyverse')\n\n\n\n\n어떤 항목은 행으로 어떤 항목은 열로 보고자 다룰 때 사용\n\n- table4a 예제\n\ntable4a\n\n\n\nA tibble: 3 × 3\n\n    country19992000\n    <chr><int><int>\n\n\n    1Afghanistan   745  2666\n    2Brazil      37737 80488\n    3China      212258213766\n\n\n\n\npivot_longer : 행을 항목으로 추가\n\ntable4a %>%\npivot_longer(c('1999', '2000'), names_to = \"year\", values_to = \"cases\")\n\n\n\nA tibble: 6 × 3\n\n    countryyearcases\n    <chr><chr><int>\n\n\n    Afghanistan1999   745\n    Afghanistan2000  2666\n    Brazil     1999 37737\n    Brazil     2000 80488\n    China      1999212258\n    China      2000213766\n\n\n\n\n\ntable4a %>%\npivot_longer(c('1999','2000'), names_to = 'year', values_to = 'population')\n\n\n\nA tibble: 6 × 3\n\n    countryyearpopulation\n    <chr><chr><int>\n\n\n    Afghanistan1999   745\n    Afghanistan2000  2666\n    Brazil     1999 37737\n    Brazil     2000 80488\n    China      1999212258\n    China      2000213766\n\n\n\n\n- 위의 두개 합쳐서 보기(merge랑 비슷한 기능인듯)\n\ntidy4a <- table4a %>%\npivot_longer(c('1999', '2000'), names_to = 'year', values_to = 'cases')\ntidy4b <- table4b %>%\npivot_longer(c('1999', '2000'), names_to = 'year', values_to = 'population')\nleft_join(tidy4a, tidy4b)\n\nJoining, by = c(\"country\", \"year\")\n\n\n\n\nA tibble: 6 × 4\n\n    countryyearcasespopulation\n    <chr><chr><int><int>\n\n\n    Afghanistan1999   745  19987071\n    Afghanistan2000  2666  20595360\n    Brazil     1999 37737 172006362\n    Brazil     2000 80488 174504898\n    China      19992122581272915272\n    China      20002137661280428583\n\n\n\n\n- table2 예제\n\ntable2\n\n\n\nA tibble: 12 × 4\n\n    countryyeartypecount\n    <chr><int><chr><int>\n\n\n    Afghanistan1999cases            745\n    Afghanistan1999population  19987071\n    Afghanistan2000cases           2666\n    Afghanistan2000population  20595360\n    Brazil     1999cases          37737\n    Brazil     1999population 172006362\n    Brazil     2000cases          80488\n    Brazil     2000population 174504898\n    China      1999cases         212258\n    China      1999population1272915272\n    China      2000cases         213766\n    China      2000population1280428583\n\n\n\n\npivot_wider : pivot_longer랑 반대로 항목을 행으로 보내기\n\ntable2 %>%\npivot_wider(names_from = type, values_from = count)\n\n\n\nA tibble: 6 × 4\n\n    countryyearcasespopulation\n    <chr><int><int><int>\n\n\n    Afghanistan1999   745  19987071\n    Afghanistan2000  2666  20595360\n    Brazil     1999 37737 172006362\n    Brazil     2000 80488 174504898\n    China      19992122581272915272\n    China      20002137661280428583\n\n\n\n\n\n결과적으로 pivot_longer은 넒은 테이블을 더 좁고 길게 만들고 pivot_wider는 긴 테이블을 더 짧고 넓게 만든다.\n\n- table3 예제\n\ntable3\n\n\n\nA tibble: 6 × 3\n\n    countryyearrate\n    <chr><int><chr>\n\n\n    1Afghanistan1999745/19987071     \n    2Afghanistan20002666/20595360    \n    3Brazil     199937737/172006362  \n    4Brazil     200080488/174504898  \n    5China      1999212258/1272915272\n    6China      2000213766/1280428583\n\n\n\n\n\n\n\nseparate : 구분 문자가 나타나는 곳마다 쪼개서 하나의 열을 여러 열로 분리 기본적으로 separate는 숫자나 글자가 아닌 문자를 볼 때마다 값을 쪼갠다. 열을 구분하는 특정 문자를 코드에 나타내려면 sep을 사용한다.\n\ntable3 %>%\nseparate(rate, into = c(\"cases\", \"population\"))\n\n\n\nA tibble: 6 × 4\n\n    countryyearcasespopulation\n    <chr><int><chr><chr>\n\n\n    Afghanistan1999745   19987071  \n    Afghanistan20002666  20595360  \n    Brazil     199937737 172006362 \n    Brazil     200080488 174504898 \n    China      19992122581272915272\n    China      20002137661280428583\n\n\n\n\n\ntable3 %>%\nseparate(rate, into = c(\"cases\", \"population\"), sep = \"/\")\n\n\n\nA tibble: 6 × 4\n\n    countryyearcasespopulation\n    <chr><int><chr><chr>\n\n\n    Afghanistan1999745   19987071  \n    Afghanistan20002666  20595360  \n    Brazil     199937737 172006362 \n    Brazil     200080488 174504898 \n    China      19992122581272915272\n    China      20002137661280428583\n\n\n\n\n\n근데 cases, population 문자형 보면 알 수 있듯이 결과가 character로 나온다 이 때 convert 사용하면 적합한 열의 유형을 변형해준다.\n\n\ntable3 %>%\nseparate(\n    rate,\n    into = c(\"cases\", \"population\"),\n    convert = TRUE\n    )\n\n\n\nA tibble: 6 × 4\n\n    countryyearcasespopulation\n    <chr><int><int><int>\n\n\n    Afghanistan1999   745  19987071\n    Afghanistan2000  2666  20595360\n    Brazil     1999 37737 172006362\n    Brazil     2000 80488 174504898\n    China      19992122581272915272\n    China      20002137661280428583\n\n\n\n\n\nsep에 숫자 입력하면 앞에서부터 그 개수만큼 잘라서 분리한다.(음수는 뒤에서부터 자름)\n\n\ntable3 %>%\nseparate(year, into = c(\"century\", \"year\"), sep = 2)\n\n\n\nA tibble: 6 × 4\n\n    countrycenturyyearrate\n    <chr><chr><chr><chr>\n\n\n    Afghanistan1999745/19987071     \n    Afghanistan20002666/20595360    \n    Brazil     199937737/172006362  \n    Brazil     200080488/174504898  \n    China      1999212258/1272915272\n    China      2000213766/1280428583\n\n\n\n\n- table5 예제\n\ntable5\n\n\n\nA tibble: 6 × 4\n\n    countrycenturyyearrate\n    <chr><chr><chr><chr>\n\n\n    1Afghanistan1999745/19987071     \n    2Afghanistan20002666/20595360    \n    3Brazil     199937737/172006362  \n    4Brazil     200080488/174504898  \n    5China      1999212258/1272915272\n    6China      2000213766/1280428583\n\n\n\n\n\n\n\nunite : separate과 반대로 여러 열을 하나의 열로 결합한다\n\ntable5 %>%\nunite(new, century, year)\n\n\n\nA tibble: 6 × 3\n\n    countrynewrate\n    <chr><chr><chr>\n\n\n    Afghanistan19_99745/19987071     \n    Afghanistan20_002666/20595360    \n    Brazil     19_9937737/172006362  \n    Brazil     20_0080488/174504898  \n    China      19_99212258/1272915272\n    China      20_00213766/1280428583\n\n\n\n\n\nsep 사용해서 분리기호 변경( _ -> 공백)\n\n\ntable5 %>%\nunite(new, century, year, sep = \"\")\n\n\n\nA tibble: 6 × 3\n\n    countrynewrate\n    <chr><chr><chr>\n\n\n    Afghanistan1999745/19987071     \n    Afghanistan20002666/20595360    \n    Brazil     199937737/172006362  \n    Brazil     200080488/174504898  \n    China      1999212258/1272915272\n    China      2000213766/1280428583\n\n\n\n\n\n\n\n\n\n데이터값은 두 가지 방식으로 결측될 수 있다.\n\n\n명시적으로, 즉 NA로 표시된다.\n암묵적으로, 즉 단순히 데이터에 존재하지 않는다.(이런거 단순히 0으로 놓고가면 문제 생김)\n\n\n- 예시 만들기\n\nstocks <- tibble(\n    year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016),\n    qtr = c(1, 2, 3, 4, 2, 3, 4),\n    return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66)\n    )\n\n\nstocks\n\n\n\nA tibble: 7 × 3\n\n    yearqtrreturn\n    <dbl><dbl><dbl>\n\n\n    201511.88\n    201520.59\n    201530.35\n    20154  NA\n    201620.92\n    201630.17\n    201642.66\n\n\n\n\n\nNA뿐만 아니라 2016년 1분기도 결측값임 아래는 데이터 셋 표현법으로 암묵적 결측값을 명시적 결측값(NA)로 나타내준 모습\n\n\nstocks %>%\npivot_wider(names_from = year, values_from = return)\n\n\n\nA tibble: 4 × 3\n\n    qtr20152016\n    <dbl><dbl><dbl>\n\n\n    11.88  NA\n    20.590.92\n    30.350.17\n    4  NA2.66\n\n\n\n\nvalues_drop_na = TRUE : pivot_longer에서 명시적 결측값을 암묵적 결측값으로 전환(위에서는 표시해줬는데 오히려 필요가 없는 경우는 이렇게)\n\nstocks %>%\npivot_wider(names_from = year, values_from = return) %>%\npivot_longer(\n    col = c('2015', '2016'),\n    names_to = \"year\",\n    values_to = \"return\",\n    values_drop_na = TRUE\n    )\n\n\n\nA tibble: 6 × 3\n\n    qtryearreturn\n    <dbl><chr><dbl>\n\n\n    120151.88\n    220150.59\n    220160.92\n    320150.35\n    320160.17\n    420162.66\n\n\n\n\ncomplete : 열 집합을 입력으로 하여 거기에 맞는 조합행을 쭉 나열, 이때 비어 있는 데이터의 경우 NA로 표시\n\nstocks %>%\ncomplete(year, qtr)\n\n\n\nA tibble: 8 × 3\n\n    yearqtrreturn\n    <dbl><dbl><dbl>\n\n\n    201511.88\n    201520.59\n    201530.35\n    20154  NA\n    20161  NA\n    201620.92\n    201630.17\n    201642.66\n\n\n\n\n\ntreatment <- tribble(\n    ~person,           ~treatment, ~response,\n    \"Derrick Whitmore\",1,          7,\n    NA,                2,          10,\n    NA,                3,          9,\n    \"Katherine Burke\", 1,          4\n    )\n\n\ntreatment\n\n\n\nA tibble: 4 × 3\n\n    persontreatmentresponse\n    <chr><dbl><dbl>\n\n\n    Derrick Whitmore1 7\n    NA              210\n    NA              3 9\n    Katherine Burke 1 4\n\n\n\n\nfill : 결측값을 가장 최근의 비결측값으로 채움\n\ntreatment %>%\nfill(person)\n\n\n\nA tibble: 4 × 3\n\n    persontreatmentresponse\n    <chr><dbl><dbl>\n\n\n    Derrick Whitmore1 7\n    Derrick Whitmore210\n    Derrick Whitmore3 9\n    Katherine Burke 1 4\n\n\n\n\n\n\n\n- who데이터 사용\n\nwho %>% head\n\n\n\nA tibble: 6 × 60\n\n    countryiso2iso3yearnew_sp_m014new_sp_m1524new_sp_m2534new_sp_m3544new_sp_m4554new_sp_m5564⋯newrel_m4554newrel_m5564newrel_m65newrel_f014newrel_f1524newrel_f2534newrel_f3544newrel_f4554newrel_f5564newrel_f65\n    <chr><chr><chr><int><int><int><int><int><int><int>⋯<int><int><int><int><int><int><int><int><int><int>\n\n\n    AfghanistanAFAFG1980NANANANANANA⋯NANANANANANANANANANA\n    AfghanistanAFAFG1981NANANANANANA⋯NANANANANANANANANANA\n    AfghanistanAFAFG1982NANANANANANA⋯NANANANANANANANANANA\n    AfghanistanAFAFG1983NANANANANANA⋯NANANANANANANANANANA\n    AfghanistanAFAFG1984NANANANANANA⋯NANANANANANANANANANA\n    AfghanistanAFAFG1985NANANANANANA⋯NANANANANANANANANANA\n\n\n\n\n\n데이터셋이 굉장히 복잡하다 보통 이럴 때에는 변수가 아닌 열을 모으는 것부터 시작하는 것이 좋다. country, iso2, iso3는 국가를 중복해서 지정하는 세개의 변수이다. year 또 분명히 변수이다. 다른 모든 열은 아직 무엇인지 알 수 없지만 변수 이름(new_sp_m014등등)의 구조를 보면 이들은 변수가 아니라 값인 것 같다. 그래서 new_sp_m014들은 값으로 취급하여 묶어서 행으로 보내고 확실한 변수들을 열에 둔다.\n\n\nwho1 <- who %>%\npivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = \"key\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n    )\nwho1 %>% head\n\n\n\nA tibble: 6 × 6\n\n    countryiso2iso3yearkeycases\n    <chr><chr><chr><int><chr><int>\n\n\n    AfghanistanAFAFG1997new_sp_m014  0\n    AfghanistanAFAFG1997new_sp_m152410\n    AfghanistanAFAFG1997new_sp_m2534 6\n    AfghanistanAFAFG1997new_sp_m3544 3\n    AfghanistanAFAFG1997new_sp_m4554 5\n    AfghanistanAFAFG1997new_sp_m5564 2\n\n\n\n\n- 새로운 key열의 값을 세어서 구조에 대한 힌트를 얻을 수 있다\n\nwho1 %>%\ncount(key) \n\n\n\nA tibble: 56 × 2\n\n    keyn\n    <chr><int>\n\n\n    new_ep_f014 1032\n    new_ep_f15241021\n    new_ep_f25341021\n    new_ep_f35441021\n    new_ep_f45541017\n    new_ep_f55641017\n    new_ep_f65  1014\n    new_ep_m014 1038\n    new_ep_m15241026\n    new_ep_m25341020\n    new_ep_m35441024\n    new_ep_m45541020\n    new_ep_m55641015\n    new_ep_m65  1018\n    new_sn_f014 1040\n    new_sn_f15241022\n    new_sn_f25341016\n    new_sn_f35441020\n    new_sn_f45541018\n    new_sn_f55641017\n    new_sn_f65  1019\n    new_sn_m014 1045\n    new_sn_m15241030\n    new_sn_m25341022\n    new_sn_m35441025\n    new_sn_m45541027\n    new_sn_m55641021\n    new_sn_m65  1020\n    new_sp_f014 3174\n    new_sp_f15243194\n    new_sp_f25343200\n    new_sp_f35443199\n    new_sp_f45543204\n    new_sp_f55643195\n    new_sp_f65  3197\n    new_sp_m014 3173\n    new_sp_m15243209\n    new_sp_m25343206\n    new_sp_m35443219\n    new_sp_m45543223\n    new_sp_m55643218\n    new_sp_m65  3209\n    newrel_f014  190\n    newrel_f1524 184\n    newrel_f2534 182\n    newrel_f3544 183\n    newrel_f4554 183\n    newrel_f5564 183\n    newrel_f65   185\n    newrel_m014  190\n    newrel_m1524 182\n    newrel_m2534 183\n    newrel_m3544 184\n    newrel_m4554 184\n    newrel_m5564 185\n    newrel_m65   182\n\n\n\n\n아래는 데이터 사전(?)을 사용하면 알려준다는데..?\n\nrel은 재발 사례를 의미 ep는 폐외 결핵 사례를 의미 sn은 폐 얼룩으로 보이지 않는 폐결핵의 사례를 의미 sp는 폐 얼룩으로 보이는 폐결핵 사례를 의미  여섯 번째는 성별 나머지 숫자는 연령대를 나타낸다. 014 -> 0~14세 . . . 65 -> 65세 이상\n\n따라서 열 이름의 형식을 수정해야 한다 new_rel이 아니라 newrel 이런식이기에 str_replace는 차후에 자세히 설명함\n\nwho2 <- who1 %>%\nmutate(key = stringr::str_replace(key, \"newrel\", \"new_rel\"))\nwho2 %>% head\n\n\n\nA tibble: 6 × 6\n\n    countryiso2iso3yearkeycases\n    <chr><chr><chr><int><chr><int>\n\n\n    AfghanistanAFAFG1997new_sp_m014  0\n    AfghanistanAFAFG1997new_sp_m152410\n    AfghanistanAFAFG1997new_sp_m2534 6\n    AfghanistanAFAFG1997new_sp_m3544 3\n    AfghanistanAFAFG1997new_sp_m4554 5\n    AfghanistanAFAFG1997new_sp_m5564 2\n\n\n\n\n\n위에서 이름 사이에 _를 넣었던 것은 분리하기 위함이였다.\n\n\nwho3 <- who2 %>%\nseparate(key, c(\"new\", \"type\", \"sexage\"), sep = \"_\")\nwho3 %>% head\n\n\n\nA tibble: 6 × 8\n\n    countryiso2iso3yearnewtypesexagecases\n    <chr><chr><chr><int><chr><chr><chr><int>\n\n\n    AfghanistanAFAFG1997newspm014  0\n    AfghanistanAFAFG1997newspm152410\n    AfghanistanAFAFG1997newspm2534 6\n    AfghanistanAFAFG1997newspm3544 3\n    AfghanistanAFAFG1997newspm4554 5\n    AfghanistanAFAFG1997newspm5564 2\n\n\n\n\n\nnew열은 상수이므로 제거한다, iso2, iso3도 중복이므로 제거한다.\n\nselect : -로 하면 그거 빼고 출력해준다\n\nwho4 <- who3 %>%\nselect(-new, -iso2, -iso3)\n\n\nwho4 %>% head\n\n\n\nA tibble: 6 × 5\n\n    countryyeartypesexagecases\n    <chr><int><chr><chr><int>\n\n\n    Afghanistan1997spm014  0\n    Afghanistan1997spm152410\n    Afghanistan1997spm2534 6\n    Afghanistan1997spm3544 3\n    Afghanistan1997spm4554 5\n    Afghanistan1997spm5564 2\n\n\n\n\n\nwho5 <- who4 %>%\nseparate(sexage, c(\"sex\", \"age\"), sep = 1)\n\n\nwho5 %>% head\n\n\n\nA tibble: 6 × 6\n\n    countryyeartypesexagecases\n    <chr><int><chr><chr><chr><int>\n\n\n    Afghanistan1997spm014  0\n    Afghanistan1997spm152410\n    Afghanistan1997spm2534 6\n    Afghanistan1997spm3544 3\n    Afghanistan1997spm4554 5\n    Afghanistan1997spm5564 2\n\n\n\n\n이 정도면 who데이터셋은 최대한 tidy하게 만듦.\n- 위에서 차례로 해온 것과 같은 방식인데 한번에 정리하기\n\nwho %>%\npivot_longer(\n    cols = new_sp_m014:newrel_f65,\n    names_to = \"key\",\n    values_to = \"cases\",\n    values_drop_na = TRUE\n\n    ) %>%\nmutate(\n    key = stringr::str_replace(key, \"newrel\",\"new_rel\")\n    ) %>%\nseparate(key, c(\"new\", \"var\", \"sexage\")) %>%\nselect(-new, -iso2, -iso3) %>%\nseparate(sexage, c(\"sex\", \"age\"), sep = 1) %>% head\n\n\n\nA tibble: 6 × 6\n\n    countryyearvarsexagecases\n    <chr><int><chr><chr><chr><int>\n\n\n    Afghanistan1997spm014  0\n    Afghanistan1997spm152410\n    Afghanistan1997spm2534 6\n    Afghanistan1997spm3544 3\n    Afghanistan1997spm4554 5\n    Afghanistan1997spm5564 2"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-21_string.html",
    "href": "posts/datascience-for-r/2022-08-21_string.html",
    "title": "string",
    "section": "",
    "text": "string_length, str_c, sep …, 문자열 서브셋(추출), 매칭(검색 및 설정)\n\nlibrary('tidyverse')\n\n\n\nstr_length : 문자열의 문자 개수 알려준다. 공백도 개수로 침\n\nstr_length(c(\"a\", \"R for data science\", NA))\n\n\n118<NA>\n\n\nstr_c : 둘 이상의 문자열 결합할 때 사용\n\nstr_c(\"x\", \"y\")\n\n'xy'\n\n\nsep : 구분 방식 조정하는 옵션\n\nstr_c(\"x\", \"y\", sep = \", \")\n\n'x, y'\n\n\n\nx <- c(\"abc\", NA)\nstr_c(\"|-\", x, \"-|\")\n\n\n'|-abc-|'NA\n\n\nstr_replace_na : 결측값을 NA로 출력하게 하기\n\nstr_c(\"|-\", str_replace_na(x), \"-|\")\n\n\n'|-abc-|''|-NA-|'\n\n\n\nstr_c는 벡터화되고 짧은 벡터가 긴 벡터와 길이가 같도록 자동으로 재사용한다.\n\n\nstr_c(\"prefix-\", c(\"a\", \"b\", \"c\"), \"-suffix\")\n\n\n'prefix-a-suffix''prefix-b-suffix''prefix-c-suffix'\n\n\ncollapse : 문자열 벡터를 하나의 문자열로 합쳐준다.\n\nstr_c(c(\"x\", \"y\", \"z\"), collapse = \", \")\n\n'x, y, z'\n\n\n\n\n\nstr_sub : 문자열을 추출한다 옵션 : 앞에서부터 추출할 문자, 추출 시작 위치, 추출 끝 위치 -붙이면 뒤에서부터 추출\n\nx <- c(\"Apple\", \"Banana\", \"Pear\")\nstr_sub(x, 2, 3)\n\n\n'pp''an''ea'\n\n\n\nstr_sub(x, -3, -2)\n\n\n'pl''an''ea'\n\n\n- 너무 짧아도 오류 안뜨고 가능한 만큼 처리해줌\n\nstr_sub(\"a\", 1, 5)\n\n'a'\n\n\nstr_to_uppper : 대문자로 변경\n\nstr_to_upper(c(\"i\", \"I\"))\n\n\n'I''I'\n\n\n\n\n\n\nx <- c(\"apple\", \"banana\", \"pear\")\n\n\nstr_view(x, \"an\")\n\nERROR: Error: htmlwidgets package required for str_view(). \nPlease install.packages(\"htmlwidgets\") to use this functionality.\n\n\n\n임의의 문자와 매칭하는 .\n\n\nstr_view(x, \".a.\")\n\nERROR: Error: htmlwidgets package required for str_view(). \nPlease install.packages(\"htmlwidgets\") to use this functionality.\n\n\n만약, .자체를 찾고 싶은거면 .대신 \\\\.으로 입력\n또, 만약에 \\자체를 찾고자하면 \\\\\\\\로 입력(4개)\n^ : 문자열의 시작부분 매칭 $ : 문자열의 끝부분 매칭\n\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_view(x, \"^a\")\n\n\nstr_view(x, \"a$\")\n\n딱 저 문자 자체만 찾고자 한다면 ^문자$사용\n\nx <- c(\"apple pie\", \"apple\", \"apple cake\")\nstr_view(x, \"apple\")\n\n\nstr_view(x, \"^apple$\")\n\n\n문자열 매칭 옵션(예를 들어 a나 b까지 허용) \\d : 임의의 숫자와 매치 \\s : 임의의 여백 문자(공백, 탭, 줄바꿈)와 매치 [abc] : a,b 또는 c와 매치 [^abc] : a,b 또는 c를 제외한 임의의 문자와 매치 | : a or b(둘 다 인정) 명확성을 위해 괄호() 사용 가능하다.\n\n\nstr_view(c(\"grey\", \"gray\"), \"gr(e|a)y\")\n\n\n\n\n다음은 패턴이 몇 회 이상 매칭하는지 조정하는 것이다.\n\n\n? : 0 or 1회 + : 1회 이상 * : 0회 이상\n\n\nx <- \"1888 is the longest year in Roman numerals: MNCCCLXXXVIII\"\n\n\nstr_view(x, \"CC?\")\n\n\nstr_view(x, \"CC+\")\n\n\nstr_view(x, 'c[LX]+')\n\n\n{n} : 정확히 n회 {n,} : n회 이상 {,m} : 최대 m회 {n,m} : n과 m회 사이\n\n\nstr_view(x, \"C{2}\")\n\n\nstr_view(x, \"C{2,}\")\n\n\nstr_view(x, \"C{2,3}\")\n\n\n뒤에 ?넣으면 가능한 조합 중 가장 짧은 문자열과 매칭\n\n\nstr_view(x, 'C{2,3}?')\n\n\nstr_view(x, 'C[LX]+?')\n\n\nstr_view(fruit, \"(..)\\\\1\", match = TRUE)\n\n\n\n\nstr_detect : 문자열 벡터 탐지\n\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_detect(x, \"e\")\n\n- t로 시작하는 단어의 개수?\n\nsum(str_detect(words, \"^t\"))\n\n- 모음으로 끝나는 단어의 비율?\n\nmean(str_detect(words, \"[aeiou]$\"))\n\n\n복잡한 구조에서는 역을 조건으로 설정하고 그 반대를 구하는 게 쉬울수도 있음\n\n- 모음이 최소 하나가 있는 단어 모두를 찾은 뒤, 그 역을 취함\n\nno_vowels_1 <- !str_detect(words, \"[aeiou]\")\n\n- 자음으로만 이루어진 단어를 모두 찾음\n\nno_vowels_2 <- str_detect(words, \"^[^aeiou]+$\")\n\nidentical : 두 개가 정확히 같은지 알려줌\n\nidentical(no_vowels_1, no_vowels_2)\n\n\n결과적으로 같지만 첫 번째 방법이 훨씬 쉽기에 저러한 방식을 사용\n\n- str_detect결과가 TRUE, FALSE로 나오기에 추출을 위해 이런식으로 사용\n\nwords[str_detect(words, \"x$\")]\n\nstr_subset : 해당하는 내용 추출\n\nstr_subset(words, \"x$\")\n\n\nseq : 시퀀스를 만들어주는 함수(번호 붙여줌 1,2,3 …. 이런식) seq_along : 시작을 1로 만들어주는데 사실상 비슷함\n\n\n하지만, 일반적으로 작업하는 것은 data.frame이기에 보통 filter를 사용함\n\n\ndf <- tibble(\n    word = words,\n    i = seq_along(word)\n    )\ndf %>%\nfilter(str_detect(words, \"x$\"))\n\nstr_count : 하나의 문자열에 몇 번 매칭되는지 수를 알려준다.\n\nx <- c(\"apple\", \"banana\", \"pear\")\nstr_count(x, \"a\")\n\n- 단어당 모음 평균 개수?\n\nmean(str_count(words, \"[aeiou]\"))\n\n\ndf %>%\nmutate(\n    vowels = str_count(word, \"[aeoiu]\"),\n    consonants = str_count(word, \"[^aeoiu]\")\n    ) %>% head\n\n참고로 consonant뜻은 자음이다\n\nstr_count(\"abababa\", \"aba\")\n\n_all : 모든 매칭에 동작하는 접미사 함수\n\nstr_view_all(\"abababa\", \"aba\")\n\n\nlength(sentences) # sentences는 패키지안에 있는 자료임\n\n\nsentences %>% head\n\n- 색상을 포함하는 문장을 선택하고 싶다. 그리고 매칭된 색상이 무엇인지도 알고 싶다\n\ncolor <- c(\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"purple\")\ncolor_match <- str_c(color, collapse = \"|\")\ncolor_match\n\n\nhas_color <- str_subset(sentences, color_match)\nhas_color %>% head\n\n\nmatches <- str_extract(has_color, color_match)\nmatches %>% head\n\n- 색상이 여러번 나온 문장만 추출\n\nmore <- sentences[str_count(sentences, color_match) > 1]\nstr_view_all(more, color_match)\n\n- 해당 문장에서 색상 추출(여러 개인 경우 앞에 것만)\n\nstr_extract(more, color_match)\n\n- 모두 나열(simplify = FALSE하면 덜 예쁘게 나옴)\n\nstr_extract_all(more, color_match, simplify = TRUE)\n\n\nx <- c(\"a\", \"a b\", \"a b c\")\n\n\nstr_extract_all(x, \"[a-z]\", simplify = FALSE)\n\n\na 또는 the 다음에 오는 단어 찾기 정규 표현식에서 ’단어’를 정의하는 것은 약간 까다롭기에 ’최소 하나 이상의 문자(공백 제외) 시퀀스’를 이용한다.\n\n\nnoun <- \"(a|the) ([^ ]+)\"\n\n\nhas_noun <- sentences %>%\nstr_subset(noun) %>%\nhead(10)\nhas_noun %>%\nstr_extract(noun)\n\nstr_extract : 완전한 매치 제공 str_match : 각각의 개별 요소 제공\n\nhas_noun %>%\nstr_match(noun)\n\n단점은 형용사들도 포함되어서 나온다.\n\n데이터가 tibble인 경우, tidyr::extract를 사용하는 것이 더 쉽다. str_match처럼 동작하지만 매치의 이름을 사용자가 지정하도록 하고 그 각각을 새로운 열로 배치한다.\n\n\ntibble(sentence = sentences) %>%\ntidyr::extract(\n    sentence, c(\"article\", \"noun\"), \"(a|the) ([^ ]+)\",\n    remove = FALSE\n    ) %>% head\n\n물론, 이렇게 해도 ’parked’같은 형용사를 걸러내진 않는다.\n\n\n\n- 패턴을 다른 문자로 바꾸기\n\nx <- c(\"apple\", \"pear\", \"banana\")\nstr_replace(x, \"[aeiou]\", \"-\")\n\n\nstr_replace_all(x, \"[aeiou]\", \"-\")\n\n- 다중 치환도 가능\n\nx <- c(\"1 house\", \"2 cars\", \"3 people\")\nstr_replace_all(x, c(\"1\" = \"one\", \"2\" = \"two\", \"3\" = \"three\"))\n\n- 두 번째와 세 번째 단어의 순서 바꾸기\n\nsentences %>%\nstr_replace(\"([^ ]+) ([^ ]+) ([^ ]+)\", \"\\\\1 \\\\3 \\\\2\") %>%\nhead(5)\n\n비교\n\nsentences %>% head(5)\n\n\n\n\nstr_split : 문자열을 조각으로 분할시켜준다.\n- 공백 기준으로 분할\n\nsentences %>%\nhead(5) %>%\nstr_split(\" \")\n\n- 글자 하나하나 분할하기\n\n\"a|b|c|d\" %>%\nstr_split(\"\\\\|\") %>%\n.[[1]]\n\nsimplify = TRUE : 결과물 행렬로 보여줌\n\nsentences %>%\nhead(5) %>%\nstr_split(\" \", simplify = TRUE)\n\n- 반환할 조각의 최대 개수 지정하기\n\nfields <- c(\"Name: Hadley\", \"Country: NZ\", \"Age: 35\")\nfields %>% str_split(\": \", n = 2, simplify = TRUE)\n\n- boundary함수 이용해서 단어 단위로 분할하기\n\nx <- \"This is a sentence. This is another sentence.\"\nstr_view_all(x, boundary(\"word\"))\n\n- 일반적인 매칭\n\nbananas <- c(\"banana\", \"Banana\", \"BANANA\")\nstr_view(bananas, \"banana\")\n\nregex : 매치의 세부 옵션을 제어가능(원래도 regex자동 적용된건데 보여지기에 default로 생략된거임) ignore_case : 대,소문자 모두 매칭시켜준다.\n\nstr_view(bananas, regex(\"banana\", ignore_case = TRUE))\n\nmultiline = TRUE : ^와 $이 전체 문자열의 시작과 끝이 아니라 각 라인의 시작과 끝이 매칭된다.\n\nx <- \"Line 1\\nLine 2\\nLine 3\"\nstr_extract_all(x, \"^Line\")[[1]]\n\n\nstr_extract_all(x, regex(\"^Line\", multiline = TRUE))[[1]]\n\n\nphone <- regex(\"\n\\\\(?           # 선택적인 여는 괄호\n(\\\\d{3})       # 지역 번호\n[)- ]?         # 선택적인 닫는 괄호, 대시 혹은 빈칸\n(\\\\d{3})       # 세 자리 숫자\n[ -]?          # 선택적인 빈칸 혹은 대시\n(\\\\d{3})       # 세 자리 숫자\n\", comments = TRUE)\n\n\nstr_match(\"514-791-8141\", phone)\n\ndotall = TRUE : .이 \\n을 포함한 모든 문자에 매칭된다.\n- boundary는 다른 함수들과도 사용가능하다. 예를들어 extract\n\nx <- \"This is a sentence.\"\nstr_extract_all(x, boundary(\"word\"))\n\n\n\n\n\nappropos : 전역 환경에서 사용할 수 있는 모든 객체를 검색\n\napropos(\"replace\")\n\ndir : 디렉터리에 있는 모든 파일을 나열"
  },
  {
    "objectID": "posts/datascience-for-r/2022-08-20_mutate.html",
    "href": "posts/datascience-for-r/2022-08-20_mutate.html",
    "title": "mutate",
    "section": "",
    "text": "mutate(filter, count, select, left_join, match), join\n\nlibrary('tidyverse')\nlibrary('nycflights13')\n\n\n\n\n\n\n테이블에서 기본키를 확인한 후 실제로 기본키가 각 관측값을 고유하게 식별하는지 확인하기 위해 count하고 n이 1보다 큰 항목을 찾는다.\n\n\nweather %>%\ncount(year, month, day, hour, origin) %>%\nfilter(n > 1)\n\n\n\nA tibble: 3 × 6\n\n    yearmonthdayhouroriginn\n    <int><int><int><int><chr><int>\n\n\n    20131131EWR2\n    20131131JFK2\n    20131131LGA2\n\n\n\n\n\nflights %>%\ncount(year, month, day, flight) %>%\nfilter(n > 1) %>% head\n\n\n\nA tibble: 6 × 5\n\n    yearmonthdayflightn\n    <int><int><int><int><int>\n\n\n    201311 12\n    201311 32\n    201311 42\n    201311113\n    201311152\n    201311212\n\n\n\n\n\n\n\n\nflights2 <- flights %>%\nselect(year:day, hour, origin, dest, tailnum, carrier)\nflights2 %>% head\n\n\n\nA tibble: 6 × 8\n\n    yearmonthdayhourorigindesttailnumcarrier\n    <int><int><int><dbl><chr><chr><chr><chr>\n\n\n    2013115EWRIAHN14228UA\n    2013115LGAIAHN24211UA\n    2013115JFKMIAN619AAAA\n    2013115JFKBQNN804JBB6\n    2013116LGAATLN668DNDL\n    2013115EWRORDN39463UA\n\n\n\n\n\n\n\n\nflights2 %>%\nselect(-origin, -dest) %>%\nleft_join(airlines, by = \"carrier\") %>% head\n\n\n\nA tibble: 6 × 7\n\n    yearmonthdayhourtailnumcarriername\n    <int><int><int><dbl><chr><chr><chr>\n\n\n    2013115N14228UAUnited Air Lines Inc. \n    2013115N24211UAUnited Air Lines Inc. \n    2013115N619AAAAAmerican Airlines Inc.\n    2013115N804JBB6JetBlue Airways       \n    2013116N668DNDLDelta Air Lines Inc.  \n    2013115N39463UAUnited Air Lines Inc. \n\n\n\n\n\nflights2 %>%\nselect(-origin, -dest) %>% head\n\n\n\nA tibble: 6 × 6\n\n    yearmonthdayhourtailnumcarrier\n    <int><int><int><dbl><chr><chr>\n\n\n    2013115N14228UA\n    2013115N24211UA\n    2013115N619AAAA\n    2013115N804JBB6\n    2013116N668DNDL\n    2013115N39463UA\n\n\n\n\n\nairlines %>% head\n\n\n\nA tibble: 6 × 2\n\n    carriername\n    <chr><chr>\n\n\n    9EEndeavor Air Inc.       \n    AAAmerican Airlines Inc.  \n    ASAlaska Airlines Inc.    \n    B6JetBlue Airways         \n    DLDelta Air Lines Inc.    \n    EVExpressJet Airlines Inc.\n\n\n\n\nmatch : 말 그대로 다른 데이터의 열의 항목과 이 열의 해당 항목에 맞는 것을 매치해준다.\n\n\n\n\nflights2 %>%\nselect(-origin, -dest) %>%\nmutate(name = airlines$name[match(carrier, airlines$carrier)]) %>% head\n\n\n\nA tibble: 6 × 7\n\n    yearmonthdayhourtailnumcarriername\n    <int><int><int><dbl><chr><chr><chr>\n\n\n    2013115N14228UAUnited Air Lines Inc. \n    2013115N24211UAUnited Air Lines Inc. \n    2013115N619AAAAAmerican Airlines Inc.\n    2013115N804JBB6JetBlue Airways       \n    2013116N668DNDLDelta Air Lines Inc.  \n    2013115N39463UAUnited Air Lines Inc. \n\n\n\n\n\n\n\n\n- 예시 추가\n\nx <- tribble(\n    ~key, ~val_x,\n    1, \"x1\",\n    2, \"x2\",\n    3, \"x3\"\n    )\ny <- tribble(\n    ~key, ~val_y,\n    1, \"y1\",\n    2, \"y2\",\n    4, \"y3\"\n    )\n\n\nx\ny\n\n\n\nA tibble: 3 × 2\n\n    keyval_x\n    <dbl><chr>\n\n\n    1x1\n    2x2\n    3x3\n\n\n\n\n\n\nA tibble: 3 × 2\n\n    keyval_y\n    <dbl><chr>\n\n\n    1y1\n    2y2\n    4y3\n\n\n\n\n\nx %>% inner_join(y, by = \"key\")\n\n\n\nA tibble: 2 × 3\n\n    keyval_xval_y\n    <dbl><chr><chr>\n\n\n    1x1y1\n    2x2y2\n\n\n\n\n\n조인 종류\n\n\n\n\n\n\n\n키가 고유하지 않고 중복일 경우?\n\n\nx <- tribble(\n    ~key, ~val_x,\n    1, \"x1\",\n    2, \"x2\",\n    2, \"x3\",\n    1, \"x4\"\n    )\ny <- tribble(\n    ~key, ~val_y,\n    1, \"y1\",\n    2, \"y2\"\n    )\nleft_join(x, y, by = \"key\")\n\n\n\nA tibble: 4 × 3\n\n    keyval_xval_y\n    <dbl><chr><chr>\n\n\n    1x1y1\n    2x2y2\n    2x3y2\n    1x4y1\n\n\n\n\n\n일반적으로 테이블 쌍에서 조인하려는 변수는 두 테이블에서 항상 하나의 변수(같은 이름)에 의해 조인되었다. by = \"key\"에 의해 하지만, by = NULL를 사용하면 두 테이블에 있는 모든 변수를 사용하여 조인한다. 이를 nature join이라 부름.\n\n\nflights2 %>%\nleft_join(weather) %>% head\n\nJoining, by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\")\n\n\n\n\nA tibble: 6 × 18\n\n    yearmonthdayhourorigindesttailnumcarriertempdewphumidwind_dirwind_speedwind_gustprecippressurevisibtime_hour\n    <int><int><int><dbl><chr><chr><chr><chr><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dbl><dttm>\n\n\n    2013115EWRIAHN14228UA39.0228.0464.4326012.65858      NA01011.9102013-01-01 05:00:00\n    2013115LGAIAHN24211UA39.9224.9854.8125014.9601421.8648201011.4102013-01-01 05:00:00\n    2013115JFKMIAN619AAAA39.0226.9661.6326014.96014      NA01012.1102013-01-01 05:00:00\n    2013115JFKBQNN804JBB639.0226.9661.6326014.96014      NA01012.1102013-01-01 05:00:00\n    2013116LGAATLN668DNDL39.9224.9854.8126016.1109223.0156001011.7102013-01-01 06:00:00\n    2013115EWRORDN39463UA39.0228.0464.4326012.65858      NA01011.9102013-01-01 05:00:00\n\n\n\n\nunion : 합집합 함수\n\nunion(colnames(flights2),colnames(weather))\n\n\n'year''month''day''hour''origin''dest''tailnum''carrier''temp''dewp''humid''wind_dir''wind_speed''wind_gust''precip''pressure''visib''time_hour'\n\n\n\n결론 : 공통된 모든 변수로 조인\n\n- 원래 하던 것처럼 특정 변수로 조인\n\nflights2 %>%\nleft_join(planes, by = \"tailnum\") %>% head\n\n\n\nA tibble: 6 × 16\n\n    year.xmonthdayhourorigindesttailnumcarrieryear.ytypemanufacturermodelenginesseatsspeedengine\n    <int><int><int><dbl><chr><chr><chr><chr><int><chr><chr><chr><int><int><int><chr>\n\n\n    2013115EWRIAHN14228UA1999Fixed wing multi engineBOEING737-824  2149NATurbo-fan\n    2013115LGAIAHN24211UA1998Fixed wing multi engineBOEING737-824  2149NATurbo-fan\n    2013115JFKMIAN619AAAA1990Fixed wing multi engineBOEING757-223  2178NATurbo-fan\n    2013115JFKBQNN804JBB62012Fixed wing multi engineAIRBUSA320-232 2200NATurbo-fan\n    2013116LGAATLN668DNDL1991Fixed wing multi engineBOEING757-232  2178NATurbo-fan\n    2013115EWRORDN39463UA2012Fixed wing multi engineBOEING737-924ER2191NATurbo-fan\n\n\n\n\n\n아래는 각 테이블에서 다른 이름의 변수이지만 하나로 통합해서 조인하고자 하는 경우 조인후에는 첫 번째 변수의 이름으로 출력된다. 여기서는 dest로 통합\n\n\nflights2 %>%\nleft_join(airports, c(\"dest\" = \"faa\")) %>% head\n\n\n\nA tibble: 6 × 15\n\n    yearmonthdayhourorigindesttailnumcarriernamelatlonalttzdsttzone\n    <int><int><int><dbl><chr><chr><chr><chr><chr><dbl><dbl><dbl><dbl><chr><chr>\n\n\n    2013115EWRIAHN14228UAGeorge Bush Intercontinental   29.98443-95.34144  97-6A America/Chicago \n    2013115LGAIAHN24211UAGeorge Bush Intercontinental   29.98443-95.34144  97-6A America/Chicago \n    2013115JFKMIAN619AAAAMiami Intl                     25.79325-80.29056   8-5A America/New_York\n    2013115JFKBQNN804JBB6NA                                   NA       NA  NANANANA              \n    2013116LGAATLN668DNDLHartsfield Jackson Atlanta Intl33.63672-84.428071026-5A America/New_York\n    2013115EWRORDN39463UAChicago Ohare Intl             41.97860-87.90484 668-6A America/Chicago \n\n\n\n\n\n\n\n\ntop_dest <- flights %>%\ncount(dest, sort = TRUE) %>%\nhead(10)\ntop_dest\n\n\n\nA tibble: 10 × 2\n\n    destn\n    <chr><int>\n\n\n    ORD17283\n    ATL17215\n    LAX16174\n    BOS15508\n    MCO14082\n    CLT14064\n    SFO13331\n    FLL12055\n    MIA11728\n    DCA 9705\n\n\n\n\n\nflights %>%\nfilter(dest %in% top_dest$dest) %>% head\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311542540 2923850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311554600-6812837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4740728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n    201311555600-5913854 19B6 507N516JBEWRFLL15810656 02013-01-01 06:00:00\n    201311557600-3838846 -8B6  79N593JBJFKMCO140 9446 02013-01-01 06:00:00\n    201311558600-2753745  8AA 301N3ALAALGAORD138 7336 02013-01-01 06:00:00\n\n\n\n\n위에서 뽑은 상위 10개의 dest에 해당하는 열만 filtering\nsemi_join : 매칭에만 관심, 조건에 해당하는 항목을 매칭해준다. anti_join : y와 매치되는 x의 모든 관측값을 삭제한다. 즉, 불일치 행만 모아준다. 여기서는 매치되지 않는 항공편이 많은지 궁금할 때 사용\n\nflights %>%\nsemi_join(top_dest) %>% head\n\nJoining, by = \"dest\"\n\n\n\n\nA tibble: 6 × 19\n\n    yearmonthdaydep_timesched_dep_timedep_delayarr_timesched_arr_timearr_delaycarrierflighttailnumorigindestair_timedistancehourminutetime_hour\n    <int><int><int><int><int><dbl><int><int><dbl><chr><int><chr><chr><chr><dbl><dbl><dbl><dbl><dttm>\n\n\n    201311542540 2923850 33AA1141N619AAJFKMIA16010895402013-01-01 05:00:00\n    201311554600-6812837-25DL 461N668DNLGAATL116 7626 02013-01-01 06:00:00\n    201311554558-4740728 12UA1696N39463EWRORD150 7195582013-01-01 05:00:00\n    201311555600-5913854 19B6 507N516JBEWRFLL15810656 02013-01-01 06:00:00\n    201311557600-3838846 -8B6  79N593JBJFKMCO140 9446 02013-01-01 06:00:00\n    201311558600-2753745  8AA 301N3ALAALGAORD138 7336 02013-01-01 06:00:00\n\n\n\n\n결과적으로 위의 filter와 같은 결과 나옴\n\nflights %>%\nanti_join(planes, by = \"tailnum\") %>%\ncount(tailnum, sort = TRUE) %>% head\n\n\n\nA tibble: 6 × 2\n\n    tailnumn\n    <chr><int>\n\n\n    NA    2512\n    N725MQ 575\n    N722MQ 513\n    N723MQ 507\n    N713MQ 483\n    N735MQ 396\n\n\n\n\n\n\n\n\nintersect(x,y) : 교집합\nunion(x,y) : 합집합\nset_diff(x,y) : x에는 있지만, y에는 없는 관측값 반환"
  }
]